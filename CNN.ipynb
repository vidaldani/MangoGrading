{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=https://api-manager.universia.net/coreplatform-document-management/api/document-management/public/6ra7ymjkfi64845 width=\"300\" align=\"left\">\n",
    "<br />\n",
    "\n",
    "# Aprendizaje automático I\n",
    "#### <font color=green>*Máster en Informática Industrial y Robótica*</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Daniel Vidal Soroa  \n",
    "Juan Diego Peña "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificación de mangos en tres clases según su presencia para la exportación, comercio local o procesamiento industrial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importación de las librerías:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from keras.models import Sequential\n",
    "from keras.applications import vgg16, mobilenet, resnet, xception\n",
    "from keras.layers import Flatten, Dense, BatchNormalization, Dropout\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from random import seed\n",
    "from random import randint\n",
    "from keras import layers\n",
    "\n",
    "IMG_SIZE = 32\n",
    "\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "  layers.RandomFlip(\"horizontal_and_vertical\")\n",
    "])\n",
    "\n",
    "# Función para mostrar lista de imágenes en escala de grises\n",
    "def show_row_of_gray_images(fig_width, *images):\n",
    "    plt.figure(figsize=(fig_width, fig_width))\n",
    "    images_count = len(images)\n",
    "    index = 1  \n",
    "    for image in images:\n",
    "        plt.subplot(1, images_count, index)\n",
    "        plt.imshow(image, cmap='gray')\n",
    "        plt.axis('off')\n",
    "        index+=1\n",
    "\n",
    "# Función para añadir datos a una tebla de excel\n",
    "def append_data_to_excel(excel_name, df):\n",
    "    with pd.ExcelWriter(excel_name,\n",
    "        mode=\"a\",\n",
    "        engine=\"openpyxl\",\n",
    "        if_sheet_exists=\"overlay\") as writer:\n",
    "        start_row = 0\n",
    "        header = True\n",
    "        if os.path.exists(excel_name):\n",
    "            df_source = pd.read_excel(excel_name, engine=\"openpyxl\").iloc[:,1:]\n",
    "        if df_source is not None:\n",
    "            n, m = df_source.shape\n",
    "            header = False if n > 0 else True\n",
    "            start_row = n + 1 if n > 0 else n\n",
    "        \n",
    "        df.to_excel(writer, sheet_name=\"Sheet1\",startcol=0, startrow = start_row, header=header)\n",
    "\n",
    "# Función para graficar progreso durante el entrenamiento de la red \n",
    "def plot_history(history):\n",
    "    plt.figure(figsize=(12,5))\n",
    "    plt.plot(history.history['accuracy'], label='Entrenamiento')\n",
    "    plt.plot(history.history['val_accuracy'], label = 'Validación')\n",
    "    plt.xlabel('Iteración (epoch)')\n",
    "    plt.ylabel('Exactitud (accuracy)')\n",
    "    plt.ylim([0, 1])\n",
    "    plt.grid()\n",
    "    plt.title('Modelo '+str(i+1))\n",
    "    plt.legend(loc='lower right')\n",
    "\n",
    "#Distintas arquitectura para salida de la red neuronal\n",
    "def cnn1(_input_shape, classes):\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=_input_shape))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(classes, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "def cnn2(_input_shape, classes):\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=_input_shape))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(classes, activation='softmax'))   \n",
    "    return model\n",
    "\n",
    "def cnn3(_input_shape, classes):\n",
    "    model = Sequential()\n",
    "    model.add(layers.Flatten(input_shape=_input_shape))\n",
    "    model.add(layers.Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.Dense(classes, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "def get_base_model(name):\n",
    "    if name == 'vgg':\n",
    "        return vgg16.VGG16(include_top=False, weights='imagenet', input_shape=(IMG_SIZE,IMG_SIZE,3))\n",
    "    elif name == 'mobilnet':\n",
    "        return mobilenet.MobileNet(include_top=False, weights='imagenet', input_shape=(IMG_SIZE,IMG_SIZE,3))\n",
    "    elif name == 'xception':\n",
    "        return xception.Xception(include_top=False, weights='imagenet', input_shape=(IMG_SIZE,IMG_SIZE,3))\n",
    "    else: return resnet.ResNet50(include_top=False, weights='imagenet', input_shape=(IMG_SIZE,IMG_SIZE,3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lectura de los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324\n",
      "1784\n",
      "328\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x1152 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# seed random number generator\n",
    "seed(1)\n",
    "\n",
    "# Dimensión de entrada de las imágenes \n",
    "h = IMG_SIZE\n",
    "w = IMG_SIZE\n",
    "\n",
    "# Leer los nombres de las imágenes para importarlas\n",
    "input_class1_path = \"./Dataset/Grading_dataset/Class_I\"\n",
    "class1_names = os.listdir(input_class1_path)\n",
    "input_class2_path = \"./Dataset/Grading_dataset/Class_II\"\n",
    "class2_names = os.listdir(input_class2_path)\n",
    "input_classex_path = \"./Dataset/Grading_dataset/Extra_Class\"\n",
    "class3_names = os.listdir(input_classex_path)\n",
    "\n",
    "# Número de elementos en cada clase\n",
    "n = len(class1_names)\n",
    "\n",
    "# Definir listas para cargar imágenes\n",
    "class1 = np.ones([n, h, w, 3])\n",
    "class2 = np.ones([n, h, w, 3])\n",
    "class3 = np.ones([n, h, w, 3])\n",
    "\n",
    "for i in range(0, n, 1):\n",
    "    # Para cada clase, se lee una imágen, se importa\n",
    "    img = resize(imread(\"./Dataset/Grading_dataset/Class_I/\" + class1_names[i]), (h, w))\n",
    "    class1[i] = img  \n",
    "    img = resize(imread(\"./Dataset/Grading_dataset/Class_II/\" + class2_names[i]), (h, w))\n",
    "    class2[i] = img \n",
    "    img = resize(imread(\"./Dataset/Grading_dataset/Extra_Class/\" + class3_names[i]), (h, w))\n",
    "    class3[i] = img \n",
    "\n",
    "# Aumentamos por un factor f el número de datos de cada clase\n",
    "f = 10\n",
    "class1_augmeted = np.zeros([n * f, h, w, 3])\n",
    "class2_augmeted = np.zeros([n * f, h, w, 3])\n",
    "class3_augmeted = np.zeros([n * f, h, w, 3])\n",
    "t1 = np.zeros(n * f)\n",
    "t2 = np.zeros(n * f)\n",
    "t3 = np.zeros(n * f)\n",
    "\n",
    "for i in range(n * f):\n",
    "    rn = randint(0, n-1)\n",
    "    img = class1[rn]\n",
    "    new_img = data_augmentation(img)\n",
    "    class1_augmeted [i] = new_img\n",
    "    t1[i] = 1\n",
    "    \n",
    "    rn = randint(0, n-1)\n",
    "    img = class2[rn]\n",
    "    new_img = data_augmentation(img)\n",
    "    class2_augmeted [i] = new_img\n",
    "    t2[i] = 2\n",
    "    \n",
    "    rn = randint(0, n-1)\n",
    "    img = class3[rn]\n",
    "    new_img = data_augmentation(img)\n",
    "    class3_augmeted [i] = new_img\n",
    "    t3[i] = 0\n",
    "\n",
    "# Se imprimen tres imágenes aleatorias de los datos aumentados para comprobar que funciona    \n",
    "rn = randint(0, 2000)\n",
    "img_1 = class1_augmeted[rn]\n",
    "print (rn)\n",
    "rn = randint(0, 2000)\n",
    "print (rn)\n",
    "img_2 = class2_augmeted[rn]\n",
    "rn = randint(0, 2000)\n",
    "print (rn)\n",
    "img_3 = class3_augmeted[rn]  \n",
    "show_row_of_gray_images(16, img_1, img_2, img_3)\n",
    "\n",
    "# Se define el conjunto de datos de entrenamiento\n",
    "X = np.zeros([f*n*3,h*w*3])\n",
    "X[0:2000] = class3_augmeted.reshape(f*n,h*w*3)\n",
    "X[2000:4000] = class1_augmeted.reshape(f*n,h*w*3)\n",
    "X[4000:6000] = class2_augmeted.reshape(f*n,h*w*3)\n",
    "\n",
    "# Se definen las etiquetas de las clases\n",
    "t = np.zeros(f*n*3)\n",
    "t[0:2000] = t3\n",
    "t[2000:4000] = t1\n",
    "t[4000:6000] = t2\n",
    "\n",
    "X_train_val, X_test, t_train_val, t_test = train_test_split(X, t, test_size=0.3,shuffle=True)\n",
    "X_train, X_val, t_train, t_val = train_test_split(X_train_val, t_train_val, test_size=0.3, shuffle=True)\n",
    "train_target = tf.keras.utils.to_categorical(t_train)\n",
    "val_target = tf.keras.utils.to_categorical(t_val)\n",
    "test_target = tf.keras.utils.to_categorical(t_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Se importa la red CNN VGG16 para utilizar su arquitectura y conocimento para resolver nuestro problema "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 38, 38, 3)    0           ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)            (None, 16, 16, 64)   9472        ['conv1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv1_bn (BatchNormalization)  (None, 16, 16, 64)   256         ['conv1_conv[0][0]']             \n",
      "                                                                                                  \n",
      " conv1_relu (Activation)        (None, 16, 16, 64)   0           ['conv1_bn[0][0]']               \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)      (None, 18, 18, 64)   0           ['conv1_relu[0][0]']             \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)      (None, 8, 8, 64)     0           ['pool1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 8, 8, 64)     4160        ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 8, 8, 64)     36928       ['conv2_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2D)   (None, 8, 8, 256)    16640       ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2D)   (None, 8, 8, 256)    16640       ['conv2_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_0_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv2_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_3_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv2_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_add (Add)         (None, 8, 8, 256)    0           ['conv2_block1_0_bn[0][0]',      \n",
      "                                                                  'conv2_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block1_out (Activation)  (None, 8, 8, 256)    0           ['conv2_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 8, 8, 64)     16448       ['conv2_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 8, 8, 64)     36928       ['conv2_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2D)   (None, 8, 8, 256)    16640       ['conv2_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_3_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv2_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_add (Add)         (None, 8, 8, 256)    0           ['conv2_block1_out[0][0]',       \n",
      "                                                                  'conv2_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block2_out (Activation)  (None, 8, 8, 256)    0           ['conv2_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 8, 8, 64)     16448       ['conv2_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 8, 8, 64)     36928       ['conv2_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2D)   (None, 8, 8, 256)    16640       ['conv2_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_3_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv2_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_add (Add)         (None, 8, 8, 256)    0           ['conv2_block2_out[0][0]',       \n",
      "                                                                  'conv2_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block3_out (Activation)  (None, 8, 8, 256)    0           ['conv2_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 4, 4, 128)    32896       ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 4, 4, 128)    147584      ['conv3_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2D)   (None, 4, 4, 512)    131584      ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2D)   (None, 4, 4, 512)    66048       ['conv3_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_0_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_3_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_add (Add)         (None, 4, 4, 512)    0           ['conv3_block1_0_bn[0][0]',      \n",
      "                                                                  'conv3_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block1_out (Activation)  (None, 4, 4, 512)    0           ['conv3_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 4, 4, 128)    65664       ['conv3_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 4, 4, 128)    147584      ['conv3_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2D)   (None, 4, 4, 512)    66048       ['conv3_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_3_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_add (Add)         (None, 4, 4, 512)    0           ['conv3_block1_out[0][0]',       \n",
      "                                                                  'conv3_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block2_out (Activation)  (None, 4, 4, 512)    0           ['conv3_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 4, 4, 128)    65664       ['conv3_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 4, 4, 128)    147584      ['conv3_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2D)   (None, 4, 4, 512)    66048       ['conv3_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_3_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_add (Add)         (None, 4, 4, 512)    0           ['conv3_block2_out[0][0]',       \n",
      "                                                                  'conv3_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block3_out (Activation)  (None, 4, 4, 512)    0           ['conv3_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 4, 4, 128)    65664       ['conv3_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 4, 4, 128)    147584      ['conv3_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2D)   (None, 4, 4, 512)    66048       ['conv3_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_3_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block4_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_add (Add)         (None, 4, 4, 512)    0           ['conv3_block3_out[0][0]',       \n",
      "                                                                  'conv3_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block4_out (Activation)  (None, 4, 4, 512)    0           ['conv3_block4_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 2, 2, 256)    131328      ['conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2D)   (None, 2, 2, 1024)   525312      ['conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_0_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block1_0_bn[0][0]',      \n",
      "                                                                  'conv4_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block1_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block1_out[0][0]',       \n",
      "                                                                  'conv4_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block2_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block2_out[0][0]',       \n",
      "                                                                  'conv4_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block3_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block4_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block3_out[0][0]',       \n",
      "                                                                  'conv4_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block4_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block4_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block5_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block5_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block5_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block5_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block4_out[0][0]',       \n",
      "                                                                  'conv4_block5_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block5_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block5_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block5_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block6_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block6_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block6_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block6_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block5_out[0][0]',       \n",
      "                                                                  'conv4_block6_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block6_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block6_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2D)   (None, 1, 1, 512)    524800      ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2D)   (None, 1, 1, 512)    2359808     ['conv5_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_2_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2D)   (None, 1, 1, 2048)   2099200     ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2D)   (None, 1, 1, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_0_bn (BatchNormal  (None, 1, 1, 2048)  8192        ['conv5_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_3_bn (BatchNormal  (None, 1, 1, 2048)  8192        ['conv5_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_add (Add)         (None, 1, 1, 2048)   0           ['conv5_block1_0_bn[0][0]',      \n",
      "                                                                  'conv5_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block1_out (Activation)  (None, 1, 1, 2048)   0           ['conv5_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2D)   (None, 1, 1, 512)    1049088     ['conv5_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2D)   (None, 1, 1, 512)    2359808     ['conv5_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2D)   (None, 1, 1, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_3_bn (BatchNormal  (None, 1, 1, 2048)  8192        ['conv5_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_add (Add)         (None, 1, 1, 2048)   0           ['conv5_block1_out[0][0]',       \n",
      "                                                                  'conv5_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block2_out (Activation)  (None, 1, 1, 2048)   0           ['conv5_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2D)   (None, 1, 1, 512)    1049088     ['conv5_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2D)   (None, 1, 1, 512)    2359808     ['conv5_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2D)   (None, 1, 1, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_3_bn (BatchNormal  (None, 1, 1, 2048)  8192        ['conv5_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_add (Add)         (None, 1, 1, 2048)   0           ['conv5_block2_out[0][0]',       \n",
      "                                                                  'conv5_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block3_out (Activation)  (None, 1, 1, 2048)   0           ['conv5_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 23,534,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# include top should be False to remove the softmax layer\n",
    "model_name = \"resnet\"\n",
    "pretrained_model = get_base_model(model_name)\n",
    "pretrained_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_2 (Flatten)         (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                131136    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 131,331\n",
      "Trainable params: 131,331\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classes = 3\n",
    "input_shape = pretrained_model.output_shape[1:4]\n",
    "modelCNN = cnn2(input_shape, classes)\n",
    "# compile the model\n",
    "modelCNN.compile(optimizer='adam', metrics=['accuracy',\n",
    "                                            tf.keras.metrics.Recall(),\n",
    "                                            tf.keras.metrics.TrueNegatives(),\n",
    "                                            tf.keras.metrics.FalsePositives(), \n",
    "                                            tf.keras.metrics.Precision(),\n",
    "                                            tf.keras.metrics.AUC()], loss='categorical_crossentropy')\n",
    "modelCNN.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finalmente se realiza la clasificación utilizando las capas finales de la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "49/49 [==============================] - 3s 28ms/step - loss: 1.1457 - accuracy: 0.3435 - recall_2: 0.0765 - true_negatives_2: 5458.0000 - false_positives_2: 422.0000 - precision_2: 0.3478 - auc_2: 0.5162 - val_loss: 1.0891 - val_accuracy: 0.3770 - val_recall_2: 0.0000e+00 - val_true_negatives_2: 2520.0000 - val_false_positives_2: 0.0000e+00 - val_precision_2: 0.0000e+00 - val_auc_2: 0.5824\n",
      "Epoch 2/200\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 1.1133 - accuracy: 0.3595 - recall_2: 0.0129 - true_negatives_2: 5831.0000 - false_positives_2: 49.0000 - precision_2: 0.4368 - auc_2: 0.5165 - val_loss: 1.0852 - val_accuracy: 0.3437 - val_recall_2: 0.0000e+00 - val_true_negatives_2: 2520.0000 - val_false_positives_2: 0.0000e+00 - val_precision_2: 0.0000e+00 - val_auc_2: 0.6007\n",
      "Epoch 3/200\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 1.0927 - accuracy: 0.3680 - recall_2: 0.0207 - true_negatives_2: 5806.0000 - false_positives_2: 74.0000 - precision_2: 0.4519 - auc_2: 0.5543 - val_loss: 1.0829 - val_accuracy: 0.4111 - val_recall_2: 0.0000e+00 - val_true_negatives_2: 2520.0000 - val_false_positives_2: 0.0000e+00 - val_precision_2: 0.0000e+00 - val_auc_2: 0.5827\n",
      "Epoch 4/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 1.0948 - accuracy: 0.3932 - recall_2: 0.0602 - true_negatives_2: 5643.0000 - false_positives_2: 237.0000 - precision_2: 0.4275 - auc_2: 0.5645 - val_loss: 1.1009 - val_accuracy: 0.3452 - val_recall_2: 0.0095 - val_true_negatives_2: 2516.0000 - val_false_positives_2: 4.0000 - val_precision_2: 0.7500 - val_auc_2: 0.5663\n",
      "Epoch 5/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 1.0829 - accuracy: 0.3878 - recall_2: 0.0286 - true_negatives_2: 5783.0000 - false_positives_2: 97.0000 - precision_2: 0.4641 - auc_2: 0.5742 - val_loss: 1.0606 - val_accuracy: 0.4484 - val_recall_2: 0.0016 - val_true_negatives_2: 2508.0000 - val_false_positives_2: 12.0000 - val_precision_2: 0.1429 - val_auc_2: 0.6521\n",
      "Epoch 6/200\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 1.0838 - accuracy: 0.3932 - recall_2: 0.0554 - true_negatives_2: 5748.0000 - false_positives_2: 132.0000 - precision_2: 0.5525 - auc_2: 0.5754 - val_loss: 1.0568 - val_accuracy: 0.4429 - val_recall_2: 0.0024 - val_true_negatives_2: 2515.0000 - val_false_positives_2: 5.0000 - val_precision_2: 0.3750 - val_auc_2: 0.6500\n",
      "Epoch 7/200\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 1.0644 - accuracy: 0.4327 - recall_2: 0.0197 - true_negatives_2: 5831.0000 - false_positives_2: 49.0000 - precision_2: 0.5421 - auc_2: 0.6145 - val_loss: 1.0535 - val_accuracy: 0.3857 - val_recall_2: 0.0056 - val_true_negatives_2: 2516.0000 - val_false_positives_2: 4.0000 - val_precision_2: 0.6364 - val_auc_2: 0.6344\n",
      "Epoch 8/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 1.0757 - accuracy: 0.4102 - recall_2: 0.0871 - true_negatives_2: 5580.0000 - false_positives_2: 300.0000 - precision_2: 0.4604 - auc_2: 0.5930 - val_loss: 1.0669 - val_accuracy: 0.3730 - val_recall_2: 0.1405 - val_true_negatives_2: 2359.0000 - val_false_positives_2: 161.0000 - val_precision_2: 0.5237 - val_auc_2: 0.6228\n",
      "Epoch 9/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 1.0641 - accuracy: 0.4204 - recall_2: 0.0588 - true_negatives_2: 5701.0000 - false_positives_2: 179.0000 - precision_2: 0.4915 - auc_2: 0.6093 - val_loss: 1.0446 - val_accuracy: 0.4429 - val_recall_2: 0.0111 - val_true_negatives_2: 2501.0000 - val_false_positives_2: 19.0000 - val_precision_2: 0.4242 - val_auc_2: 0.6560\n",
      "Epoch 10/200\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 1.0400 - accuracy: 0.4684 - recall_2: 0.0333 - true_negatives_2: 5810.0000 - false_positives_2: 70.0000 - precision_2: 0.5833 - auc_2: 0.6557 - val_loss: 1.0321 - val_accuracy: 0.4810 - val_recall_2: 0.0381 - val_true_negatives_2: 2474.0000 - val_false_positives_2: 46.0000 - val_precision_2: 0.5106 - val_auc_2: 0.6785\n",
      "Epoch 11/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 1.0519 - accuracy: 0.4432 - recall_2: 0.0588 - true_negatives_2: 5700.0000 - false_positives_2: 180.0000 - precision_2: 0.4901 - auc_2: 0.6299 - val_loss: 1.0572 - val_accuracy: 0.4167 - val_recall_2: 0.1913 - val_true_negatives_2: 2301.0000 - val_false_positives_2: 219.0000 - val_precision_2: 0.5239 - val_auc_2: 0.6264\n",
      "Epoch 12/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 1.0400 - accuracy: 0.4714 - recall_2: 0.0575 - true_negatives_2: 5731.0000 - false_positives_2: 149.0000 - precision_2: 0.5314 - auc_2: 0.6478 - val_loss: 1.0228 - val_accuracy: 0.5183 - val_recall_2: 0.0460 - val_true_negatives_2: 2463.0000 - val_false_positives_2: 57.0000 - val_precision_2: 0.5043 - val_auc_2: 0.6942\n",
      "Epoch 13/200\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 1.0397 - accuracy: 0.4422 - recall_2: 0.0827 - true_negatives_2: 5723.0000 - false_positives_2: 157.0000 - precision_2: 0.6075 - auc_2: 0.6442 - val_loss: 1.0328 - val_accuracy: 0.4373 - val_recall_2: 0.0278 - val_true_negatives_2: 2488.0000 - val_false_positives_2: 32.0000 - val_precision_2: 0.5224 - val_auc_2: 0.6534\n",
      "Epoch 14/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 1.0322 - accuracy: 0.4486 - recall_2: 0.1112 - true_negatives_2: 5622.0000 - false_positives_2: 258.0000 - precision_2: 0.5590 - auc_2: 0.6527 - val_loss: 1.0178 - val_accuracy: 0.5238 - val_recall_2: 0.0325 - val_true_negatives_2: 2493.0000 - val_false_positives_2: 27.0000 - val_precision_2: 0.6029 - val_auc_2: 0.6911\n",
      "Epoch 15/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 1.0419 - accuracy: 0.4588 - recall_2: 0.1395 - true_negatives_2: 5528.0000 - false_positives_2: 352.0000 - precision_2: 0.5381 - auc_2: 0.6389 - val_loss: 1.0257 - val_accuracy: 0.4770 - val_recall_2: 0.1548 - val_true_negatives_2: 2389.0000 - val_false_positives_2: 131.0000 - val_precision_2: 0.5982 - val_auc_2: 0.6639\n",
      "Epoch 16/200\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 1.0424 - accuracy: 0.4599 - recall_2: 0.1238 - true_negatives_2: 5594.0000 - false_positives_2: 286.0000 - precision_2: 0.5600 - auc_2: 0.6397 - val_loss: 1.0260 - val_accuracy: 0.5071 - val_recall_2: 0.0476 - val_true_negatives_2: 2492.0000 - val_false_positives_2: 28.0000 - val_precision_2: 0.6818 - val_auc_2: 0.6622\n",
      "Epoch 17/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 1.0364 - accuracy: 0.4554 - recall_2: 0.1259 - true_negatives_2: 5581.0000 - false_positives_2: 299.0000 - precision_2: 0.5531 - auc_2: 0.6467 - val_loss: 1.1055 - val_accuracy: 0.3262 - val_recall_2: 0.2294 - val_true_negatives_2: 2150.0000 - val_false_positives_2: 370.0000 - val_precision_2: 0.4385 - val_auc_2: 0.5795\n",
      "Epoch 18/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 1.0178 - accuracy: 0.4857 - recall_2: 0.1054 - true_negatives_2: 5660.0000 - false_positives_2: 220.0000 - precision_2: 0.5849 - auc_2: 0.6746 - val_loss: 1.0714 - val_accuracy: 0.3635 - val_recall_2: 0.1675 - val_true_negatives_2: 2387.0000 - val_false_positives_2: 133.0000 - val_precision_2: 0.6134 - val_auc_2: 0.6001\n",
      "Epoch 19/200\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 1.0389 - accuracy: 0.4473 - recall_2: 0.1429 - true_negatives_2: 5514.0000 - false_positives_2: 366.0000 - precision_2: 0.5344 - auc_2: 0.6426 - val_loss: 1.0238 - val_accuracy: 0.4206 - val_recall_2: 0.1913 - val_true_negatives_2: 2290.0000 - val_false_positives_2: 230.0000 - val_precision_2: 0.5117 - val_auc_2: 0.6614\n",
      "Epoch 20/200\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 1.0323 - accuracy: 0.4592 - recall_2: 0.1265 - true_negatives_2: 5556.0000 - false_positives_2: 324.0000 - precision_2: 0.5345 - auc_2: 0.6512 - val_loss: 1.0370 - val_accuracy: 0.4524 - val_recall_2: 0.2421 - val_true_negatives_2: 2249.0000 - val_false_positives_2: 271.0000 - val_precision_2: 0.5295 - val_auc_2: 0.6528\n",
      "Epoch 21/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 1.0476 - accuracy: 0.4354 - recall_2: 0.1697 - true_negatives_2: 5395.0000 - false_positives_2: 485.0000 - precision_2: 0.5071 - auc_2: 0.6321 - val_loss: 1.0446 - val_accuracy: 0.4389 - val_recall_2: 0.1071 - val_true_negatives_2: 2458.0000 - val_false_positives_2: 62.0000 - val_precision_2: 0.6853 - val_auc_2: 0.6365\n",
      "Epoch 22/200\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 1.0410 - accuracy: 0.4510 - recall_2: 0.1731 - true_negatives_2: 5441.0000 - false_positives_2: 439.0000 - precision_2: 0.5369 - auc_2: 0.6395 - val_loss: 1.0115 - val_accuracy: 0.4810 - val_recall_2: 0.1230 - val_true_negatives_2: 2443.0000 - val_false_positives_2: 77.0000 - val_precision_2: 0.6681 - val_auc_2: 0.6779\n",
      "Epoch 23/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 1.0199 - accuracy: 0.4728 - recall_2: 0.1592 - true_negatives_2: 5543.0000 - false_positives_2: 337.0000 - precision_2: 0.5814 - auc_2: 0.6664 - val_loss: 1.0211 - val_accuracy: 0.4675 - val_recall_2: 0.2206 - val_true_negatives_2: 2283.0000 - val_false_positives_2: 237.0000 - val_precision_2: 0.5398 - val_auc_2: 0.6665\n",
      "Epoch 24/200\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 1.0139 - accuracy: 0.4840 - recall_2: 0.1612 - true_negatives_2: 5497.0000 - false_positives_2: 383.0000 - precision_2: 0.5531 - auc_2: 0.6734 - val_loss: 0.9969 - val_accuracy: 0.5183 - val_recall_2: 0.1008 - val_true_negatives_2: 2455.0000 - val_false_positives_2: 65.0000 - val_precision_2: 0.6615 - val_auc_2: 0.7041\n",
      "Epoch 25/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 1.0090 - accuracy: 0.4823 - recall_2: 0.1446 - true_negatives_2: 5616.0000 - false_positives_2: 264.0000 - precision_2: 0.6168 - auc_2: 0.6795 - val_loss: 1.0393 - val_accuracy: 0.3976 - val_recall_2: 0.1913 - val_true_negatives_2: 2343.0000 - val_false_positives_2: 177.0000 - val_precision_2: 0.5766 - val_auc_2: 0.6310\n",
      "Epoch 26/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 1.0203 - accuracy: 0.4738 - recall_2: 0.1714 - true_negatives_2: 5510.0000 - false_positives_2: 370.0000 - precision_2: 0.5767 - auc_2: 0.6653 - val_loss: 0.9834 - val_accuracy: 0.5429 - val_recall_2: 0.1063 - val_true_negatives_2: 2460.0000 - val_false_positives_2: 60.0000 - val_precision_2: 0.6907 - val_auc_2: 0.7263\n",
      "Epoch 27/200\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 1.0068 - accuracy: 0.4891 - recall_2: 0.1660 - true_negatives_2: 5580.0000 - false_positives_2: 300.0000 - precision_2: 0.6193 - auc_2: 0.6813 - val_loss: 1.0183 - val_accuracy: 0.4738 - val_recall_2: 0.2730 - val_true_negatives_2: 2265.0000 - val_false_positives_2: 255.0000 - val_precision_2: 0.5743 - val_auc_2: 0.6697\n",
      "Epoch 28/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 1.0051 - accuracy: 0.4905 - recall_2: 0.1881 - true_negatives_2: 5476.0000 - false_positives_2: 404.0000 - precision_2: 0.5778 - auc_2: 0.6814 - val_loss: 0.9987 - val_accuracy: 0.5222 - val_recall_2: 0.1437 - val_true_negatives_2: 2431.0000 - val_false_positives_2: 89.0000 - val_precision_2: 0.6704 - val_auc_2: 0.6894\n",
      "Epoch 29/200\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 1.0372 - accuracy: 0.4707 - recall_2: 0.2003 - true_negatives_2: 5389.0000 - false_positives_2: 491.0000 - precision_2: 0.5454 - auc_2: 0.6476 - val_loss: 0.9848 - val_accuracy: 0.5310 - val_recall_2: 0.1381 - val_true_negatives_2: 2443.0000 - val_false_positives_2: 77.0000 - val_precision_2: 0.6932 - val_auc_2: 0.7124\n",
      "Epoch 30/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 1.0036 - accuracy: 0.4986 - recall_2: 0.1881 - true_negatives_2: 5512.0000 - false_positives_2: 368.0000 - precision_2: 0.6004 - auc_2: 0.6839 - val_loss: 0.9823 - val_accuracy: 0.4968 - val_recall_2: 0.2119 - val_true_negatives_2: 2352.0000 - val_false_positives_2: 168.0000 - val_precision_2: 0.6138 - val_auc_2: 0.7083\n",
      "Epoch 31/200\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 1.0233 - accuracy: 0.4738 - recall_2: 0.2054 - true_negatives_2: 5401.0000 - false_positives_2: 479.0000 - precision_2: 0.5577 - auc_2: 0.6589 - val_loss: 0.9875 - val_accuracy: 0.5278 - val_recall_2: 0.1381 - val_true_negatives_2: 2453.0000 - val_false_positives_2: 67.0000 - val_precision_2: 0.7220 - val_auc_2: 0.7059\n",
      "Epoch 32/200\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.9959 - accuracy: 0.4973 - recall_2: 0.2143 - true_negatives_2: 5491.0000 - false_positives_2: 389.0000 - precision_2: 0.6183 - auc_2: 0.6906 - val_loss: 0.9954 - val_accuracy: 0.4690 - val_recall_2: 0.2540 - val_true_negatives_2: 2276.0000 - val_false_positives_2: 244.0000 - val_precision_2: 0.5674 - val_auc_2: 0.6891\n",
      "Epoch 33/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.9945 - accuracy: 0.4929 - recall_2: 0.2088 - true_negatives_2: 5473.0000 - false_positives_2: 407.0000 - precision_2: 0.6014 - auc_2: 0.6886 - val_loss: 1.0159 - val_accuracy: 0.4437 - val_recall_2: 0.2119 - val_true_negatives_2: 2370.0000 - val_false_positives_2: 150.0000 - val_precision_2: 0.6403 - val_auc_2: 0.6586\n",
      "Epoch 34/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.9888 - accuracy: 0.5027 - recall_2: 0.2180 - true_negatives_2: 5494.0000 - false_positives_2: 386.0000 - precision_2: 0.6241 - auc_2: 0.6982 - val_loss: 0.9722 - val_accuracy: 0.5381 - val_recall_2: 0.1738 - val_true_negatives_2: 2438.0000 - val_false_positives_2: 82.0000 - val_precision_2: 0.7276 - val_auc_2: 0.7234\n",
      "Epoch 35/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.9869 - accuracy: 0.5099 - recall_2: 0.2276 - true_negatives_2: 5465.0000 - false_positives_2: 415.0000 - precision_2: 0.6172 - auc_2: 0.6983 - val_loss: 0.9851 - val_accuracy: 0.5135 - val_recall_2: 0.2325 - val_true_negatives_2: 2371.0000 - val_false_positives_2: 149.0000 - val_precision_2: 0.6629 - val_auc_2: 0.7047\n",
      "Epoch 36/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.9895 - accuracy: 0.5109 - recall_2: 0.2170 - true_negatives_2: 5474.0000 - false_positives_2: 406.0000 - precision_2: 0.6111 - auc_2: 0.6963 - val_loss: 0.9606 - val_accuracy: 0.5675 - val_recall_2: 0.1937 - val_true_negatives_2: 2406.0000 - val_false_positives_2: 114.0000 - val_precision_2: 0.6816 - val_auc_2: 0.7388\n",
      "Epoch 37/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.9753 - accuracy: 0.5296 - recall_2: 0.2207 - true_negatives_2: 5524.0000 - false_positives_2: 356.0000 - precision_2: 0.6458 - auc_2: 0.7142 - val_loss: 0.9794 - val_accuracy: 0.5222 - val_recall_2: 0.2437 - val_true_negatives_2: 2357.0000 - val_false_positives_2: 163.0000 - val_precision_2: 0.6532 - val_auc_2: 0.7086\n",
      "Epoch 38/200\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.9795 - accuracy: 0.5041 - recall_2: 0.2361 - true_negatives_2: 5469.0000 - false_positives_2: 411.0000 - precision_2: 0.6281 - auc_2: 0.7053 - val_loss: 1.0497 - val_accuracy: 0.4548 - val_recall_2: 0.3310 - val_true_negatives_2: 2103.0000 - val_false_positives_2: 417.0000 - val_precision_2: 0.5000 - val_auc_2: 0.6579\n",
      "Epoch 39/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 1.0105 - accuracy: 0.4799 - recall_2: 0.2735 - true_negatives_2: 5248.0000 - false_positives_2: 632.0000 - precision_2: 0.5599 - auc_2: 0.6747 - val_loss: 1.0512 - val_accuracy: 0.3913 - val_recall_2: 0.2778 - val_true_negatives_2: 2122.0000 - val_false_positives_2: 398.0000 - val_precision_2: 0.4679 - val_auc_2: 0.6379\n",
      "Epoch 40/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.9986 - accuracy: 0.4990 - recall_2: 0.2459 - true_negatives_2: 5367.0000 - false_positives_2: 513.0000 - precision_2: 0.5850 - auc_2: 0.6863 - val_loss: 0.9835 - val_accuracy: 0.4611 - val_recall_2: 0.2421 - val_true_negatives_2: 2356.0000 - val_false_positives_2: 164.0000 - val_precision_2: 0.6503 - val_auc_2: 0.6945\n",
      "Epoch 41/200\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.9678 - accuracy: 0.5187 - recall_2: 0.2388 - true_negatives_2: 5518.0000 - false_positives_2: 362.0000 - precision_2: 0.6598 - auc_2: 0.7180 - val_loss: 0.9597 - val_accuracy: 0.5270 - val_recall_2: 0.2603 - val_true_negatives_2: 2327.0000 - val_false_positives_2: 193.0000 - val_precision_2: 0.6296 - val_auc_2: 0.7241\n",
      "Epoch 42/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.9684 - accuracy: 0.5204 - recall_2: 0.2670 - true_negatives_2: 5461.0000 - false_positives_2: 419.0000 - precision_2: 0.6520 - auc_2: 0.7157 - val_loss: 0.9589 - val_accuracy: 0.5452 - val_recall_2: 0.2595 - val_true_negatives_2: 2302.0000 - val_false_positives_2: 218.0000 - val_precision_2: 0.6000 - val_auc_2: 0.7275\n",
      "Epoch 43/200\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.9809 - accuracy: 0.5075 - recall_2: 0.2776 - true_negatives_2: 5352.0000 - false_positives_2: 528.0000 - precision_2: 0.6071 - auc_2: 0.6999 - val_loss: 0.9717 - val_accuracy: 0.5270 - val_recall_2: 0.2881 - val_true_negatives_2: 2277.0000 - val_false_positives_2: 243.0000 - val_precision_2: 0.5990 - val_auc_2: 0.7142\n",
      "Epoch 44/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.9628 - accuracy: 0.5231 - recall_2: 0.2714 - true_negatives_2: 5439.0000 - false_positives_2: 441.0000 - precision_2: 0.6441 - auc_2: 0.7199 - val_loss: 0.9794 - val_accuracy: 0.4937 - val_recall_2: 0.2595 - val_true_negatives_2: 2354.0000 - val_false_positives_2: 166.0000 - val_precision_2: 0.6633 - val_auc_2: 0.6966\n",
      "Epoch 45/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.9609 - accuracy: 0.5425 - recall_2: 0.2650 - true_negatives_2: 5499.0000 - false_positives_2: 381.0000 - precision_2: 0.6716 - auc_2: 0.7236 - val_loss: 0.9408 - val_accuracy: 0.5738 - val_recall_2: 0.2651 - val_true_negatives_2: 2362.0000 - val_false_positives_2: 158.0000 - val_precision_2: 0.6789 - val_auc_2: 0.7476\n",
      "Epoch 46/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.9593 - accuracy: 0.5381 - recall_2: 0.2779 - true_negatives_2: 5460.0000 - false_positives_2: 420.0000 - precision_2: 0.6605 - auc_2: 0.7233 - val_loss: 0.9414 - val_accuracy: 0.5786 - val_recall_2: 0.2587 - val_true_negatives_2: 2380.0000 - val_false_positives_2: 140.0000 - val_precision_2: 0.6996 - val_auc_2: 0.7464\n",
      "Epoch 47/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.9628 - accuracy: 0.5269 - recall_2: 0.2942 - true_negatives_2: 5392.0000 - false_positives_2: 488.0000 - precision_2: 0.6393 - auc_2: 0.7183 - val_loss: 0.9604 - val_accuracy: 0.5365 - val_recall_2: 0.3032 - val_true_negatives_2: 2255.0000 - val_false_positives_2: 265.0000 - val_precision_2: 0.5904 - val_auc_2: 0.7198\n",
      "Epoch 48/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.9976 - accuracy: 0.5010 - recall_2: 0.2915 - true_negatives_2: 5262.0000 - false_positives_2: 618.0000 - precision_2: 0.5810 - auc_2: 0.6884 - val_loss: 0.9568 - val_accuracy: 0.5413 - val_recall_2: 0.2571 - val_true_negatives_2: 2378.0000 - val_false_positives_2: 142.0000 - val_precision_2: 0.6953 - val_auc_2: 0.7253\n",
      "Epoch 49/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.9613 - accuracy: 0.5259 - recall_2: 0.2820 - true_negatives_2: 5415.0000 - false_positives_2: 465.0000 - precision_2: 0.6406 - auc_2: 0.7211 - val_loss: 0.9791 - val_accuracy: 0.4643 - val_recall_2: 0.2754 - val_true_negatives_2: 2295.0000 - val_false_positives_2: 225.0000 - val_precision_2: 0.6066 - val_auc_2: 0.6960\n",
      "Epoch 50/200\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.9493 - accuracy: 0.5456 - recall_2: 0.2813 - true_negatives_2: 5452.0000 - false_positives_2: 428.0000 - precision_2: 0.6590 - auc_2: 0.7329 - val_loss: 0.9404 - val_accuracy: 0.5563 - val_recall_2: 0.2722 - val_true_negatives_2: 2379.0000 - val_false_positives_2: 141.0000 - val_precision_2: 0.7087 - val_auc_2: 0.7417\n",
      "Epoch 51/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.9478 - accuracy: 0.5412 - recall_2: 0.3143 - true_negatives_2: 5403.0000 - false_positives_2: 477.0000 - precision_2: 0.6595 - auc_2: 0.7313 - val_loss: 0.9310 - val_accuracy: 0.5889 - val_recall_2: 0.2849 - val_true_negatives_2: 2365.0000 - val_false_positives_2: 155.0000 - val_precision_2: 0.6984 - val_auc_2: 0.7542\n",
      "Epoch 52/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.9491 - accuracy: 0.5483 - recall_2: 0.2973 - true_negatives_2: 5410.0000 - false_positives_2: 470.0000 - precision_2: 0.6503 - auc_2: 0.7314 - val_loss: 0.9445 - val_accuracy: 0.5611 - val_recall_2: 0.3175 - val_true_negatives_2: 2303.0000 - val_false_positives_2: 217.0000 - val_precision_2: 0.6483 - val_auc_2: 0.7366\n",
      "Epoch 53/200\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.9557 - accuracy: 0.5347 - recall_2: 0.3197 - true_negatives_2: 5327.0000 - false_positives_2: 553.0000 - precision_2: 0.6296 - auc_2: 0.7237 - val_loss: 0.9503 - val_accuracy: 0.5151 - val_recall_2: 0.3111 - val_true_negatives_2: 2227.0000 - val_false_positives_2: 293.0000 - val_precision_2: 0.5723 - val_auc_2: 0.7235\n",
      "Epoch 54/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.9689 - accuracy: 0.5187 - recall_2: 0.3265 - true_negatives_2: 5269.0000 - false_positives_2: 611.0000 - precision_2: 0.6111 - auc_2: 0.7113 - val_loss: 0.9209 - val_accuracy: 0.5929 - val_recall_2: 0.2905 - val_true_negatives_2: 2367.0000 - val_false_positives_2: 153.0000 - val_precision_2: 0.7052 - val_auc_2: 0.7630\n",
      "Epoch 55/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.9341 - accuracy: 0.5599 - recall_2: 0.3133 - true_negatives_2: 5420.0000 - false_positives_2: 460.0000 - precision_2: 0.6669 - auc_2: 0.7444 - val_loss: 0.9363 - val_accuracy: 0.5587 - val_recall_2: 0.2952 - val_true_negatives_2: 2354.0000 - val_false_positives_2: 166.0000 - val_precision_2: 0.6914 - val_auc_2: 0.7444\n",
      "Epoch 56/200\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.9424 - accuracy: 0.5435 - recall_2: 0.3187 - true_negatives_2: 5348.0000 - false_positives_2: 532.0000 - precision_2: 0.6378 - auc_2: 0.7340 - val_loss: 0.9244 - val_accuracy: 0.5817 - val_recall_2: 0.3079 - val_true_negatives_2: 2362.0000 - val_false_positives_2: 158.0000 - val_precision_2: 0.7106 - val_auc_2: 0.7554\n",
      "Epoch 57/200\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.9287 - accuracy: 0.5721 - recall_2: 0.3163 - true_negatives_2: 5447.0000 - false_positives_2: 433.0000 - precision_2: 0.6823 - auc_2: 0.7493 - val_loss: 0.9233 - val_accuracy: 0.5746 - val_recall_2: 0.3286 - val_true_negatives_2: 2308.0000 - val_false_positives_2: 212.0000 - val_precision_2: 0.6613 - val_auc_2: 0.7536\n",
      "Epoch 58/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.9614 - accuracy: 0.5286 - recall_2: 0.3238 - true_negatives_2: 5292.0000 - false_positives_2: 588.0000 - precision_2: 0.6182 - auc_2: 0.7198 - val_loss: 1.0498 - val_accuracy: 0.4063 - val_recall_2: 0.2897 - val_true_negatives_2: 2099.0000 - val_false_positives_2: 421.0000 - val_precision_2: 0.4644 - val_auc_2: 0.6439\n",
      "Epoch 59/200\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.9533 - accuracy: 0.5384 - recall_2: 0.3119 - true_negatives_2: 5369.0000 - false_positives_2: 511.0000 - precision_2: 0.6422 - auc_2: 0.7257 - val_loss: 0.9229 - val_accuracy: 0.5794 - val_recall_2: 0.3063 - val_true_negatives_2: 2376.0000 - val_false_positives_2: 144.0000 - val_precision_2: 0.7283 - val_auc_2: 0.7575\n",
      "Epoch 60/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.9464 - accuracy: 0.5456 - recall_2: 0.3248 - true_negatives_2: 5367.0000 - false_positives_2: 513.0000 - precision_2: 0.6505 - auc_2: 0.7306 - val_loss: 0.9229 - val_accuracy: 0.5468 - val_recall_2: 0.3278 - val_true_negatives_2: 2284.0000 - val_false_positives_2: 236.0000 - val_precision_2: 0.6364 - val_auc_2: 0.7508\n",
      "Epoch 61/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.9434 - accuracy: 0.5473 - recall_2: 0.3252 - true_negatives_2: 5343.0000 - false_positives_2: 537.0000 - precision_2: 0.6403 - auc_2: 0.7339 - val_loss: 0.9132 - val_accuracy: 0.5968 - val_recall_2: 0.2976 - val_true_negatives_2: 2369.0000 - val_false_positives_2: 151.0000 - val_precision_2: 0.7129 - val_auc_2: 0.7697\n",
      "Epoch 62/200\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.9184 - accuracy: 0.5779 - recall_2: 0.3204 - true_negatives_2: 5442.0000 - false_positives_2: 438.0000 - precision_2: 0.6826 - auc_2: 0.7591 - val_loss: 0.9322 - val_accuracy: 0.5460 - val_recall_2: 0.3603 - val_true_negatives_2: 2245.0000 - val_false_positives_2: 275.0000 - val_precision_2: 0.6228 - val_auc_2: 0.7430\n",
      "Epoch 63/200\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.9513 - accuracy: 0.5306 - recall_2: 0.3429 - true_negatives_2: 5278.0000 - false_positives_2: 602.0000 - precision_2: 0.6261 - auc_2: 0.7269 - val_loss: 0.9388 - val_accuracy: 0.5317 - val_recall_2: 0.3262 - val_true_negatives_2: 2330.0000 - val_false_positives_2: 190.0000 - val_precision_2: 0.6839 - val_auc_2: 0.7347\n",
      "Epoch 64/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.9230 - accuracy: 0.5667 - recall_2: 0.3473 - true_negatives_2: 5364.0000 - false_positives_2: 516.0000 - precision_2: 0.6643 - auc_2: 0.7507 - val_loss: 0.9109 - val_accuracy: 0.5817 - val_recall_2: 0.3127 - val_true_negatives_2: 2370.0000 - val_false_positives_2: 150.0000 - val_precision_2: 0.7243 - val_auc_2: 0.7685\n",
      "Epoch 65/200\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.9457 - accuracy: 0.5398 - recall_2: 0.3384 - true_negatives_2: 5318.0000 - false_positives_2: 562.0000 - precision_2: 0.6390 - auc_2: 0.7317 - val_loss: 0.9219 - val_accuracy: 0.5619 - val_recall_2: 0.3603 - val_true_negatives_2: 2254.0000 - val_false_positives_2: 266.0000 - val_precision_2: 0.6306 - val_auc_2: 0.7507\n",
      "Epoch 66/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.9234 - accuracy: 0.5595 - recall_2: 0.3446 - true_negatives_2: 5345.0000 - false_positives_2: 535.0000 - precision_2: 0.6544 - auc_2: 0.7491 - val_loss: 0.9679 - val_accuracy: 0.4738 - val_recall_2: 0.3087 - val_true_negatives_2: 2270.0000 - val_false_positives_2: 250.0000 - val_precision_2: 0.6088 - val_auc_2: 0.7041\n",
      "Epoch 67/200\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.9263 - accuracy: 0.5575 - recall_2: 0.3490 - true_negatives_2: 5373.0000 - false_positives_2: 507.0000 - precision_2: 0.6693 - auc_2: 0.7466 - val_loss: 0.9055 - val_accuracy: 0.6000 - val_recall_2: 0.3405 - val_true_negatives_2: 2323.0000 - val_false_positives_2: 197.0000 - val_precision_2: 0.6853 - val_auc_2: 0.7676\n",
      "Epoch 68/200\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.9332 - accuracy: 0.5493 - recall_2: 0.3531 - true_negatives_2: 5316.0000 - false_positives_2: 564.0000 - precision_2: 0.6479 - auc_2: 0.7395 - val_loss: 0.9897 - val_accuracy: 0.4921 - val_recall_2: 0.3730 - val_true_negatives_2: 2139.0000 - val_false_positives_2: 381.0000 - val_precision_2: 0.5523 - val_auc_2: 0.7028\n",
      "Epoch 69/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.9439 - accuracy: 0.5388 - recall_2: 0.3544 - true_negatives_2: 5280.0000 - false_positives_2: 600.0000 - precision_2: 0.6346 - auc_2: 0.7293 - val_loss: 0.9417 - val_accuracy: 0.5230 - val_recall_2: 0.3222 - val_true_negatives_2: 2316.0000 - val_false_positives_2: 204.0000 - val_precision_2: 0.6656 - val_auc_2: 0.7287\n",
      "Epoch 70/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.9364 - accuracy: 0.5483 - recall_2: 0.3449 - true_negatives_2: 5329.0000 - false_positives_2: 551.0000 - precision_2: 0.6479 - auc_2: 0.7381 - val_loss: 0.9188 - val_accuracy: 0.5659 - val_recall_2: 0.3730 - val_true_negatives_2: 2240.0000 - val_false_positives_2: 280.0000 - val_precision_2: 0.6267 - val_auc_2: 0.7511\n",
      "Epoch 71/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.9324 - accuracy: 0.5483 - recall_2: 0.3667 - true_negatives_2: 5289.0000 - false_positives_2: 591.0000 - precision_2: 0.6459 - auc_2: 0.7398 - val_loss: 0.9575 - val_accuracy: 0.5254 - val_recall_2: 0.3770 - val_true_negatives_2: 2187.0000 - val_false_positives_2: 333.0000 - val_precision_2: 0.5879 - val_auc_2: 0.7233\n",
      "Epoch 72/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.9576 - accuracy: 0.5374 - recall_2: 0.3554 - true_negatives_2: 5237.0000 - false_positives_2: 643.0000 - precision_2: 0.6191 - auc_2: 0.7226 - val_loss: 0.9206 - val_accuracy: 0.5635 - val_recall_2: 0.3770 - val_true_negatives_2: 2243.0000 - val_false_positives_2: 277.0000 - val_precision_2: 0.6316 - val_auc_2: 0.7505\n",
      "Epoch 73/200\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.9275 - accuracy: 0.5575 - recall_2: 0.3670 - true_negatives_2: 5306.0000 - false_positives_2: 574.0000 - precision_2: 0.6528 - auc_2: 0.7460 - val_loss: 0.9052 - val_accuracy: 0.5889 - val_recall_2: 0.3468 - val_true_negatives_2: 2338.0000 - val_false_positives_2: 182.0000 - val_precision_2: 0.7060 - val_auc_2: 0.7674\n",
      "Epoch 74/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.9133 - accuracy: 0.5806 - recall_2: 0.3667 - true_negatives_2: 5345.0000 - false_positives_2: 535.0000 - precision_2: 0.6683 - auc_2: 0.7578 - val_loss: 0.8944 - val_accuracy: 0.5865 - val_recall_2: 0.3683 - val_true_negatives_2: 2289.0000 - val_false_positives_2: 231.0000 - val_precision_2: 0.6676 - val_auc_2: 0.7733\n",
      "Epoch 75/200\n",
      "49/49 [==============================] - 0s 9ms/step - loss: 0.9209 - accuracy: 0.5694 - recall_2: 0.3629 - true_negatives_2: 5303.0000 - false_positives_2: 577.0000 - precision_2: 0.6490 - auc_2: 0.7487 - val_loss: 0.9162 - val_accuracy: 0.5810 - val_recall_2: 0.3397 - val_true_negatives_2: 2319.0000 - val_false_positives_2: 201.0000 - val_precision_2: 0.6804 - val_auc_2: 0.7548\n",
      "Epoch 76/200\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.9100 - accuracy: 0.5728 - recall_2: 0.3646 - true_negatives_2: 5339.0000 - false_positives_2: 541.0000 - precision_2: 0.6646 - auc_2: 0.7593 - val_loss: 0.9003 - val_accuracy: 0.5929 - val_recall_2: 0.3754 - val_true_negatives_2: 2278.0000 - val_false_positives_2: 242.0000 - val_precision_2: 0.6615 - val_auc_2: 0.7680\n",
      "Epoch 77/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.9151 - accuracy: 0.5616 - recall_2: 0.3687 - true_negatives_2: 5298.0000 - false_positives_2: 582.0000 - precision_2: 0.6507 - auc_2: 0.7526 - val_loss: 0.8948 - val_accuracy: 0.5913 - val_recall_2: 0.3587 - val_true_negatives_2: 2329.0000 - val_false_positives_2: 191.0000 - val_precision_2: 0.7030 - val_auc_2: 0.7737\n",
      "Epoch 78/200\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.9153 - accuracy: 0.5728 - recall_2: 0.3731 - true_negatives_2: 5300.0000 - false_positives_2: 580.0000 - precision_2: 0.6541 - auc_2: 0.7539 - val_loss: 0.9184 - val_accuracy: 0.5651 - val_recall_2: 0.3992 - val_true_negatives_2: 2211.0000 - val_false_positives_2: 309.0000 - val_precision_2: 0.6195 - val_auc_2: 0.7503\n",
      "Epoch 79/200\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.9108 - accuracy: 0.5830 - recall_2: 0.3745 - true_negatives_2: 5339.0000 - false_positives_2: 541.0000 - precision_2: 0.6705 - auc_2: 0.7586 - val_loss: 0.8877 - val_accuracy: 0.6032 - val_recall_2: 0.3833 - val_true_negatives_2: 2287.0000 - val_false_positives_2: 233.0000 - val_precision_2: 0.6746 - val_auc_2: 0.7767\n",
      "Epoch 80/200\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.9444 - accuracy: 0.5432 - recall_2: 0.3752 - true_negatives_2: 5202.0000 - false_positives_2: 678.0000 - precision_2: 0.6193 - auc_2: 0.7329 - val_loss: 0.9102 - val_accuracy: 0.5786 - val_recall_2: 0.3817 - val_true_negatives_2: 2256.0000 - val_false_positives_2: 264.0000 - val_precision_2: 0.6456 - val_auc_2: 0.7583\n",
      "Epoch 81/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.9287 - accuracy: 0.5571 - recall_2: 0.3704 - true_negatives_2: 5276.0000 - false_positives_2: 604.0000 - precision_2: 0.6432 - auc_2: 0.7437 - val_loss: 0.9153 - val_accuracy: 0.5635 - val_recall_2: 0.3897 - val_true_negatives_2: 2237.0000 - val_false_positives_2: 283.0000 - val_precision_2: 0.6344 - val_auc_2: 0.7543\n",
      "Epoch 82/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.9427 - accuracy: 0.5350 - recall_2: 0.3769 - true_negatives_2: 5232.0000 - false_positives_2: 648.0000 - precision_2: 0.6310 - auc_2: 0.7325 - val_loss: 0.9024 - val_accuracy: 0.5770 - val_recall_2: 0.3873 - val_true_negatives_2: 2256.0000 - val_false_positives_2: 264.0000 - val_precision_2: 0.6489 - val_auc_2: 0.7631\n",
      "Epoch 83/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.8942 - accuracy: 0.5854 - recall_2: 0.3888 - true_negatives_2: 5327.0000 - false_positives_2: 553.0000 - precision_2: 0.6739 - auc_2: 0.7700 - val_loss: 0.9111 - val_accuracy: 0.5675 - val_recall_2: 0.3937 - val_true_negatives_2: 2232.0000 - val_false_positives_2: 288.0000 - val_precision_2: 0.6327 - val_auc_2: 0.7567\n",
      "Epoch 84/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.9257 - accuracy: 0.5456 - recall_2: 0.3847 - true_negatives_2: 5253.0000 - false_positives_2: 627.0000 - precision_2: 0.6433 - auc_2: 0.7442 - val_loss: 0.8839 - val_accuracy: 0.6008 - val_recall_2: 0.3484 - val_true_negatives_2: 2344.0000 - val_false_positives_2: 176.0000 - val_precision_2: 0.7138 - val_auc_2: 0.7863\n",
      "Epoch 85/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.8996 - accuracy: 0.5850 - recall_2: 0.3810 - true_negatives_2: 5350.0000 - false_positives_2: 530.0000 - precision_2: 0.6788 - auc_2: 0.7669 - val_loss: 0.9029 - val_accuracy: 0.5667 - val_recall_2: 0.3968 - val_true_negatives_2: 2223.0000 - val_false_positives_2: 297.0000 - val_precision_2: 0.6274 - val_auc_2: 0.7602\n",
      "Epoch 86/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.9257 - accuracy: 0.5497 - recall_2: 0.3864 - true_negatives_2: 5234.0000 - false_positives_2: 646.0000 - precision_2: 0.6375 - auc_2: 0.7440 - val_loss: 0.9439 - val_accuracy: 0.5238 - val_recall_2: 0.3476 - val_true_negatives_2: 2255.0000 - val_false_positives_2: 265.0000 - val_precision_2: 0.6230 - val_auc_2: 0.7263\n",
      "Epoch 87/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.9016 - accuracy: 0.5633 - recall_2: 0.3816 - true_negatives_2: 5317.0000 - false_positives_2: 563.0000 - precision_2: 0.6659 - auc_2: 0.7620 - val_loss: 0.9027 - val_accuracy: 0.5714 - val_recall_2: 0.4048 - val_true_negatives_2: 2241.0000 - val_false_positives_2: 279.0000 - val_precision_2: 0.6464 - val_auc_2: 0.7624\n",
      "Epoch 88/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.8969 - accuracy: 0.5847 - recall_2: 0.3898 - true_negatives_2: 5305.0000 - false_positives_2: 575.0000 - precision_2: 0.6659 - auc_2: 0.7674 - val_loss: 0.8809 - val_accuracy: 0.6024 - val_recall_2: 0.3976 - val_true_negatives_2: 2283.0000 - val_false_positives_2: 237.0000 - val_precision_2: 0.6789 - val_auc_2: 0.7809\n",
      "Epoch 89/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.9260 - accuracy: 0.5531 - recall_2: 0.3922 - true_negatives_2: 5202.0000 - false_positives_2: 678.0000 - precision_2: 0.6297 - auc_2: 0.7426 - val_loss: 0.9143 - val_accuracy: 0.5548 - val_recall_2: 0.3516 - val_true_negatives_2: 2306.0000 - val_false_positives_2: 214.0000 - val_precision_2: 0.6743 - val_auc_2: 0.7516\n",
      "Epoch 90/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.9097 - accuracy: 0.5684 - recall_2: 0.3969 - true_negatives_2: 5284.0000 - false_positives_2: 596.0000 - precision_2: 0.6619 - auc_2: 0.7569 - val_loss: 0.8857 - val_accuracy: 0.5881 - val_recall_2: 0.3746 - val_true_negatives_2: 2310.0000 - val_false_positives_2: 210.0000 - val_precision_2: 0.6921 - val_auc_2: 0.7779\n",
      "Epoch 91/200\n",
      "49/49 [==============================] - 0s 9ms/step - loss: 0.9394 - accuracy: 0.5401 - recall_2: 0.3799 - true_negatives_2: 5224.0000 - false_positives_2: 656.0000 - precision_2: 0.6300 - auc_2: 0.7338 - val_loss: 0.9074 - val_accuracy: 0.5587 - val_recall_2: 0.3484 - val_true_negatives_2: 2330.0000 - val_false_positives_2: 190.0000 - val_precision_2: 0.6979 - val_auc_2: 0.7583\n",
      "Epoch 92/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.8908 - accuracy: 0.5833 - recall_2: 0.3912 - true_negatives_2: 5315.0000 - false_positives_2: 565.0000 - precision_2: 0.6706 - auc_2: 0.7708 - val_loss: 0.8881 - val_accuracy: 0.5921 - val_recall_2: 0.3667 - val_true_negatives_2: 2317.0000 - val_false_positives_2: 203.0000 - val_precision_2: 0.6947 - val_auc_2: 0.7755\n",
      "Epoch 93/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.8999 - accuracy: 0.5690 - recall_2: 0.3990 - true_negatives_2: 5276.0000 - false_positives_2: 604.0000 - precision_2: 0.6601 - auc_2: 0.7612 - val_loss: 0.9015 - val_accuracy: 0.5714 - val_recall_2: 0.4135 - val_true_negatives_2: 2213.0000 - val_false_positives_2: 307.0000 - val_precision_2: 0.6292 - val_auc_2: 0.7612\n",
      "Epoch 94/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.9374 - accuracy: 0.5432 - recall_2: 0.3861 - true_negatives_2: 5237.0000 - false_positives_2: 643.0000 - precision_2: 0.6384 - auc_2: 0.7385 - val_loss: 0.8974 - val_accuracy: 0.5849 - val_recall_2: 0.3516 - val_true_negatives_2: 2345.0000 - val_false_positives_2: 175.0000 - val_precision_2: 0.7168 - val_auc_2: 0.7693\n",
      "Epoch 95/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.9086 - accuracy: 0.5738 - recall_2: 0.3867 - true_negatives_2: 5276.0000 - false_positives_2: 604.0000 - precision_2: 0.6531 - auc_2: 0.7571 - val_loss: 0.8784 - val_accuracy: 0.6000 - val_recall_2: 0.3984 - val_true_negatives_2: 2306.0000 - val_false_positives_2: 214.0000 - val_precision_2: 0.7011 - val_auc_2: 0.7827\n",
      "Epoch 96/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.8839 - accuracy: 0.5867 - recall_2: 0.4007 - true_negatives_2: 5350.0000 - false_positives_2: 530.0000 - precision_2: 0.6897 - auc_2: 0.7760 - val_loss: 0.8820 - val_accuracy: 0.5960 - val_recall_2: 0.3794 - val_true_negatives_2: 2313.0000 - val_false_positives_2: 207.0000 - val_precision_2: 0.6978 - val_auc_2: 0.7786\n",
      "Epoch 97/200\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.9001 - accuracy: 0.5772 - recall_2: 0.4007 - true_negatives_2: 5271.0000 - false_positives_2: 609.0000 - precision_2: 0.6592 - auc_2: 0.7630 - val_loss: 0.8820 - val_accuracy: 0.5706 - val_recall_2: 0.4238 - val_true_negatives_2: 2238.0000 - val_false_positives_2: 282.0000 - val_precision_2: 0.6544 - val_auc_2: 0.7752\n",
      "Epoch 98/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.8795 - accuracy: 0.5939 - recall_2: 0.4133 - true_negatives_2: 5313.0000 - false_positives_2: 567.0000 - precision_2: 0.6818 - auc_2: 0.7787 - val_loss: 0.8778 - val_accuracy: 0.5992 - val_recall_2: 0.4159 - val_true_negatives_2: 2278.0000 - val_false_positives_2: 242.0000 - val_precision_2: 0.6841 - val_auc_2: 0.7816\n",
      "Epoch 99/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.8929 - accuracy: 0.5765 - recall_2: 0.4027 - true_negatives_2: 5249.0000 - false_positives_2: 631.0000 - precision_2: 0.6523 - auc_2: 0.7661 - val_loss: 0.8889 - val_accuracy: 0.5881 - val_recall_2: 0.3730 - val_true_negatives_2: 2306.0000 - val_false_positives_2: 214.0000 - val_precision_2: 0.6871 - val_auc_2: 0.7726\n",
      "Epoch 100/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.9077 - accuracy: 0.5673 - recall_2: 0.4010 - true_negatives_2: 5221.0000 - false_positives_2: 659.0000 - precision_2: 0.6415 - auc_2: 0.7564 - val_loss: 0.8652 - val_accuracy: 0.6079 - val_recall_2: 0.4048 - val_true_negatives_2: 2308.0000 - val_false_positives_2: 212.0000 - val_precision_2: 0.7064 - val_auc_2: 0.7939\n",
      "Epoch 101/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.8823 - accuracy: 0.5776 - recall_2: 0.3980 - true_negatives_2: 5329.0000 - false_positives_2: 551.0000 - precision_2: 0.6798 - auc_2: 0.7754 - val_loss: 0.8729 - val_accuracy: 0.5849 - val_recall_2: 0.4063 - val_true_negatives_2: 2292.0000 - val_false_positives_2: 228.0000 - val_precision_2: 0.6919 - val_auc_2: 0.7840\n",
      "Epoch 102/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.8904 - accuracy: 0.5755 - recall_2: 0.4037 - true_negatives_2: 5270.0000 - false_positives_2: 610.0000 - precision_2: 0.6605 - auc_2: 0.7697 - val_loss: 0.9027 - val_accuracy: 0.5714 - val_recall_2: 0.4317 - val_true_negatives_2: 2214.0000 - val_false_positives_2: 306.0000 - val_precision_2: 0.6400 - val_auc_2: 0.7605\n",
      "Epoch 103/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.8826 - accuracy: 0.5861 - recall_2: 0.4014 - true_negatives_2: 5274.0000 - false_positives_2: 606.0000 - precision_2: 0.6607 - auc_2: 0.7742 - val_loss: 0.8675 - val_accuracy: 0.6071 - val_recall_2: 0.3984 - val_true_negatives_2: 2313.0000 - val_false_positives_2: 207.0000 - val_precision_2: 0.7080 - val_auc_2: 0.7918\n",
      "Epoch 104/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.9043 - accuracy: 0.5782 - recall_2: 0.4207 - true_negatives_2: 5215.0000 - false_positives_2: 665.0000 - precision_2: 0.6504 - auc_2: 0.7612 - val_loss: 0.9780 - val_accuracy: 0.5111 - val_recall_2: 0.3984 - val_true_negatives_2: 2116.0000 - val_false_positives_2: 404.0000 - val_precision_2: 0.5541 - val_auc_2: 0.7175\n",
      "Epoch 105/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.9197 - accuracy: 0.5592 - recall_2: 0.3997 - true_negatives_2: 5187.0000 - false_positives_2: 693.0000 - precision_2: 0.6290 - auc_2: 0.7499 - val_loss: 0.8687 - val_accuracy: 0.6016 - val_recall_2: 0.4024 - val_true_negatives_2: 2294.0000 - val_false_positives_2: 226.0000 - val_precision_2: 0.6917 - val_auc_2: 0.7871\n",
      "Epoch 106/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.8767 - accuracy: 0.5922 - recall_2: 0.4058 - true_negatives_2: 5307.0000 - false_positives_2: 573.0000 - precision_2: 0.6755 - auc_2: 0.7786 - val_loss: 0.8874 - val_accuracy: 0.5778 - val_recall_2: 0.4270 - val_true_negatives_2: 2215.0000 - val_false_positives_2: 305.0000 - val_precision_2: 0.6382 - val_auc_2: 0.7693\n",
      "Epoch 107/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.8871 - accuracy: 0.5810 - recall_2: 0.4184 - true_negatives_2: 5234.0000 - false_positives_2: 646.0000 - precision_2: 0.6557 - auc_2: 0.7696 - val_loss: 0.8751 - val_accuracy: 0.5952 - val_recall_2: 0.4183 - val_true_negatives_2: 2263.0000 - val_false_positives_2: 257.0000 - val_precision_2: 0.6722 - val_auc_2: 0.7803\n",
      "Epoch 108/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.9160 - accuracy: 0.5524 - recall_2: 0.4058 - true_negatives_2: 5187.0000 - false_positives_2: 693.0000 - precision_2: 0.6326 - auc_2: 0.7501 - val_loss: 0.8825 - val_accuracy: 0.5929 - val_recall_2: 0.3746 - val_true_negatives_2: 2309.0000 - val_false_positives_2: 211.0000 - val_precision_2: 0.6911 - val_auc_2: 0.7774\n",
      "Epoch 109/200\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.8941 - accuracy: 0.5820 - recall_2: 0.4027 - true_negatives_2: 5246.0000 - false_positives_2: 634.0000 - precision_2: 0.6513 - auc_2: 0.7667 - val_loss: 0.8821 - val_accuracy: 0.5992 - val_recall_2: 0.3659 - val_true_negatives_2: 2324.0000 - val_false_positives_2: 196.0000 - val_precision_2: 0.7017 - val_auc_2: 0.7788\n",
      "Epoch 110/200\n",
      "49/49 [==============================] - 0s 9ms/step - loss: 0.8834 - accuracy: 0.5844 - recall_2: 0.4150 - true_negatives_2: 5276.0000 - false_positives_2: 604.0000 - precision_2: 0.6689 - auc_2: 0.7729 - val_loss: 0.8604 - val_accuracy: 0.6000 - val_recall_2: 0.4079 - val_true_negatives_2: 2287.0000 - val_false_positives_2: 233.0000 - val_precision_2: 0.6881 - val_auc_2: 0.7930\n",
      "Epoch 111/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.8862 - accuracy: 0.5850 - recall_2: 0.4221 - true_negatives_2: 5280.0000 - false_positives_2: 600.0000 - precision_2: 0.6741 - auc_2: 0.7732 - val_loss: 0.8556 - val_accuracy: 0.6024 - val_recall_2: 0.4206 - val_true_negatives_2: 2293.0000 - val_false_positives_2: 227.0000 - val_precision_2: 0.7001 - val_auc_2: 0.7967\n",
      "Epoch 112/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.8846 - accuracy: 0.5793 - recall_2: 0.4262 - true_negatives_2: 5252.0000 - false_positives_2: 628.0000 - precision_2: 0.6661 - auc_2: 0.7724 - val_loss: 0.8542 - val_accuracy: 0.6056 - val_recall_2: 0.4254 - val_true_negatives_2: 2283.0000 - val_false_positives_2: 237.0000 - val_precision_2: 0.6934 - val_auc_2: 0.7976\n",
      "Epoch 113/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.8696 - accuracy: 0.5918 - recall_2: 0.4265 - true_negatives_2: 5291.0000 - false_positives_2: 589.0000 - precision_2: 0.6804 - auc_2: 0.7822 - val_loss: 0.8854 - val_accuracy: 0.5873 - val_recall_2: 0.3817 - val_true_negatives_2: 2293.0000 - val_false_positives_2: 227.0000 - val_precision_2: 0.6794 - val_auc_2: 0.7726\n",
      "Epoch 114/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.8956 - accuracy: 0.5667 - recall_2: 0.4167 - true_negatives_2: 5237.0000 - false_positives_2: 643.0000 - precision_2: 0.6558 - auc_2: 0.7638 - val_loss: 0.9892 - val_accuracy: 0.4754 - val_recall_2: 0.3532 - val_true_negatives_2: 2172.0000 - val_false_positives_2: 348.0000 - val_precision_2: 0.5612 - val_auc_2: 0.6981\n",
      "Epoch 115/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.9034 - accuracy: 0.5741 - recall_2: 0.4129 - true_negatives_2: 5201.0000 - false_positives_2: 679.0000 - precision_2: 0.6413 - auc_2: 0.7590 - val_loss: 0.8559 - val_accuracy: 0.6095 - val_recall_2: 0.4373 - val_true_negatives_2: 2263.0000 - val_false_positives_2: 257.0000 - val_precision_2: 0.6819 - val_auc_2: 0.7935\n",
      "Epoch 116/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.8739 - accuracy: 0.5847 - recall_2: 0.4160 - true_negatives_2: 5245.0000 - false_positives_2: 635.0000 - precision_2: 0.6582 - auc_2: 0.7791 - val_loss: 0.8921 - val_accuracy: 0.5802 - val_recall_2: 0.4524 - val_true_negatives_2: 2190.0000 - val_false_positives_2: 330.0000 - val_precision_2: 0.6333 - val_auc_2: 0.7667\n",
      "Epoch 117/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.9208 - accuracy: 0.5507 - recall_2: 0.4054 - true_negatives_2: 5163.0000 - false_positives_2: 717.0000 - precision_2: 0.6244 - auc_2: 0.7490 - val_loss: 0.9215 - val_accuracy: 0.5452 - val_recall_2: 0.3810 - val_true_negatives_2: 2257.0000 - val_false_positives_2: 263.0000 - val_precision_2: 0.6460 - val_auc_2: 0.7437\n",
      "Epoch 118/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.8698 - accuracy: 0.5861 - recall_2: 0.4211 - true_negatives_2: 5280.0000 - false_positives_2: 600.0000 - precision_2: 0.6736 - auc_2: 0.7823 - val_loss: 0.8509 - val_accuracy: 0.6063 - val_recall_2: 0.4143 - val_true_negatives_2: 2305.0000 - val_false_positives_2: 215.0000 - val_precision_2: 0.7083 - val_auc_2: 0.8016\n",
      "Epoch 119/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.8745 - accuracy: 0.5905 - recall_2: 0.4296 - true_negatives_2: 5263.0000 - false_positives_2: 617.0000 - precision_2: 0.6718 - auc_2: 0.7780 - val_loss: 0.8727 - val_accuracy: 0.5944 - val_recall_2: 0.3857 - val_true_negatives_2: 2307.0000 - val_false_positives_2: 213.0000 - val_precision_2: 0.6953 - val_auc_2: 0.7826\n",
      "Epoch 120/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.8798 - accuracy: 0.5891 - recall_2: 0.4272 - true_negatives_2: 5266.0000 - false_positives_2: 614.0000 - precision_2: 0.6717 - auc_2: 0.7759 - val_loss: 0.8770 - val_accuracy: 0.5944 - val_recall_2: 0.4516 - val_true_negatives_2: 2230.0000 - val_false_positives_2: 290.0000 - val_precision_2: 0.6624 - val_auc_2: 0.7772\n",
      "Epoch 121/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.9010 - accuracy: 0.5724 - recall_2: 0.4265 - true_negatives_2: 5192.0000 - false_positives_2: 688.0000 - precision_2: 0.6457 - auc_2: 0.7618 - val_loss: 0.9881 - val_accuracy: 0.5270 - val_recall_2: 0.4167 - val_true_negatives_2: 2085.0000 - val_false_positives_2: 435.0000 - val_precision_2: 0.5469 - val_auc_2: 0.7245\n",
      "Epoch 122/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.8682 - accuracy: 0.5973 - recall_2: 0.4374 - true_negatives_2: 5260.0000 - false_positives_2: 620.0000 - precision_2: 0.6747 - auc_2: 0.7840 - val_loss: 0.8661 - val_accuracy: 0.6040 - val_recall_2: 0.4167 - val_true_negatives_2: 2270.0000 - val_false_positives_2: 250.0000 - val_precision_2: 0.6774 - val_auc_2: 0.7860\n",
      "Epoch 123/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.9194 - accuracy: 0.5592 - recall_2: 0.4150 - true_negatives_2: 5156.0000 - false_positives_2: 724.0000 - precision_2: 0.6276 - auc_2: 0.7495 - val_loss: 0.9801 - val_accuracy: 0.5190 - val_recall_2: 0.4119 - val_true_negatives_2: 2085.0000 - val_false_positives_2: 435.0000 - val_precision_2: 0.5440 - val_auc_2: 0.7248\n",
      "Epoch 124/200\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.8718 - accuracy: 0.5915 - recall_2: 0.4221 - true_negatives_2: 5275.0000 - false_positives_2: 605.0000 - precision_2: 0.6723 - auc_2: 0.7816 - val_loss: 0.8513 - val_accuracy: 0.6175 - val_recall_2: 0.4016 - val_true_negatives_2: 2297.0000 - val_false_positives_2: 223.0000 - val_precision_2: 0.6941 - val_auc_2: 0.8005\n",
      "Epoch 125/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.8647 - accuracy: 0.5918 - recall_2: 0.4367 - true_negatives_2: 5225.0000 - false_positives_2: 655.0000 - precision_2: 0.6622 - auc_2: 0.7851 - val_loss: 0.9155 - val_accuracy: 0.5500 - val_recall_2: 0.3968 - val_true_negatives_2: 2223.0000 - val_false_positives_2: 297.0000 - val_precision_2: 0.6274 - val_auc_2: 0.7479\n",
      "Epoch 126/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.8775 - accuracy: 0.5929 - recall_2: 0.4354 - true_negatives_2: 5269.0000 - false_positives_2: 611.0000 - precision_2: 0.6769 - auc_2: 0.7780 - val_loss: 0.8412 - val_accuracy: 0.6087 - val_recall_2: 0.4429 - val_true_negatives_2: 2269.0000 - val_false_positives_2: 251.0000 - val_precision_2: 0.6897 - val_auc_2: 0.8028\n",
      "Epoch 127/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.8520 - accuracy: 0.6109 - recall_2: 0.4497 - true_negatives_2: 5275.0000 - false_positives_2: 605.0000 - precision_2: 0.6860 - auc_2: 0.7934 - val_loss: 0.8498 - val_accuracy: 0.6159 - val_recall_2: 0.4071 - val_true_negatives_2: 2287.0000 - val_false_positives_2: 233.0000 - val_precision_2: 0.6877 - val_auc_2: 0.8002\n",
      "Epoch 128/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.8526 - accuracy: 0.6085 - recall_2: 0.4490 - true_negatives_2: 5280.0000 - false_positives_2: 600.0000 - precision_2: 0.6875 - auc_2: 0.7946 - val_loss: 0.8407 - val_accuracy: 0.6079 - val_recall_2: 0.4563 - val_true_negatives_2: 2264.0000 - val_false_positives_2: 256.0000 - val_precision_2: 0.6919 - val_auc_2: 0.8031\n",
      "Epoch 129/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.8709 - accuracy: 0.5895 - recall_2: 0.4316 - true_negatives_2: 5241.0000 - false_positives_2: 639.0000 - precision_2: 0.6651 - auc_2: 0.7811 - val_loss: 0.8533 - val_accuracy: 0.6095 - val_recall_2: 0.4492 - val_true_negatives_2: 2244.0000 - val_false_positives_2: 276.0000 - val_precision_2: 0.6722 - val_auc_2: 0.7925\n",
      "Epoch 130/200\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.8616 - accuracy: 0.5990 - recall_2: 0.4565 - true_negatives_2: 5252.0000 - false_positives_2: 628.0000 - precision_2: 0.6812 - auc_2: 0.7865 - val_loss: 0.8697 - val_accuracy: 0.5905 - val_recall_2: 0.4230 - val_true_negatives_2: 2276.0000 - val_false_positives_2: 244.0000 - val_precision_2: 0.6860 - val_auc_2: 0.7825\n",
      "Epoch 131/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.8714 - accuracy: 0.5942 - recall_2: 0.4405 - true_negatives_2: 5232.0000 - false_positives_2: 648.0000 - precision_2: 0.6665 - auc_2: 0.7788 - val_loss: 0.9647 - val_accuracy: 0.5341 - val_recall_2: 0.4508 - val_true_negatives_2: 2111.0000 - val_false_positives_2: 409.0000 - val_precision_2: 0.5814 - val_auc_2: 0.7322\n",
      "Epoch 132/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.8797 - accuracy: 0.5840 - recall_2: 0.4293 - true_negatives_2: 5235.0000 - false_positives_2: 645.0000 - precision_2: 0.6618 - auc_2: 0.7762 - val_loss: 0.8588 - val_accuracy: 0.5976 - val_recall_2: 0.4619 - val_true_negatives_2: 2227.0000 - val_false_positives_2: 293.0000 - val_precision_2: 0.6651 - val_auc_2: 0.7887\n",
      "Epoch 133/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.8599 - accuracy: 0.6041 - recall_2: 0.4565 - true_negatives_2: 5251.0000 - false_positives_2: 629.0000 - precision_2: 0.6809 - auc_2: 0.7884 - val_loss: 0.8534 - val_accuracy: 0.6087 - val_recall_2: 0.4571 - val_true_negatives_2: 2253.0000 - val_false_positives_2: 267.0000 - val_precision_2: 0.6833 - val_auc_2: 0.7931\n",
      "Epoch 134/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.8617 - accuracy: 0.5976 - recall_2: 0.4418 - true_negatives_2: 5256.0000 - false_positives_2: 624.0000 - precision_2: 0.6755 - auc_2: 0.7867 - val_loss: 0.8666 - val_accuracy: 0.5929 - val_recall_2: 0.4746 - val_true_negatives_2: 2205.0000 - val_false_positives_2: 315.0000 - val_precision_2: 0.6550 - val_auc_2: 0.7821\n",
      "Epoch 135/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.8654 - accuracy: 0.5871 - recall_2: 0.4439 - true_negatives_2: 5220.0000 - false_positives_2: 660.0000 - precision_2: 0.6641 - auc_2: 0.7824 - val_loss: 0.8524 - val_accuracy: 0.6008 - val_recall_2: 0.4325 - val_true_negatives_2: 2264.0000 - val_false_positives_2: 256.0000 - val_precision_2: 0.6804 - val_auc_2: 0.7942\n",
      "Epoch 136/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.8568 - accuracy: 0.6027 - recall_2: 0.4548 - true_negatives_2: 5241.0000 - false_positives_2: 639.0000 - precision_2: 0.6766 - auc_2: 0.7892 - val_loss: 0.8330 - val_accuracy: 0.6222 - val_recall_2: 0.4389 - val_true_negatives_2: 2265.0000 - val_false_positives_2: 255.0000 - val_precision_2: 0.6844 - val_auc_2: 0.8064\n",
      "Epoch 137/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.8733 - accuracy: 0.5871 - recall_2: 0.4412 - true_negatives_2: 5224.0000 - false_positives_2: 656.0000 - precision_2: 0.6641 - auc_2: 0.7782 - val_loss: 0.8360 - val_accuracy: 0.6151 - val_recall_2: 0.4667 - val_true_negatives_2: 2255.0000 - val_false_positives_2: 265.0000 - val_precision_2: 0.6893 - val_auc_2: 0.8032\n",
      "Epoch 138/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.8551 - accuracy: 0.6007 - recall_2: 0.4442 - true_negatives_2: 5276.0000 - false_positives_2: 604.0000 - precision_2: 0.6838 - auc_2: 0.7917 - val_loss: 0.8515 - val_accuracy: 0.5968 - val_recall_2: 0.4373 - val_true_negatives_2: 2276.0000 - val_false_positives_2: 244.0000 - val_precision_2: 0.6931 - val_auc_2: 0.7940\n",
      "Epoch 139/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.8609 - accuracy: 0.6014 - recall_2: 0.4466 - true_negatives_2: 5236.0000 - false_positives_2: 644.0000 - precision_2: 0.6709 - auc_2: 0.7859 - val_loss: 0.8849 - val_accuracy: 0.5627 - val_recall_2: 0.3817 - val_true_negatives_2: 2287.0000 - val_false_positives_2: 233.0000 - val_precision_2: 0.6737 - val_auc_2: 0.7690\n",
      "Epoch 140/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.8635 - accuracy: 0.5891 - recall_2: 0.4571 - true_negatives_2: 5171.0000 - false_positives_2: 709.0000 - precision_2: 0.6547 - auc_2: 0.7831 - val_loss: 0.8393 - val_accuracy: 0.6024 - val_recall_2: 0.4563 - val_true_negatives_2: 2259.0000 - val_false_positives_2: 261.0000 - val_precision_2: 0.6878 - val_auc_2: 0.8023\n",
      "Epoch 141/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.8685 - accuracy: 0.5915 - recall_2: 0.4296 - true_negatives_2: 5245.0000 - false_positives_2: 635.0000 - precision_2: 0.6654 - auc_2: 0.7807 - val_loss: 0.8377 - val_accuracy: 0.6143 - val_recall_2: 0.4484 - val_true_negatives_2: 2284.0000 - val_false_positives_2: 236.0000 - val_precision_2: 0.7054 - val_auc_2: 0.8051\n",
      "Epoch 142/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.8488 - accuracy: 0.6007 - recall_2: 0.4667 - true_negatives_2: 5235.0000 - false_positives_2: 645.0000 - precision_2: 0.6802 - auc_2: 0.7933 - val_loss: 0.9549 - val_accuracy: 0.5524 - val_recall_2: 0.4683 - val_true_negatives_2: 2118.0000 - val_false_positives_2: 402.0000 - val_precision_2: 0.5948 - val_auc_2: 0.7392\n",
      "Epoch 143/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.8836 - accuracy: 0.5891 - recall_2: 0.4486 - true_negatives_2: 5203.0000 - false_positives_2: 677.0000 - precision_2: 0.6608 - auc_2: 0.7735 - val_loss: 0.8675 - val_accuracy: 0.5857 - val_recall_2: 0.4706 - val_true_negatives_2: 2204.0000 - val_false_positives_2: 316.0000 - val_precision_2: 0.6524 - val_auc_2: 0.7811\n",
      "Epoch 144/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.8394 - accuracy: 0.6153 - recall_2: 0.4514 - true_negatives_2: 5277.0000 - false_positives_2: 603.0000 - precision_2: 0.6876 - auc_2: 0.8007 - val_loss: 0.8362 - val_accuracy: 0.6095 - val_recall_2: 0.4675 - val_true_negatives_2: 2234.0000 - val_false_positives_2: 286.0000 - val_precision_2: 0.6731 - val_auc_2: 0.8012\n",
      "Epoch 145/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.8464 - accuracy: 0.6095 - recall_2: 0.4690 - true_negatives_2: 5234.0000 - false_positives_2: 646.0000 - precision_2: 0.6810 - auc_2: 0.7955 - val_loss: 0.9104 - val_accuracy: 0.5476 - val_recall_2: 0.4103 - val_true_negatives_2: 2221.0000 - val_false_positives_2: 299.0000 - val_precision_2: 0.6336 - val_auc_2: 0.7513\n",
      "Epoch 146/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.8765 - accuracy: 0.5864 - recall_2: 0.4537 - true_negatives_2: 5160.0000 - false_positives_2: 720.0000 - precision_2: 0.6495 - auc_2: 0.7756 - val_loss: 0.8516 - val_accuracy: 0.6071 - val_recall_2: 0.4746 - val_true_negatives_2: 2218.0000 - val_false_positives_2: 302.0000 - val_precision_2: 0.6644 - val_auc_2: 0.7912\n",
      "Epoch 147/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.8592 - accuracy: 0.5986 - recall_2: 0.4687 - true_negatives_2: 5226.0000 - false_positives_2: 654.0000 - precision_2: 0.6781 - auc_2: 0.7880 - val_loss: 0.8746 - val_accuracy: 0.5794 - val_recall_2: 0.4722 - val_true_negatives_2: 2190.0000 - val_false_positives_2: 330.0000 - val_precision_2: 0.6432 - val_auc_2: 0.7766\n",
      "Epoch 148/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.8788 - accuracy: 0.5762 - recall_2: 0.4456 - true_negatives_2: 5190.0000 - false_positives_2: 690.0000 - precision_2: 0.6550 - auc_2: 0.7752 - val_loss: 0.8266 - val_accuracy: 0.6151 - val_recall_2: 0.4532 - val_true_negatives_2: 2264.0000 - val_false_positives_2: 256.0000 - val_precision_2: 0.6904 - val_auc_2: 0.8087\n",
      "Epoch 149/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.8603 - accuracy: 0.5864 - recall_2: 0.4541 - true_negatives_2: 5220.0000 - false_positives_2: 660.0000 - precision_2: 0.6692 - auc_2: 0.7842 - val_loss: 0.9511 - val_accuracy: 0.5294 - val_recall_2: 0.4278 - val_true_negatives_2: 2117.0000 - val_false_positives_2: 403.0000 - val_precision_2: 0.5722 - val_auc_2: 0.7375\n",
      "Epoch 150/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.8515 - accuracy: 0.5966 - recall_2: 0.4585 - true_negatives_2: 5233.0000 - false_positives_2: 647.0000 - precision_2: 0.6757 - auc_2: 0.7906 - val_loss: 0.8229 - val_accuracy: 0.6214 - val_recall_2: 0.4722 - val_true_negatives_2: 2252.0000 - val_false_positives_2: 268.0000 - val_precision_2: 0.6895 - val_auc_2: 0.8116\n",
      "Epoch 151/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.8413 - accuracy: 0.6085 - recall_2: 0.4636 - true_negatives_2: 5273.0000 - false_positives_2: 607.0000 - precision_2: 0.6919 - auc_2: 0.7977 - val_loss: 0.9290 - val_accuracy: 0.5222 - val_recall_2: 0.3905 - val_true_negatives_2: 2212.0000 - val_false_positives_2: 308.0000 - val_precision_2: 0.6150 - val_auc_2: 0.7380\n",
      "Epoch 152/200\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.8594 - accuracy: 0.5929 - recall_2: 0.4575 - true_negatives_2: 5206.0000 - false_positives_2: 674.0000 - precision_2: 0.6662 - auc_2: 0.7874 - val_loss: 0.8243 - val_accuracy: 0.6214 - val_recall_2: 0.4500 - val_true_negatives_2: 2283.0000 - val_false_positives_2: 237.0000 - val_precision_2: 0.7052 - val_auc_2: 0.8128\n",
      "Epoch 153/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.8531 - accuracy: 0.6027 - recall_2: 0.4633 - true_negatives_2: 5232.0000 - false_positives_2: 648.0000 - precision_2: 0.6776 - auc_2: 0.7913 - val_loss: 0.8873 - val_accuracy: 0.5825 - val_recall_2: 0.4905 - val_true_negatives_2: 2167.0000 - val_false_positives_2: 353.0000 - val_precision_2: 0.6365 - val_auc_2: 0.7710\n",
      "Epoch 154/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.8603 - accuracy: 0.6048 - recall_2: 0.4789 - true_negatives_2: 5166.0000 - false_positives_2: 714.0000 - precision_2: 0.6635 - auc_2: 0.7864 - val_loss: 0.8245 - val_accuracy: 0.6365 - val_recall_2: 0.4381 - val_true_negatives_2: 2305.0000 - val_false_positives_2: 215.0000 - val_precision_2: 0.7197 - val_auc_2: 0.8146\n",
      "Epoch 155/200\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.8419 - accuracy: 0.6099 - recall_2: 0.4687 - true_negatives_2: 5251.0000 - false_positives_2: 629.0000 - precision_2: 0.6866 - auc_2: 0.7988 - val_loss: 0.8566 - val_accuracy: 0.5960 - val_recall_2: 0.4119 - val_true_negatives_2: 2290.0000 - val_false_positives_2: 230.0000 - val_precision_2: 0.6929 - val_auc_2: 0.7902\n",
      "Epoch 156/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.8836 - accuracy: 0.5738 - recall_2: 0.4384 - true_negatives_2: 5209.0000 - false_positives_2: 671.0000 - precision_2: 0.6577 - auc_2: 0.7703 - val_loss: 0.9120 - val_accuracy: 0.5563 - val_recall_2: 0.4389 - val_true_negatives_2: 2159.0000 - val_false_positives_2: 361.0000 - val_precision_2: 0.6050 - val_auc_2: 0.7548\n",
      "Epoch 157/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.8586 - accuracy: 0.5997 - recall_2: 0.4537 - true_negatives_2: 5217.0000 - false_positives_2: 663.0000 - precision_2: 0.6680 - auc_2: 0.7864 - val_loss: 1.0363 - val_accuracy: 0.4659 - val_recall_2: 0.3683 - val_true_negatives_2: 2078.0000 - val_false_positives_2: 442.0000 - val_precision_2: 0.5121 - val_auc_2: 0.6892\n",
      "Epoch 158/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.8453 - accuracy: 0.6126 - recall_2: 0.4656 - true_negatives_2: 5209.0000 - false_positives_2: 671.0000 - precision_2: 0.6711 - auc_2: 0.7955 - val_loss: 0.8429 - val_accuracy: 0.6103 - val_recall_2: 0.4897 - val_true_negatives_2: 2224.0000 - val_false_positives_2: 296.0000 - val_precision_2: 0.6758 - val_auc_2: 0.7963\n",
      "Epoch 159/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.8321 - accuracy: 0.6184 - recall_2: 0.4796 - true_negatives_2: 5237.0000 - false_positives_2: 643.0000 - precision_2: 0.6868 - auc_2: 0.8023 - val_loss: 0.8227 - val_accuracy: 0.6175 - val_recall_2: 0.4698 - val_true_negatives_2: 2268.0000 - val_false_positives_2: 252.0000 - val_precision_2: 0.7014 - val_auc_2: 0.8125\n",
      "Epoch 160/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.8307 - accuracy: 0.6259 - recall_2: 0.4765 - true_negatives_2: 5273.0000 - false_positives_2: 607.0000 - precision_2: 0.6977 - auc_2: 0.8058 - val_loss: 0.8929 - val_accuracy: 0.5778 - val_recall_2: 0.4960 - val_true_negatives_2: 2161.0000 - val_false_positives_2: 359.0000 - val_precision_2: 0.6352 - val_auc_2: 0.7689\n",
      "Epoch 161/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.8730 - accuracy: 0.5912 - recall_2: 0.4619 - true_negatives_2: 5160.0000 - false_positives_2: 720.0000 - precision_2: 0.6535 - auc_2: 0.7791 - val_loss: 0.8521 - val_accuracy: 0.6008 - val_recall_2: 0.4921 - val_true_negatives_2: 2208.0000 - val_false_positives_2: 312.0000 - val_precision_2: 0.6652 - val_auc_2: 0.7899\n",
      "Epoch 162/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.8414 - accuracy: 0.6051 - recall_2: 0.4592 - true_negatives_2: 5235.0000 - false_positives_2: 645.0000 - precision_2: 0.6767 - auc_2: 0.7971 - val_loss: 0.8944 - val_accuracy: 0.5706 - val_recall_2: 0.4754 - val_true_negatives_2: 2157.0000 - val_false_positives_2: 363.0000 - val_precision_2: 0.6227 - val_auc_2: 0.7662\n",
      "Epoch 163/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.8503 - accuracy: 0.6003 - recall_2: 0.4697 - true_negatives_2: 5192.0000 - false_positives_2: 688.0000 - precision_2: 0.6675 - auc_2: 0.7907 - val_loss: 0.8141 - val_accuracy: 0.6262 - val_recall_2: 0.4524 - val_true_negatives_2: 2282.0000 - val_false_positives_2: 238.0000 - val_precision_2: 0.7054 - val_auc_2: 0.8183\n",
      "Epoch 164/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.8458 - accuracy: 0.5980 - recall_2: 0.4609 - true_negatives_2: 5210.0000 - false_positives_2: 670.0000 - precision_2: 0.6691 - auc_2: 0.7936 - val_loss: 0.8199 - val_accuracy: 0.6262 - val_recall_2: 0.4754 - val_true_negatives_2: 2248.0000 - val_false_positives_2: 272.0000 - val_precision_2: 0.6877 - val_auc_2: 0.8108\n",
      "Epoch 165/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.8513 - accuracy: 0.6003 - recall_2: 0.4636 - true_negatives_2: 5205.0000 - false_positives_2: 675.0000 - precision_2: 0.6688 - auc_2: 0.7906 - val_loss: 0.8719 - val_accuracy: 0.5849 - val_recall_2: 0.4921 - val_true_negatives_2: 2190.0000 - val_false_positives_2: 330.0000 - val_precision_2: 0.6526 - val_auc_2: 0.7792\n",
      "Epoch 166/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.8596 - accuracy: 0.5935 - recall_2: 0.4619 - true_negatives_2: 5157.0000 - false_positives_2: 723.0000 - precision_2: 0.6526 - auc_2: 0.7839 - val_loss: 0.8300 - val_accuracy: 0.6159 - val_recall_2: 0.4333 - val_true_negatives_2: 2309.0000 - val_false_positives_2: 211.0000 - val_precision_2: 0.7213 - val_auc_2: 0.8089\n",
      "Epoch 167/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.8361 - accuracy: 0.6184 - recall_2: 0.4446 - true_negatives_2: 5307.0000 - false_positives_2: 573.0000 - precision_2: 0.6952 - auc_2: 0.8023 - val_loss: 0.8183 - val_accuracy: 0.6357 - val_recall_2: 0.4405 - val_true_negatives_2: 2299.0000 - val_false_positives_2: 221.0000 - val_precision_2: 0.7152 - val_auc_2: 0.8167\n",
      "Epoch 168/200\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.8402 - accuracy: 0.6078 - recall_2: 0.4694 - true_negatives_2: 5268.0000 - false_positives_2: 612.0000 - precision_2: 0.6928 - auc_2: 0.7984 - val_loss: 0.8136 - val_accuracy: 0.6143 - val_recall_2: 0.4921 - val_true_negatives_2: 2235.0000 - val_false_positives_2: 285.0000 - val_precision_2: 0.6851 - val_auc_2: 0.8127\n",
      "Epoch 169/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.8651 - accuracy: 0.6000 - recall_2: 0.4728 - true_negatives_2: 5148.0000 - false_positives_2: 732.0000 - precision_2: 0.6550 - auc_2: 0.7837 - val_loss: 0.8164 - val_accuracy: 0.6357 - val_recall_2: 0.4341 - val_true_negatives_2: 2310.0000 - val_false_positives_2: 210.0000 - val_precision_2: 0.7226 - val_auc_2: 0.8186\n",
      "Epoch 170/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.8237 - accuracy: 0.6116 - recall_2: 0.4701 - true_negatives_2: 5273.0000 - false_positives_2: 607.0000 - precision_2: 0.6948 - auc_2: 0.8076 - val_loss: 0.8187 - val_accuracy: 0.6270 - val_recall_2: 0.4714 - val_true_negatives_2: 2266.0000 - val_false_positives_2: 254.0000 - val_precision_2: 0.7005 - val_auc_2: 0.8125\n",
      "Epoch 171/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.8338 - accuracy: 0.6099 - recall_2: 0.4738 - true_negatives_2: 5231.0000 - false_positives_2: 649.0000 - precision_2: 0.6822 - auc_2: 0.8016 - val_loss: 0.8340 - val_accuracy: 0.6071 - val_recall_2: 0.4889 - val_true_negatives_2: 2243.0000 - val_false_positives_2: 277.0000 - val_precision_2: 0.6898 - val_auc_2: 0.8022\n",
      "Epoch 172/200\n",
      "49/49 [==============================] - 0s 9ms/step - loss: 0.8238 - accuracy: 0.6255 - recall_2: 0.4871 - true_negatives_2: 5242.0000 - false_positives_2: 638.0000 - precision_2: 0.6918 - auc_2: 0.8079 - val_loss: 0.8908 - val_accuracy: 0.5683 - val_recall_2: 0.4056 - val_true_negatives_2: 2257.0000 - val_false_positives_2: 263.0000 - val_precision_2: 0.6602 - val_auc_2: 0.7634\n",
      "Epoch 173/200\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.8355 - accuracy: 0.6071 - recall_2: 0.4759 - true_negatives_2: 5225.0000 - false_positives_2: 655.0000 - precision_2: 0.6811 - auc_2: 0.8002 - val_loss: 0.8271 - val_accuracy: 0.6135 - val_recall_2: 0.4714 - val_true_negatives_2: 2259.0000 - val_false_positives_2: 261.0000 - val_precision_2: 0.6947 - val_auc_2: 0.8088\n",
      "Epoch 174/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.8668 - accuracy: 0.6000 - recall_2: 0.4721 - true_negatives_2: 5176.0000 - false_positives_2: 704.0000 - precision_2: 0.6635 - auc_2: 0.7835 - val_loss: 0.8615 - val_accuracy: 0.5913 - val_recall_2: 0.4762 - val_true_negatives_2: 2194.0000 - val_false_positives_2: 326.0000 - val_precision_2: 0.6479 - val_auc_2: 0.7840\n",
      "Epoch 175/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.9553 - accuracy: 0.5367 - recall_2: 0.4303 - true_negatives_2: 5035.0000 - false_positives_2: 845.0000 - precision_2: 0.5995 - auc_2: 0.7343 - val_loss: 0.8418 - val_accuracy: 0.6175 - val_recall_2: 0.4111 - val_true_negatives_2: 2324.0000 - val_false_positives_2: 196.0000 - val_precision_2: 0.7255 - val_auc_2: 0.8058\n",
      "Epoch 176/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.8509 - accuracy: 0.6014 - recall_2: 0.4524 - true_negatives_2: 5265.0000 - false_positives_2: 615.0000 - precision_2: 0.6838 - auc_2: 0.7916 - val_loss: 0.8316 - val_accuracy: 0.6222 - val_recall_2: 0.4778 - val_true_negatives_2: 2256.0000 - val_false_positives_2: 264.0000 - val_precision_2: 0.6952 - val_auc_2: 0.8070\n",
      "Epoch 177/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.8753 - accuracy: 0.5789 - recall_2: 0.4408 - true_negatives_2: 5244.0000 - false_positives_2: 636.0000 - precision_2: 0.6708 - auc_2: 0.7759 - val_loss: 0.8675 - val_accuracy: 0.5833 - val_recall_2: 0.4175 - val_true_negatives_2: 2288.0000 - val_false_positives_2: 232.0000 - val_precision_2: 0.6939 - val_auc_2: 0.7823\n",
      "Epoch 178/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.8973 - accuracy: 0.5762 - recall_2: 0.4408 - true_negatives_2: 5145.0000 - false_positives_2: 735.0000 - precision_2: 0.6381 - auc_2: 0.7621 - val_loss: 0.8568 - val_accuracy: 0.5944 - val_recall_2: 0.4706 - val_true_negatives_2: 2223.0000 - val_false_positives_2: 297.0000 - val_precision_2: 0.6663 - val_auc_2: 0.7878\n",
      "Epoch 179/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.8590 - accuracy: 0.6034 - recall_2: 0.4456 - true_negatives_2: 5275.0000 - false_positives_2: 605.0000 - precision_2: 0.6841 - auc_2: 0.7874 - val_loss: 0.8200 - val_accuracy: 0.6365 - val_recall_2: 0.4532 - val_true_negatives_2: 2303.0000 - val_false_positives_2: 217.0000 - val_precision_2: 0.7246 - val_auc_2: 0.8186\n",
      "Epoch 180/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.8340 - accuracy: 0.6075 - recall_2: 0.4537 - true_negatives_2: 5315.0000 - false_positives_2: 565.0000 - precision_2: 0.7025 - auc_2: 0.8043 - val_loss: 0.8889 - val_accuracy: 0.5643 - val_recall_2: 0.4095 - val_true_negatives_2: 2267.0000 - val_false_positives_2: 253.0000 - val_precision_2: 0.6710 - val_auc_2: 0.7649\n",
      "Epoch 181/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.8427 - accuracy: 0.6037 - recall_2: 0.4568 - true_negatives_2: 5273.0000 - false_positives_2: 607.0000 - precision_2: 0.6887 - auc_2: 0.7977 - val_loss: 0.8198 - val_accuracy: 0.6325 - val_recall_2: 0.4651 - val_true_negatives_2: 2284.0000 - val_false_positives_2: 236.0000 - val_precision_2: 0.7129 - val_auc_2: 0.8152\n",
      "Epoch 182/200\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.8369 - accuracy: 0.6160 - recall_2: 0.4514 - true_negatives_2: 5270.0000 - false_positives_2: 610.0000 - precision_2: 0.6851 - auc_2: 0.8006 - val_loss: 0.8292 - val_accuracy: 0.6151 - val_recall_2: 0.4746 - val_true_negatives_2: 2273.0000 - val_false_positives_2: 247.0000 - val_precision_2: 0.7077 - val_auc_2: 0.8093\n",
      "Epoch 183/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.8282 - accuracy: 0.6224 - recall_2: 0.4670 - true_negatives_2: 5295.0000 - false_positives_2: 585.0000 - precision_2: 0.7012 - auc_2: 0.8085 - val_loss: 0.8275 - val_accuracy: 0.6254 - val_recall_2: 0.4413 - val_true_negatives_2: 2297.0000 - val_false_positives_2: 223.0000 - val_precision_2: 0.7137 - val_auc_2: 0.8132\n",
      "Epoch 184/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.8231 - accuracy: 0.6282 - recall_2: 0.4687 - true_negatives_2: 5294.0000 - false_positives_2: 586.0000 - precision_2: 0.7016 - auc_2: 0.8101 - val_loss: 0.8498 - val_accuracy: 0.6040 - val_recall_2: 0.3905 - val_true_negatives_2: 2314.0000 - val_false_positives_2: 206.0000 - val_precision_2: 0.7049 - val_auc_2: 0.7972\n",
      "Epoch 185/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.8288 - accuracy: 0.6255 - recall_2: 0.4687 - true_negatives_2: 5310.0000 - false_positives_2: 570.0000 - precision_2: 0.7074 - auc_2: 0.8077 - val_loss: 0.8191 - val_accuracy: 0.6389 - val_recall_2: 0.4405 - val_true_negatives_2: 2309.0000 - val_false_positives_2: 211.0000 - val_precision_2: 0.7245 - val_auc_2: 0.8189\n",
      "Epoch 186/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.8489 - accuracy: 0.6007 - recall_2: 0.4622 - true_negatives_2: 5253.0000 - false_positives_2: 627.0000 - precision_2: 0.6843 - auc_2: 0.7934 - val_loss: 0.8669 - val_accuracy: 0.5857 - val_recall_2: 0.4698 - val_true_negatives_2: 2201.0000 - val_false_positives_2: 319.0000 - val_precision_2: 0.6498 - val_auc_2: 0.7815\n",
      "Epoch 187/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.8415 - accuracy: 0.6078 - recall_2: 0.4667 - true_negatives_2: 5276.0000 - false_positives_2: 604.0000 - precision_2: 0.6943 - auc_2: 0.7979 - val_loss: 0.9128 - val_accuracy: 0.5643 - val_recall_2: 0.4079 - val_true_negatives_2: 2227.0000 - val_false_positives_2: 293.0000 - val_precision_2: 0.6369 - val_auc_2: 0.7519\n",
      "Epoch 188/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.8479 - accuracy: 0.6051 - recall_2: 0.4694 - true_negatives_2: 5244.0000 - false_positives_2: 636.0000 - precision_2: 0.6845 - auc_2: 0.7946 - val_loss: 0.8796 - val_accuracy: 0.5794 - val_recall_2: 0.4762 - val_true_negatives_2: 2181.0000 - val_false_positives_2: 339.0000 - val_precision_2: 0.6390 - val_auc_2: 0.7738\n",
      "Epoch 189/200\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.8325 - accuracy: 0.6133 - recall_2: 0.4748 - true_negatives_2: 5241.0000 - false_positives_2: 639.0000 - precision_2: 0.6860 - auc_2: 0.8033 - val_loss: 0.8118 - val_accuracy: 0.6381 - val_recall_2: 0.4722 - val_true_negatives_2: 2283.0000 - val_false_positives_2: 237.0000 - val_precision_2: 0.7151 - val_auc_2: 0.8194\n",
      "Epoch 190/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.8299 - accuracy: 0.6197 - recall_2: 0.4690 - true_negatives_2: 5276.0000 - false_positives_2: 604.0000 - precision_2: 0.6954 - auc_2: 0.8051 - val_loss: 0.8262 - val_accuracy: 0.6206 - val_recall_2: 0.4325 - val_true_negatives_2: 2299.0000 - val_false_positives_2: 221.0000 - val_precision_2: 0.7115 - val_auc_2: 0.8132\n",
      "Epoch 191/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.8348 - accuracy: 0.6116 - recall_2: 0.4636 - true_negatives_2: 5263.0000 - false_positives_2: 617.0000 - precision_2: 0.6884 - auc_2: 0.8018 - val_loss: 0.8723 - val_accuracy: 0.5825 - val_recall_2: 0.4746 - val_true_negatives_2: 2184.0000 - val_false_positives_2: 336.0000 - val_precision_2: 0.6403 - val_auc_2: 0.7778\n",
      "Epoch 192/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.8249 - accuracy: 0.6286 - recall_2: 0.4704 - true_negatives_2: 5295.0000 - false_positives_2: 585.0000 - precision_2: 0.7027 - auc_2: 0.8091 - val_loss: 0.8757 - val_accuracy: 0.5635 - val_recall_2: 0.4159 - val_true_negatives_2: 2265.0000 - val_false_positives_2: 255.0000 - val_precision_2: 0.6727 - val_auc_2: 0.7733\n",
      "Epoch 193/200\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.8852 - accuracy: 0.5796 - recall_2: 0.4486 - true_negatives_2: 5164.0000 - false_positives_2: 716.0000 - precision_2: 0.6482 - auc_2: 0.7715 - val_loss: 0.8572 - val_accuracy: 0.5976 - val_recall_2: 0.4310 - val_true_negatives_2: 2272.0000 - val_false_positives_2: 248.0000 - val_precision_2: 0.6865 - val_auc_2: 0.7873\n",
      "Epoch 194/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.8519 - accuracy: 0.5990 - recall_2: 0.4738 - true_negatives_2: 5191.0000 - false_positives_2: 689.0000 - precision_2: 0.6691 - auc_2: 0.7917 - val_loss: 0.8074 - val_accuracy: 0.6484 - val_recall_2: 0.4556 - val_true_negatives_2: 2314.0000 - val_false_positives_2: 206.0000 - val_precision_2: 0.7359 - val_auc_2: 0.8251\n",
      "Epoch 195/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.8631 - accuracy: 0.5935 - recall_2: 0.4636 - true_negatives_2: 5219.0000 - false_positives_2: 661.0000 - precision_2: 0.6734 - auc_2: 0.7842 - val_loss: 0.8088 - val_accuracy: 0.6476 - val_recall_2: 0.4563 - val_true_negatives_2: 2296.0000 - val_false_positives_2: 224.0000 - val_precision_2: 0.7196 - val_auc_2: 0.8227\n",
      "Epoch 196/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.8342 - accuracy: 0.6133 - recall_2: 0.4779 - true_negatives_2: 5231.0000 - false_positives_2: 649.0000 - precision_2: 0.6840 - auc_2: 0.8014 - val_loss: 0.9048 - val_accuracy: 0.5373 - val_recall_2: 0.3976 - val_true_negatives_2: 2215.0000 - val_false_positives_2: 305.0000 - val_precision_2: 0.6216 - val_auc_2: 0.7533\n",
      "Epoch 197/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.8526 - accuracy: 0.6000 - recall_2: 0.4673 - true_negatives_2: 5201.0000 - false_positives_2: 679.0000 - precision_2: 0.6693 - auc_2: 0.7901 - val_loss: 0.8271 - val_accuracy: 0.6127 - val_recall_2: 0.4738 - val_true_negatives_2: 2263.0000 - val_false_positives_2: 257.0000 - val_precision_2: 0.6991 - val_auc_2: 0.8076\n",
      "Epoch 198/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.8522 - accuracy: 0.6044 - recall_2: 0.4823 - true_negatives_2: 5212.0000 - false_positives_2: 668.0000 - precision_2: 0.6798 - auc_2: 0.7917 - val_loss: 0.9057 - val_accuracy: 0.5913 - val_recall_2: 0.4468 - val_true_negatives_2: 2173.0000 - val_false_positives_2: 347.0000 - val_precision_2: 0.6187 - val_auc_2: 0.7595\n",
      "Epoch 199/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.8491 - accuracy: 0.6020 - recall_2: 0.4772 - true_negatives_2: 5220.0000 - false_positives_2: 660.0000 - precision_2: 0.6801 - auc_2: 0.7921 - val_loss: 0.8406 - val_accuracy: 0.6119 - val_recall_2: 0.4841 - val_true_negatives_2: 2209.0000 - val_false_positives_2: 311.0000 - val_precision_2: 0.6623 - val_auc_2: 0.7975\n",
      "Epoch 200/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.8503 - accuracy: 0.6044 - recall_2: 0.4728 - true_negatives_2: 5179.0000 - false_positives_2: 701.0000 - precision_2: 0.6648 - auc_2: 0.7915 - val_loss: 0.8217 - val_accuracy: 0.6143 - val_recall_2: 0.4484 - val_true_negatives_2: 2288.0000 - val_false_positives_2: 232.0000 - val_precision_2: 0.7089 - val_auc_2: 0.8140\n",
      "                    base model  out layers  extra params  epochs  batch size  \\\n",
      "26/03/2022 14:25:15   resnet50           3        131331     200          60   \n",
      "\n",
      "                     accuracy  recall  specificity  precision  f1_score   auc  \\\n",
      "26/03/2022 14:25:15      0.63    0.46         0.91       0.71      0.56  0.82   \n",
      "\n",
      "                     train time  eval time  \n",
      "26/03/2022 14:25:15       99.34      12.63  \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train model using features generated from VGG16 model\n",
    "epochs = 200\n",
    "batch_size = 60\n",
    "specificity = []\n",
    "train_time = []\n",
    "eval_time = []\n",
    "precision = []\n",
    "accuracy = []\n",
    "f1_score = []\n",
    "au_curve = []\n",
    "_layers = []\n",
    "params = []\n",
    "recall = []\n",
    "model = []\n",
    "batch = []\n",
    "epoch = []\n",
    "time_ = []\n",
    "\n",
    "#Se entrena el modelo\n",
    "tic = time.perf_counter()\n",
    "features_train = pretrained_model.predict(X_train.reshape(len(X_train),IMG_SIZE,IMG_SIZE,3))\n",
    "features_val = pretrained_model.predict(X_val.reshape(len(X_val),IMG_SIZE,IMG_SIZE,3))\n",
    "history = (modelCNN.fit(features_train, train_target, epochs=epochs, batch_size=batch_size, validation_data=(features_val, val_target)))\n",
    "toc = time.perf_counter()\n",
    "train_time.append(round((toc-tic), 2))\n",
    "\n",
    "# Se evalua el modelo segun algunas metricas de error\n",
    "tic = time.perf_counter()\n",
    "features_test = pretrained_model.predict(X_test.reshape(len(X_test),IMG_SIZE,IMG_SIZE,3))\n",
    "test_loss, test_acc, test_recall, true_neg, false_pos, test_prec, test_auc = modelCNN.evaluate(features_test,  test_target, verbose=0)\n",
    "toc = time.perf_counter()\n",
    "eval_time.append(round((toc-tic), 2))\n",
    "specificity.append(round(true_neg/(true_neg + false_pos),2))\n",
    "f1_score.append(round(2 * test_recall * test_prec / (test_recall + test_prec),2)\n",
    "                if (test_recall + test_prec) > 0 else 0)\n",
    "model.append(pretrained_model.name)\n",
    "epoch.append(epochs)\n",
    "batch.append(batch_size)\n",
    "accuracy.append(round(test_acc,2))\n",
    "recall.append(round(test_recall,2))\n",
    "precision.append(round(test_prec,2))\n",
    "au_curve.append(round(test_auc,2))\n",
    "_layers.append(len(modelCNN.layers))\n",
    "params.append(modelCNN.count_params()) \n",
    "\n",
    "test_data = {'base model':model,\n",
    "        'out layers': _layers,\n",
    "        'extra params': params,\n",
    "        'epochs': epoch,\n",
    "        'batch size': batch,\n",
    "        'accuracy': accuracy,\n",
    "        'recall': recall,\n",
    "        'specificity': specificity,\n",
    "        'precision': precision,\n",
    "        'f1_score': f1_score,\n",
    "        'auc': au_curve,\n",
    "        'train time': train_time,\n",
    "        'eval time': eval_time\n",
    "        }\n",
    "\n",
    "now = datetime.now() # current date and time\n",
    "time_.append(now.strftime(\"%d/%m/%Y %H:%M:%S\"))\n",
    "df = pd.DataFrame(test_data, index = time_)\n",
    "excel_name = \"./informe/tables/DCNN.xlsx\"\n",
    "append_data_to_excel(excel_name, df)\n",
    "print(df)\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Se puede calcular la matriz de confusión de la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
       "array([[391, 139,  74],\n",
       "       [105, 273, 217],\n",
       "       [ 49,  86, 466]])>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_test = pretrained_model.predict(X_test.reshape(len(X_test),IMG_SIZE,IMG_SIZE,3))\n",
    "t_pred = []\n",
    "for i in range(0,len(features_test)):\n",
    "    t_pred.append(np.argmax(modelCNN.predict(features_test[i:i+1])))\n",
    "tf.math.confusion_matrix(t_test, t_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
