{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=https://api-manager.universia.net/coreplatform-document-management/api/document-management/public/6ra7ymjkfi64845 width=\"300\" align=\"left\">\n",
    "<br />\n",
    "\n",
    "# Aprendizaje automático I\n",
    "#### <font color=green>*Máster en Informática Industrial y Robótica*</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Daniel Vidal Soroa  \n",
    "Juan Diego Peña "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificación de mangos en tres clases según su presencia para la exportación, comercio local o procesamiento industrial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importación de las librerías:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from keras.models import Sequential\n",
    "from keras.applications import vgg16, mobilenet, resnet, xception\n",
    "from keras.layers import Flatten, Dense, BatchNormalization, Dropout\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from random import seed\n",
    "from random import randint\n",
    "from keras import layers\n",
    "\n",
    "IMG_SIZE = 32\n",
    "\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "  layers.RandomFlip(\"horizontal_and_vertical\")\n",
    "])\n",
    "\n",
    "# Función para mostrar lista de imágenes en escala de grises\n",
    "def show_row_of_gray_images(fig_width, *images):\n",
    "    plt.figure(figsize=(fig_width, fig_width))\n",
    "    images_count = len(images)\n",
    "    index = 1  \n",
    "    for image in images:\n",
    "        plt.subplot(1, images_count, index)\n",
    "        plt.imshow(image, cmap='gray')\n",
    "        plt.axis('off')\n",
    "        index+=1\n",
    "\n",
    "# Función para añadir datos a una tebla de excel\n",
    "def append_data_to_excel(excel_name, df):\n",
    "    with pd.ExcelWriter(excel_name,\n",
    "        mode=\"a\",\n",
    "        engine=\"openpyxl\",\n",
    "        if_sheet_exists=\"overlay\") as writer:\n",
    "        start_row = 0\n",
    "        header = True\n",
    "        if os.path.exists(excel_name):\n",
    "            df_source = pd.read_excel(excel_name, engine=\"openpyxl\").iloc[:,1:]\n",
    "        if df_source is not None:\n",
    "            n, m = df_source.shape\n",
    "            header = False if n > 0 else True\n",
    "            start_row = n + 1 if n > 0 else n\n",
    "        \n",
    "        df.to_excel(writer, sheet_name=\"Sheet1\",startcol=0, startrow = start_row, header=header)\n",
    "\n",
    "# Función para graficar progreso durante el entrenamiento de la red \n",
    "def plot_history(history):\n",
    "    plt.figure(figsize=(12,5))\n",
    "    plt.plot(history.history['accuracy'], label='Entrenamiento')\n",
    "    plt.plot(history.history['val_accuracy'], label = 'Validación')\n",
    "    plt.xlabel('Iteración (epoch)')\n",
    "    plt.ylabel('Exactitud (accuracy)')\n",
    "    plt.ylim([0, 1])\n",
    "    plt.grid()\n",
    "    plt.title('Modelo '+str(i+1))\n",
    "    plt.legend(loc='lower right')\n",
    "\n",
    "#Distintas arquitectura para salida de la red neuronal\n",
    "def cnn1(_input_shape, classes):\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=_input_shape))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(classes, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "def cnn2(_input_shape, classes):\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=_input_shape))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(classes, activation='softmax'))   \n",
    "    return model\n",
    "\n",
    "def cnn3(_input_shape, classes):\n",
    "    model = Sequential()\n",
    "    model.add(layers.Flatten(input_shape=_input_shape))\n",
    "    model.add(layers.Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.Dense(classes, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "def get_base_model(name):\n",
    "    if name == 'vgg':\n",
    "        return vgg16.VGG16(include_top=False, weights='imagenet', input_shape=(IMG_SIZE,IMG_SIZE,3))\n",
    "    elif name == 'mobilnet':\n",
    "        return mobilenet.MobileNet(include_top=False, weights='imagenet', input_shape=(IMG_SIZE,IMG_SIZE,3))\n",
    "    elif name == 'xception':\n",
    "        return xception.Xception(include_top=False, weights='imagenet', input_shape=(IMG_SIZE,IMG_SIZE,3))\n",
    "    else: return resnet.ResNet50(include_top=False, weights='imagenet', input_shape=(IMG_SIZE,IMG_SIZE,3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lectura de los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324\n",
      "1784\n",
      "328\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x1152 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# seed random number generator\n",
    "seed(1)\n",
    "\n",
    "# Dimensión de entrada de las imágenes \n",
    "h = IMG_SIZE\n",
    "w = IMG_SIZE\n",
    "\n",
    "# Leer los nombres de las imágenes para importarlas\n",
    "input_class1_path = \"./Dataset/Grading_dataset/Class_I\"\n",
    "class1_names = os.listdir(input_class1_path)\n",
    "input_class2_path = \"./Dataset/Grading_dataset/Class_II\"\n",
    "class2_names = os.listdir(input_class2_path)\n",
    "input_classex_path = \"./Dataset/Grading_dataset/Extra_Class\"\n",
    "class3_names = os.listdir(input_classex_path)\n",
    "\n",
    "# Número de elementos en cada clase\n",
    "n = len(class1_names)\n",
    "\n",
    "# Definir listas para cargar imágenes\n",
    "class1 = np.ones([n, h, w, 3])\n",
    "class2 = np.ones([n, h, w, 3])\n",
    "class3 = np.ones([n, h, w, 3])\n",
    "\n",
    "for i in range(0, n, 1):\n",
    "    # Para cada clase, se lee una imágen, se importa\n",
    "    img = resize(imread(\"./Dataset/Grading_dataset/Class_I/\" + class1_names[i]), (h, w))\n",
    "    class1[i] = img  \n",
    "    img = resize(imread(\"./Dataset/Grading_dataset/Class_II/\" + class2_names[i]), (h, w))\n",
    "    class2[i] = img \n",
    "    img = resize(imread(\"./Dataset/Grading_dataset/Extra_Class/\" + class3_names[i]), (h, w))\n",
    "    class3[i] = img \n",
    "\n",
    "# Aumentamos por un factor f el número de datos de cada clase\n",
    "f = 10\n",
    "class1_augmeted = np.zeros([n * f, h, w, 3])\n",
    "class2_augmeted = np.zeros([n * f, h, w, 3])\n",
    "class3_augmeted = np.zeros([n * f, h, w, 3])\n",
    "t1 = np.zeros(n * f)\n",
    "t2 = np.zeros(n * f)\n",
    "t3 = np.zeros(n * f)\n",
    "\n",
    "for i in range(n * f):\n",
    "    rn = randint(0, n-1)\n",
    "    img = class1[rn]\n",
    "    new_img = data_augmentation(img)\n",
    "    class1_augmeted [i] = new_img\n",
    "    t1[i] = 1\n",
    "    \n",
    "    rn = randint(0, n-1)\n",
    "    img = class2[rn]\n",
    "    new_img = data_augmentation(img)\n",
    "    class2_augmeted [i] = new_img\n",
    "    t2[i] = 2\n",
    "    \n",
    "    rn = randint(0, n-1)\n",
    "    img = class3[rn]\n",
    "    new_img = data_augmentation(img)\n",
    "    class3_augmeted [i] = new_img\n",
    "    t3[i] = 0\n",
    "\n",
    "# Se imprimen tres imágenes aleatorias de los datos aumentados para comprobar que funciona    \n",
    "rn = randint(0, 2000)\n",
    "img_1 = class1_augmeted[rn]\n",
    "print (rn)\n",
    "rn = randint(0, 2000)\n",
    "print (rn)\n",
    "img_2 = class2_augmeted[rn]\n",
    "rn = randint(0, 2000)\n",
    "print (rn)\n",
    "img_3 = class3_augmeted[rn]  \n",
    "show_row_of_gray_images(16, img_1, img_2, img_3)\n",
    "\n",
    "# Se define el conjunto de datos de entrenamiento\n",
    "X = np.zeros([f*n*3,h*w*3])\n",
    "X[0:2000] = class3_augmeted.reshape(f*n,h*w*3)\n",
    "X[2000:4000] = class1_augmeted.reshape(f*n,h*w*3)\n",
    "X[4000:6000] = class2_augmeted.reshape(f*n,h*w*3)\n",
    "\n",
    "# Se definen las etiquetas de las clases\n",
    "t = np.zeros(f*n*3)\n",
    "t[0:2000] = t3\n",
    "t[2000:4000] = t1\n",
    "t[4000:6000] = t2\n",
    "\n",
    "X_train_val, X_test, t_train_val, t_test = train_test_split(X, t, test_size=0.3,shuffle=True)\n",
    "X_train, X_val, t_train, t_val = train_test_split(X_train_val, t_train_val, test_size=0.3, shuffle=True)\n",
    "train_target = tf.keras.utils.to_categorical(t_train)\n",
    "val_target = tf.keras.utils.to_categorical(t_val)\n",
    "test_target = tf.keras.utils.to_categorical(t_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Se importa la red CNN VGG16 para utilizar su arquitectura y conocimento para resolver nuestro problema "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94773248/94765736 [==============================] - 5s 0us/step\n",
      "94781440/94765736 [==============================] - 5s 0us/step\n",
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 38, 38, 3)    0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)            (None, 16, 16, 64)   9472        ['conv1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv1_bn (BatchNormalization)  (None, 16, 16, 64)   256         ['conv1_conv[0][0]']             \n",
      "                                                                                                  \n",
      " conv1_relu (Activation)        (None, 16, 16, 64)   0           ['conv1_bn[0][0]']               \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)      (None, 18, 18, 64)   0           ['conv1_relu[0][0]']             \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)      (None, 8, 8, 64)     0           ['pool1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 8, 8, 64)     4160        ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 8, 8, 64)     36928       ['conv2_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2D)   (None, 8, 8, 256)    16640       ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2D)   (None, 8, 8, 256)    16640       ['conv2_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_0_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv2_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_3_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv2_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_add (Add)         (None, 8, 8, 256)    0           ['conv2_block1_0_bn[0][0]',      \n",
      "                                                                  'conv2_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block1_out (Activation)  (None, 8, 8, 256)    0           ['conv2_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 8, 8, 64)     16448       ['conv2_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 8, 8, 64)     36928       ['conv2_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2D)   (None, 8, 8, 256)    16640       ['conv2_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_3_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv2_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_add (Add)         (None, 8, 8, 256)    0           ['conv2_block1_out[0][0]',       \n",
      "                                                                  'conv2_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block2_out (Activation)  (None, 8, 8, 256)    0           ['conv2_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 8, 8, 64)     16448       ['conv2_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 8, 8, 64)     36928       ['conv2_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2D)   (None, 8, 8, 256)    16640       ['conv2_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_3_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv2_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_add (Add)         (None, 8, 8, 256)    0           ['conv2_block2_out[0][0]',       \n",
      "                                                                  'conv2_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block3_out (Activation)  (None, 8, 8, 256)    0           ['conv2_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 4, 4, 128)    32896       ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 4, 4, 128)    147584      ['conv3_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2D)   (None, 4, 4, 512)    131584      ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2D)   (None, 4, 4, 512)    66048       ['conv3_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_0_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_3_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_add (Add)         (None, 4, 4, 512)    0           ['conv3_block1_0_bn[0][0]',      \n",
      "                                                                  'conv3_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block1_out (Activation)  (None, 4, 4, 512)    0           ['conv3_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 4, 4, 128)    65664       ['conv3_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 4, 4, 128)    147584      ['conv3_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2D)   (None, 4, 4, 512)    66048       ['conv3_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_3_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_add (Add)         (None, 4, 4, 512)    0           ['conv3_block1_out[0][0]',       \n",
      "                                                                  'conv3_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block2_out (Activation)  (None, 4, 4, 512)    0           ['conv3_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 4, 4, 128)    65664       ['conv3_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 4, 4, 128)    147584      ['conv3_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2D)   (None, 4, 4, 512)    66048       ['conv3_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_3_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_add (Add)         (None, 4, 4, 512)    0           ['conv3_block2_out[0][0]',       \n",
      "                                                                  'conv3_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block3_out (Activation)  (None, 4, 4, 512)    0           ['conv3_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 4, 4, 128)    65664       ['conv3_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 4, 4, 128)    147584      ['conv3_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2D)   (None, 4, 4, 512)    66048       ['conv3_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_3_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block4_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_add (Add)         (None, 4, 4, 512)    0           ['conv3_block3_out[0][0]',       \n",
      "                                                                  'conv3_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block4_out (Activation)  (None, 4, 4, 512)    0           ['conv3_block4_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 2, 2, 256)    131328      ['conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2D)   (None, 2, 2, 1024)   525312      ['conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_0_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block1_0_bn[0][0]',      \n",
      "                                                                  'conv4_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block1_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block1_out[0][0]',       \n",
      "                                                                  'conv4_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block2_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block2_out[0][0]',       \n",
      "                                                                  'conv4_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block3_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block4_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block3_out[0][0]',       \n",
      "                                                                  'conv4_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block4_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block4_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block5_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block5_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block5_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block5_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block4_out[0][0]',       \n",
      "                                                                  'conv4_block5_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block5_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block5_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block5_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block6_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block6_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block6_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block6_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block5_out[0][0]',       \n",
      "                                                                  'conv4_block6_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block6_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block6_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2D)   (None, 1, 1, 512)    524800      ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2D)   (None, 1, 1, 512)    2359808     ['conv5_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_2_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2D)   (None, 1, 1, 2048)   2099200     ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2D)   (None, 1, 1, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_0_bn (BatchNormal  (None, 1, 1, 2048)  8192        ['conv5_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_3_bn (BatchNormal  (None, 1, 1, 2048)  8192        ['conv5_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_add (Add)         (None, 1, 1, 2048)   0           ['conv5_block1_0_bn[0][0]',      \n",
      "                                                                  'conv5_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block1_out (Activation)  (None, 1, 1, 2048)   0           ['conv5_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2D)   (None, 1, 1, 512)    1049088     ['conv5_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2D)   (None, 1, 1, 512)    2359808     ['conv5_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2D)   (None, 1, 1, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_3_bn (BatchNormal  (None, 1, 1, 2048)  8192        ['conv5_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_add (Add)         (None, 1, 1, 2048)   0           ['conv5_block1_out[0][0]',       \n",
      "                                                                  'conv5_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block2_out (Activation)  (None, 1, 1, 2048)   0           ['conv5_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2D)   (None, 1, 1, 512)    1049088     ['conv5_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2D)   (None, 1, 1, 512)    2359808     ['conv5_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2D)   (None, 1, 1, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_3_bn (BatchNormal  (None, 1, 1, 2048)  8192        ['conv5_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_add (Add)         (None, 1, 1, 2048)   0           ['conv5_block2_out[0][0]',       \n",
      "                                                                  'conv5_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block3_out (Activation)  (None, 1, 1, 2048)   0           ['conv5_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 23,534,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# include top should be False to remove the softmax layer\n",
    "model_name = \"resnet\"\n",
    "pretrained_model = get_base_model(model_name)\n",
    "pretrained_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                131136    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 131,331\n",
      "Trainable params: 131,331\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classes = 3\n",
    "input_shape = pretrained_model.output_shape[1:4]\n",
    "modelCNN = cnn2(input_shape, classes)\n",
    "# compile the model\n",
    "modelCNN.compile(optimizer='adam', metrics=['accuracy',\n",
    "                                            tf.keras.metrics.Recall(),\n",
    "                                            tf.keras.metrics.TrueNegatives(),\n",
    "                                            tf.keras.metrics.FalsePositives(), \n",
    "                                            tf.keras.metrics.Precision(),\n",
    "                                            tf.keras.metrics.AUC()], loss='categorical_crossentropy')\n",
    "modelCNN.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finalmente se realiza la clasificación utilizando las capas finales de la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "49/49 [==============================] - 2s 15ms/step - loss: 1.2091 - accuracy: 0.3265 - recall: 0.0772 - true_negatives: 5368.0000 - false_positives: 512.0000 - precision: 0.3072 - auc: 0.4923 - val_loss: 1.1054 - val_accuracy: 0.3302 - val_recall: 0.0000e+00 - val_true_negatives: 2520.0000 - val_false_positives: 0.0000e+00 - val_precision: 0.0000e+00 - val_auc: 0.5280\n",
      "Epoch 2/200\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 1.1118 - accuracy: 0.3517 - recall: 0.0075 - true_negatives: 5835.0000 - false_positives: 45.0000 - precision: 0.3284 - auc: 0.5234 - val_loss: 1.1202 - val_accuracy: 0.3302 - val_recall: 0.0730 - val_true_negatives: 2430.0000 - val_false_positives: 90.0000 - val_precision: 0.5055 - val_auc: 0.5568\n",
      "Epoch 3/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 1.0930 - accuracy: 0.3724 - recall: 0.0286 - true_negatives: 5785.0000 - false_positives: 95.0000 - precision: 0.4693 - auc: 0.5563 - val_loss: 1.0714 - val_accuracy: 0.4095 - val_recall: 0.0000e+00 - val_true_negatives: 2520.0000 - val_false_positives: 0.0000e+00 - val_precision: 0.0000e+00 - val_auc: 0.6178\n",
      "Epoch 4/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 1.1286 - accuracy: 0.3711 - recall: 0.0901 - true_negatives: 5496.0000 - false_positives: 384.0000 - precision: 0.4083 - auc: 0.5385 - val_loss: 1.1314 - val_accuracy: 0.3500 - val_recall: 0.1968 - val_true_negatives: 2203.0000 - val_false_positives: 317.0000 - val_precision: 0.4389 - val_auc: 0.5531\n",
      "Epoch 5/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 1.1033 - accuracy: 0.3915 - recall: 0.0833 - true_negatives: 5584.0000 - false_positives: 296.0000 - precision: 0.4529 - auc: 0.5604 - val_loss: 1.0724 - val_accuracy: 0.4198 - val_recall: 0.0405 - val_true_negatives: 2485.0000 - val_false_positives: 35.0000 - val_precision: 0.5930 - val_auc: 0.5953\n",
      "Epoch 6/200\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 1.0795 - accuracy: 0.3942 - recall: 0.0408 - true_negatives: 5730.0000 - false_positives: 150.0000 - precision: 0.4444 - auc: 0.5860 - val_loss: 1.0626 - val_accuracy: 0.4103 - val_recall: 0.0071 - val_true_negatives: 2517.0000 - val_false_positives: 3.0000 - val_precision: 0.7500 - val_auc: 0.6154\n",
      "Epoch 7/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 1.0857 - accuracy: 0.3983 - recall: 0.0616 - true_negatives: 5693.0000 - false_positives: 187.0000 - precision: 0.4918 - auc: 0.5764 - val_loss: 1.0549 - val_accuracy: 0.4389 - val_recall: 0.0476 - val_true_negatives: 2476.0000 - val_false_positives: 44.0000 - val_precision: 0.5769 - val_auc: 0.6329\n",
      "Epoch 8/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 1.0758 - accuracy: 0.4197 - recall: 0.0772 - true_negatives: 5635.0000 - false_positives: 245.0000 - precision: 0.4809 - auc: 0.5980 - val_loss: 1.0470 - val_accuracy: 0.4738 - val_recall: 0.0222 - val_true_negatives: 2503.0000 - val_false_positives: 17.0000 - val_precision: 0.6222 - val_auc: 0.6601\n",
      "Epoch 9/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 1.0859 - accuracy: 0.3966 - recall: 0.1109 - true_negatives: 5460.0000 - false_positives: 420.0000 - precision: 0.4370 - auc: 0.5858 - val_loss: 1.0440 - val_accuracy: 0.5103 - val_recall: 0.0151 - val_true_negatives: 2516.0000 - val_false_positives: 4.0000 - val_precision: 0.8261 - val_auc: 0.6665\n",
      "Epoch 10/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 1.0536 - accuracy: 0.4361 - recall: 0.0531 - true_negatives: 5745.0000 - false_positives: 135.0000 - precision: 0.5361 - auc: 0.6265 - val_loss: 1.0561 - val_accuracy: 0.3865 - val_recall: 0.0667 - val_true_negatives: 2470.0000 - val_false_positives: 50.0000 - val_precision: 0.6269 - val_auc: 0.6161\n",
      "Epoch 11/200\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 1.0611 - accuracy: 0.4241 - recall: 0.0779 - true_negatives: 5699.0000 - false_positives: 181.0000 - precision: 0.5585 - auc: 0.6124 - val_loss: 1.0760 - val_accuracy: 0.4159 - val_recall: 0.1111 - val_true_negatives: 2366.0000 - val_false_positives: 154.0000 - val_precision: 0.4762 - val_auc: 0.6035\n",
      "Epoch 12/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 1.0727 - accuracy: 0.4320 - recall: 0.0959 - true_negatives: 5578.0000 - false_positives: 302.0000 - precision: 0.4829 - auc: 0.6089 - val_loss: 1.1118 - val_accuracy: 0.4167 - val_recall: 0.1619 - val_true_negatives: 2252.0000 - val_false_positives: 268.0000 - val_precision: 0.4322 - val_auc: 0.5958\n",
      "Epoch 13/200\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 1.0712 - accuracy: 0.4316 - recall: 0.1177 - true_negatives: 5516.0000 - false_positives: 364.0000 - precision: 0.4873 - auc: 0.6105 - val_loss: 1.2237 - val_accuracy: 0.4452 - val_recall: 0.2429 - val_true_negatives: 2291.0000 - val_false_positives: 229.0000 - val_precision: 0.5720 - val_auc: 0.5994\n",
      "Epoch 14/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 1.0758 - accuracy: 0.4252 - recall: 0.1663 - true_negatives: 5461.0000 - false_positives: 419.0000 - precision: 0.5385 - auc: 0.6086 - val_loss: 1.1344 - val_accuracy: 0.3349 - val_recall: 0.3198 - val_true_negatives: 1853.0000 - val_false_positives: 667.0000 - val_precision: 0.3766 - val_auc: 0.6121\n",
      "Epoch 15/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 1.0612 - accuracy: 0.4279 - recall: 0.1395 - true_negatives: 5504.0000 - false_positives: 376.0000 - precision: 0.5216 - auc: 0.6150 - val_loss: 1.0382 - val_accuracy: 0.4063 - val_recall: 0.0762 - val_true_negatives: 2457.0000 - val_false_positives: 63.0000 - val_precision: 0.6038 - val_auc: 0.6470\n",
      "Epoch 16/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 1.0527 - accuracy: 0.4381 - recall: 0.1252 - true_negatives: 5548.0000 - false_positives: 332.0000 - precision: 0.5257 - auc: 0.6277 - val_loss: 1.1325 - val_accuracy: 0.4778 - val_recall: 0.1865 - val_true_negatives: 2404.0000 - val_false_positives: 116.0000 - val_precision: 0.6695 - val_auc: 0.6171\n",
      "Epoch 17/200\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 1.0457 - accuracy: 0.4480 - recall: 0.1139 - true_negatives: 5581.0000 - false_positives: 299.0000 - precision: 0.5284 - auc: 0.6385 - val_loss: 1.0182 - val_accuracy: 0.4810 - val_recall: 0.0675 - val_true_negatives: 2459.0000 - val_false_positives: 61.0000 - val_precision: 0.5822 - val_auc: 0.6855\n",
      "Epoch 18/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 1.0388 - accuracy: 0.4663 - recall: 0.1272 - true_negatives: 5561.0000 - false_positives: 319.0000 - precision: 0.5397 - auc: 0.6472 - val_loss: 1.0765 - val_accuracy: 0.3841 - val_recall: 0.2357 - val_true_negatives: 2145.0000 - val_false_positives: 375.0000 - val_precision: 0.4420 - val_auc: 0.6164\n",
      "Epoch 19/200\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 1.0429 - accuracy: 0.4442 - recall: 0.1459 - true_negatives: 5512.0000 - false_positives: 368.0000 - precision: 0.5383 - auc: 0.6373 - val_loss: 1.0096 - val_accuracy: 0.5325 - val_recall: 0.0532 - val_true_negatives: 2499.0000 - val_false_positives: 21.0000 - val_precision: 0.7614 - val_auc: 0.7077\n",
      "Epoch 20/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 1.0183 - accuracy: 0.4850 - recall: 0.1187 - true_negatives: 5608.0000 - false_positives: 272.0000 - precision: 0.5620 - auc: 0.6756 - val_loss: 1.0120 - val_accuracy: 0.4825 - val_recall: 0.0921 - val_true_negatives: 2469.0000 - val_false_positives: 51.0000 - val_precision: 0.6946 - val_auc: 0.6894\n",
      "Epoch 21/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 1.0262 - accuracy: 0.4704 - recall: 0.1337 - true_negatives: 5591.0000 - false_positives: 289.0000 - precision: 0.5762 - auc: 0.6607 - val_loss: 1.0248 - val_accuracy: 0.4738 - val_recall: 0.1381 - val_true_negatives: 2444.0000 - val_false_positives: 76.0000 - val_precision: 0.6960 - val_auc: 0.6619\n",
      "Epoch 22/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 1.0214 - accuracy: 0.4759 - recall: 0.1612 - true_negatives: 5519.0000 - false_positives: 361.0000 - precision: 0.5677 - auc: 0.6664 - val_loss: 1.1026 - val_accuracy: 0.5024 - val_recall: 0.2659 - val_true_negatives: 2354.0000 - val_false_positives: 166.0000 - val_precision: 0.6687 - val_auc: 0.6414\n",
      "Epoch 23/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 1.0502 - accuracy: 0.4503 - recall: 0.2017 - true_negatives: 5338.0000 - false_positives: 542.0000 - precision: 0.5225 - auc: 0.6346 - val_loss: 1.0294 - val_accuracy: 0.4119 - val_recall: 0.2048 - val_true_negatives: 2286.0000 - val_false_positives: 234.0000 - val_precision: 0.5244 - val_auc: 0.6519\n",
      "Epoch 24/200\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 1.0343 - accuracy: 0.4456 - recall: 0.2020 - true_negatives: 5385.0000 - false_positives: 495.0000 - precision: 0.5455 - auc: 0.6480 - val_loss: 1.0033 - val_accuracy: 0.4794 - val_recall: 0.1341 - val_true_negatives: 2381.0000 - val_false_positives: 139.0000 - val_precision: 0.5487 - val_auc: 0.6848\n",
      "Epoch 25/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 1.0148 - accuracy: 0.4922 - recall: 0.1728 - true_negatives: 5527.0000 - false_positives: 353.0000 - precision: 0.5900 - auc: 0.6739 - val_loss: 1.0302 - val_accuracy: 0.4944 - val_recall: 0.2103 - val_true_negatives: 2401.0000 - val_false_positives: 119.0000 - val_precision: 0.6901 - val_auc: 0.6612\n",
      "Epoch 26/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 1.0001 - accuracy: 0.4932 - recall: 0.1561 - true_negatives: 5629.0000 - false_positives: 251.0000 - precision: 0.6465 - auc: 0.6918 - val_loss: 1.0006 - val_accuracy: 0.5230 - val_recall: 0.1873 - val_true_negatives: 2417.0000 - val_false_positives: 103.0000 - val_precision: 0.6962 - val_auc: 0.6957\n",
      "Epoch 27/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 1.0031 - accuracy: 0.5000 - recall: 0.1701 - true_negatives: 5535.0000 - false_positives: 345.0000 - precision: 0.5917 - auc: 0.6863 - val_loss: 1.0117 - val_accuracy: 0.4413 - val_recall: 0.2103 - val_true_negatives: 2300.0000 - val_false_positives: 220.0000 - val_precision: 0.5464 - val_auc: 0.6688\n",
      "Epoch 28/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 1.0249 - accuracy: 0.4707 - recall: 0.2231 - true_negatives: 5303.0000 - false_positives: 577.0000 - precision: 0.5320 - auc: 0.6568 - val_loss: 1.0109 - val_accuracy: 0.4611 - val_recall: 0.2389 - val_true_negatives: 2342.0000 - val_false_positives: 178.0000 - val_precision: 0.6284 - val_auc: 0.6694\n",
      "Epoch 29/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.9999 - accuracy: 0.4901 - recall: 0.2122 - true_negatives: 5436.0000 - false_positives: 444.0000 - precision: 0.5843 - auc: 0.6864 - val_loss: 0.9939 - val_accuracy: 0.4984 - val_recall: 0.2159 - val_true_negatives: 2351.0000 - val_false_positives: 169.0000 - val_precision: 0.6168 - val_auc: 0.6958\n",
      "Epoch 30/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 1.0060 - accuracy: 0.4929 - recall: 0.2252 - true_negatives: 5423.0000 - false_positives: 457.0000 - precision: 0.5916 - auc: 0.6801 - val_loss: 0.9742 - val_accuracy: 0.5294 - val_recall: 0.1659 - val_true_negatives: 2426.0000 - val_false_positives: 94.0000 - val_precision: 0.6898 - val_auc: 0.7217\n",
      "Epoch 31/200\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.9800 - accuracy: 0.5150 - recall: 0.2248 - true_negatives: 5517.0000 - false_positives: 363.0000 - precision: 0.6455 - auc: 0.7069 - val_loss: 0.9840 - val_accuracy: 0.5095 - val_recall: 0.2040 - val_true_negatives: 2299.0000 - val_false_positives: 221.0000 - val_precision: 0.5377 - val_auc: 0.7008\n",
      "Epoch 32/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.9839 - accuracy: 0.5095 - recall: 0.2340 - true_negatives: 5437.0000 - false_positives: 443.0000 - precision: 0.6083 - auc: 0.7024 - val_loss: 0.9685 - val_accuracy: 0.5381 - val_recall: 0.2119 - val_true_negatives: 2394.0000 - val_false_positives: 126.0000 - val_precision: 0.6794 - val_auc: 0.7266\n",
      "Epoch 33/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.9720 - accuracy: 0.5231 - recall: 0.2378 - true_negatives: 5463.0000 - false_positives: 417.0000 - precision: 0.6263 - auc: 0.7158 - val_loss: 0.9628 - val_accuracy: 0.5532 - val_recall: 0.2246 - val_true_negatives: 2417.0000 - val_false_positives: 103.0000 - val_precision: 0.7332 - val_auc: 0.7349\n",
      "Epoch 34/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.9863 - accuracy: 0.5170 - recall: 0.2408 - true_negatives: 5402.0000 - false_positives: 478.0000 - precision: 0.5970 - auc: 0.7005 - val_loss: 0.9852 - val_accuracy: 0.5262 - val_recall: 0.2365 - val_true_negatives: 2329.0000 - val_false_positives: 191.0000 - val_precision: 0.6094 - val_auc: 0.6965\n",
      "Epoch 35/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.9705 - accuracy: 0.5245 - recall: 0.2384 - true_negatives: 5491.0000 - false_positives: 389.0000 - precision: 0.6431 - auc: 0.7169 - val_loss: 0.9438 - val_accuracy: 0.5817 - val_recall: 0.2103 - val_true_negatives: 2425.0000 - val_false_positives: 95.0000 - val_precision: 0.7361 - val_auc: 0.7560\n",
      "Epoch 36/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.9870 - accuracy: 0.4976 - recall: 0.2806 - true_negatives: 5285.0000 - false_positives: 595.0000 - precision: 0.5810 - auc: 0.6942 - val_loss: 0.9434 - val_accuracy: 0.5556 - val_recall: 0.2175 - val_true_negatives: 2411.0000 - val_false_positives: 109.0000 - val_precision: 0.7154 - val_auc: 0.7521\n",
      "Epoch 37/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.9726 - accuracy: 0.5177 - recall: 0.2544 - true_negatives: 5426.0000 - false_positives: 454.0000 - precision: 0.6223 - auc: 0.7098 - val_loss: 0.9641 - val_accuracy: 0.5008 - val_recall: 0.2651 - val_true_negatives: 2324.0000 - val_false_positives: 196.0000 - val_precision: 0.6302 - val_auc: 0.7162\n",
      "Epoch 38/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.9765 - accuracy: 0.5235 - recall: 0.2741 - true_negatives: 5382.0000 - false_positives: 498.0000 - precision: 0.6181 - auc: 0.7073 - val_loss: 0.9988 - val_accuracy: 0.4643 - val_recall: 0.3111 - val_true_negatives: 2188.0000 - val_false_positives: 332.0000 - val_precision: 0.5414 - val_auc: 0.6831\n",
      "Epoch 39/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.9794 - accuracy: 0.5037 - recall: 0.2878 - true_negatives: 5326.0000 - false_positives: 554.0000 - precision: 0.6043 - auc: 0.7032 - val_loss: 0.9662 - val_accuracy: 0.4937 - val_recall: 0.2849 - val_true_negatives: 2186.0000 - val_false_positives: 334.0000 - val_precision: 0.5180 - val_auc: 0.7104\n",
      "Epoch 40/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.9534 - accuracy: 0.5452 - recall: 0.2765 - true_negatives: 5414.0000 - false_positives: 466.0000 - precision: 0.6357 - auc: 0.7303 - val_loss: 0.9333 - val_accuracy: 0.5603 - val_recall: 0.2651 - val_true_negatives: 2381.0000 - val_false_positives: 139.0000 - val_precision: 0.7061 - val_auc: 0.7559\n",
      "Epoch 41/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.9468 - accuracy: 0.5439 - recall: 0.2772 - true_negatives: 5481.0000 - false_positives: 399.0000 - precision: 0.6713 - auc: 0.7354 - val_loss: 0.9229 - val_accuracy: 0.5881 - val_recall: 0.2516 - val_true_negatives: 2412.0000 - val_false_positives: 108.0000 - val_precision: 0.7459 - val_auc: 0.7678\n",
      "Epoch 42/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.9492 - accuracy: 0.5412 - recall: 0.2765 - true_negatives: 5431.0000 - false_positives: 449.0000 - precision: 0.6442 - auc: 0.7328 - val_loss: 0.9385 - val_accuracy: 0.5444 - val_recall: 0.2683 - val_true_negatives: 2312.0000 - val_false_positives: 208.0000 - val_precision: 0.6190 - val_auc: 0.7382\n",
      "Epoch 43/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.9676 - accuracy: 0.5116 - recall: 0.2871 - true_negatives: 5339.0000 - false_positives: 541.0000 - precision: 0.6094 - auc: 0.7117 - val_loss: 0.9566 - val_accuracy: 0.5048 - val_recall: 0.2913 - val_true_negatives: 2319.0000 - val_false_positives: 201.0000 - val_precision: 0.6461 - val_auc: 0.7173\n",
      "Epoch 44/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.9595 - accuracy: 0.5327 - recall: 0.3218 - true_negatives: 5316.0000 - false_positives: 564.0000 - precision: 0.6265 - auc: 0.7188 - val_loss: 0.9509 - val_accuracy: 0.5484 - val_recall: 0.3413 - val_true_negatives: 2307.0000 - val_false_positives: 213.0000 - val_precision: 0.6687 - val_auc: 0.7275\n",
      "Epoch 45/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.9694 - accuracy: 0.5201 - recall: 0.3051 - true_negatives: 5275.0000 - false_positives: 605.0000 - precision: 0.5972 - auc: 0.7110 - val_loss: 1.0282 - val_accuracy: 0.4532 - val_recall: 0.3373 - val_true_negatives: 2106.0000 - val_false_positives: 414.0000 - val_precision: 0.5066 - val_auc: 0.6690\n",
      "Epoch 46/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.9838 - accuracy: 0.5007 - recall: 0.3163 - true_negatives: 5220.0000 - false_positives: 660.0000 - precision: 0.5849 - auc: 0.6991 - val_loss: 0.9167 - val_accuracy: 0.5690 - val_recall: 0.2968 - val_true_negatives: 2366.0000 - val_false_positives: 154.0000 - val_precision: 0.7083 - val_auc: 0.7657\n",
      "Epoch 47/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.9623 - accuracy: 0.5293 - recall: 0.3299 - true_negatives: 5256.0000 - false_positives: 624.0000 - precision: 0.6085 - auc: 0.7193 - val_loss: 0.9264 - val_accuracy: 0.5548 - val_recall: 0.2937 - val_true_negatives: 2291.0000 - val_false_positives: 229.0000 - val_precision: 0.6177 - val_auc: 0.7475\n",
      "Epoch 48/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.9344 - accuracy: 0.5463 - recall: 0.3126 - true_negatives: 5395.0000 - false_positives: 485.0000 - precision: 0.6546 - auc: 0.7409 - val_loss: 0.9698 - val_accuracy: 0.5127 - val_recall: 0.3595 - val_true_negatives: 2233.0000 - val_false_positives: 287.0000 - val_precision: 0.6122 - val_auc: 0.7096\n",
      "Epoch 49/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.9626 - accuracy: 0.5136 - recall: 0.3252 - true_negatives: 5217.0000 - false_positives: 663.0000 - precision: 0.5905 - auc: 0.7145 - val_loss: 0.9109 - val_accuracy: 0.5730 - val_recall: 0.3087 - val_true_negatives: 2367.0000 - val_false_positives: 153.0000 - val_precision: 0.7177 - val_auc: 0.7692\n",
      "Epoch 50/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.9550 - accuracy: 0.5340 - recall: 0.3272 - true_negatives: 5273.0000 - false_positives: 607.0000 - precision: 0.6131 - auc: 0.7249 - val_loss: 1.0398 - val_accuracy: 0.4437 - val_recall: 0.3484 - val_true_negatives: 2058.0000 - val_false_positives: 462.0000 - val_precision: 0.4872 - val_auc: 0.6753\n",
      "Epoch 51/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.9787 - accuracy: 0.4986 - recall: 0.3248 - true_negatives: 5180.0000 - false_positives: 700.0000 - precision: 0.5770 - auc: 0.7028 - val_loss: 0.9100 - val_accuracy: 0.5714 - val_recall: 0.3079 - val_true_negatives: 2321.0000 - val_false_positives: 199.0000 - val_precision: 0.6610 - val_auc: 0.7653\n",
      "Epoch 52/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.9267 - accuracy: 0.5551 - recall: 0.3293 - true_negatives: 5396.0000 - false_positives: 484.0000 - precision: 0.6667 - auc: 0.7481 - val_loss: 0.9005 - val_accuracy: 0.5968 - val_recall: 0.3143 - val_true_negatives: 2365.0000 - val_false_positives: 155.0000 - val_precision: 0.7187 - val_auc: 0.7775\n",
      "Epoch 53/200\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.9347 - accuracy: 0.5578 - recall: 0.3238 - true_negatives: 5339.0000 - false_positives: 541.0000 - precision: 0.6376 - auc: 0.7392 - val_loss: 0.8967 - val_accuracy: 0.5984 - val_recall: 0.3079 - val_true_negatives: 2365.0000 - val_false_positives: 155.0000 - val_precision: 0.7145 - val_auc: 0.7803\n",
      "Epoch 54/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.9253 - accuracy: 0.5463 - recall: 0.3350 - true_negatives: 5353.0000 - false_positives: 527.0000 - precision: 0.6515 - auc: 0.7448 - val_loss: 0.8928 - val_accuracy: 0.5976 - val_recall: 0.3167 - val_true_negatives: 2364.0000 - val_false_positives: 156.0000 - val_precision: 0.7189 - val_auc: 0.7826\n",
      "Epoch 55/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.9461 - accuracy: 0.5476 - recall: 0.3432 - true_negatives: 5280.0000 - false_positives: 600.0000 - precision: 0.6271 - auc: 0.7291 - val_loss: 1.0426 - val_accuracy: 0.4603 - val_recall: 0.3603 - val_true_negatives: 2060.0000 - val_false_positives: 460.0000 - val_precision: 0.4967 - val_auc: 0.6707\n",
      "Epoch 56/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.9682 - accuracy: 0.5058 - recall: 0.3432 - true_negatives: 5151.0000 - false_positives: 729.0000 - precision: 0.5806 - auc: 0.7108 - val_loss: 0.9544 - val_accuracy: 0.5183 - val_recall: 0.3556 - val_true_negatives: 2178.0000 - val_false_positives: 342.0000 - val_precision: 0.5671 - val_auc: 0.7193\n",
      "Epoch 57/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.9461 - accuracy: 0.5333 - recall: 0.3282 - true_negatives: 5292.0000 - false_positives: 588.0000 - precision: 0.6214 - auc: 0.7277 - val_loss: 0.9152 - val_accuracy: 0.5452 - val_recall: 0.3143 - val_true_negatives: 2282.0000 - val_false_positives: 238.0000 - val_precision: 0.6246 - val_auc: 0.7537\n",
      "Epoch 58/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.9154 - accuracy: 0.5728 - recall: 0.3248 - true_negatives: 5435.0000 - false_positives: 445.0000 - precision: 0.6821 - auc: 0.7587 - val_loss: 0.9314 - val_accuracy: 0.5452 - val_recall: 0.3381 - val_true_negatives: 2270.0000 - val_false_positives: 250.0000 - val_precision: 0.6302 - val_auc: 0.7404\n",
      "Epoch 59/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.9395 - accuracy: 0.5395 - recall: 0.3255 - true_negatives: 5326.0000 - false_positives: 554.0000 - precision: 0.6334 - auc: 0.7340 - val_loss: 0.9053 - val_accuracy: 0.5619 - val_recall: 0.3262 - val_true_negatives: 2350.0000 - val_false_positives: 170.0000 - val_precision: 0.7074 - val_auc: 0.7657\n",
      "Epoch 60/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.9299 - accuracy: 0.5483 - recall: 0.3265 - true_negatives: 5339.0000 - false_positives: 541.0000 - precision: 0.6396 - auc: 0.7412 - val_loss: 0.8897 - val_accuracy: 0.5921 - val_recall: 0.3230 - val_true_negatives: 2369.0000 - val_false_positives: 151.0000 - val_precision: 0.7294 - val_auc: 0.7841\n",
      "Epoch 61/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.9096 - accuracy: 0.5707 - recall: 0.3255 - true_negatives: 5419.0000 - false_positives: 461.0000 - precision: 0.6749 - auc: 0.7617 - val_loss: 0.9076 - val_accuracy: 0.5571 - val_recall: 0.3167 - val_true_negatives: 2347.0000 - val_false_positives: 173.0000 - val_precision: 0.6976 - val_auc: 0.7604\n",
      "Epoch 62/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.9187 - accuracy: 0.5602 - recall: 0.3408 - true_negatives: 5370.0000 - false_positives: 510.0000 - precision: 0.6627 - auc: 0.7522 - val_loss: 0.9219 - val_accuracy: 0.5333 - val_recall: 0.3278 - val_true_negatives: 2317.0000 - val_false_positives: 203.0000 - val_precision: 0.6705 - val_auc: 0.7447\n",
      "Epoch 63/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.9715 - accuracy: 0.5194 - recall: 0.3558 - true_negatives: 5148.0000 - false_positives: 732.0000 - precision: 0.5883 - auc: 0.7120 - val_loss: 0.8959 - val_accuracy: 0.5714 - val_recall: 0.3659 - val_true_negatives: 2324.0000 - val_false_positives: 196.0000 - val_precision: 0.7017 - val_auc: 0.7719\n",
      "Epoch 64/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.9130 - accuracy: 0.5626 - recall: 0.3493 - true_negatives: 5347.0000 - false_positives: 533.0000 - precision: 0.6583 - auc: 0.7559 - val_loss: 0.9481 - val_accuracy: 0.4897 - val_recall: 0.3325 - val_true_negatives: 2240.0000 - val_false_positives: 280.0000 - val_precision: 0.5994 - val_auc: 0.7203\n",
      "Epoch 65/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.9230 - accuracy: 0.5418 - recall: 0.3490 - true_negatives: 5307.0000 - false_positives: 573.0000 - precision: 0.6417 - auc: 0.7444 - val_loss: 0.8828 - val_accuracy: 0.5849 - val_recall: 0.3405 - val_true_negatives: 2318.0000 - val_false_positives: 202.0000 - val_precision: 0.6799 - val_auc: 0.7824\n",
      "Epoch 66/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.9363 - accuracy: 0.5446 - recall: 0.3514 - true_negatives: 5244.0000 - false_positives: 636.0000 - precision: 0.6189 - auc: 0.7351 - val_loss: 0.9719 - val_accuracy: 0.4960 - val_recall: 0.3611 - val_true_negatives: 2159.0000 - val_false_positives: 361.0000 - val_precision: 0.5576 - val_auc: 0.7090\n",
      "Epoch 67/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.9308 - accuracy: 0.5405 - recall: 0.3534 - true_negatives: 5275.0000 - false_positives: 605.0000 - precision: 0.6320 - auc: 0.7391 - val_loss: 0.9095 - val_accuracy: 0.5698 - val_recall: 0.3714 - val_true_negatives: 2272.0000 - val_false_positives: 248.0000 - val_precision: 0.6536 - val_auc: 0.7566\n",
      "Epoch 68/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.9262 - accuracy: 0.5517 - recall: 0.3762 - true_negatives: 5228.0000 - false_positives: 652.0000 - precision: 0.6291 - auc: 0.7437 - val_loss: 0.9120 - val_accuracy: 0.5349 - val_recall: 0.3825 - val_true_negatives: 2171.0000 - val_false_positives: 349.0000 - val_precision: 0.5800 - val_auc: 0.7470\n",
      "Epoch 69/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.9112 - accuracy: 0.5609 - recall: 0.3711 - true_negatives: 5275.0000 - false_positives: 605.0000 - precision: 0.6433 - auc: 0.7551 - val_loss: 0.9005 - val_accuracy: 0.5524 - val_recall: 0.3468 - val_true_negatives: 2334.0000 - val_false_positives: 186.0000 - val_precision: 0.7014 - val_auc: 0.7633\n",
      "Epoch 70/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.9358 - accuracy: 0.5466 - recall: 0.3762 - true_negatives: 5231.0000 - false_positives: 649.0000 - precision: 0.6302 - auc: 0.7391 - val_loss: 0.9177 - val_accuracy: 0.5690 - val_recall: 0.3611 - val_true_negatives: 2273.0000 - val_false_positives: 247.0000 - val_precision: 0.6481 - val_auc: 0.7499\n",
      "Epoch 71/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.9176 - accuracy: 0.5650 - recall: 0.3602 - true_negatives: 5298.0000 - false_positives: 582.0000 - precision: 0.6453 - auc: 0.7523 - val_loss: 0.8931 - val_accuracy: 0.5778 - val_recall: 0.3659 - val_true_negatives: 2294.0000 - val_false_positives: 226.0000 - val_precision: 0.6710 - val_auc: 0.7697\n",
      "Epoch 72/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.9101 - accuracy: 0.5609 - recall: 0.3694 - true_negatives: 5301.0000 - false_positives: 579.0000 - precision: 0.6523 - auc: 0.7555 - val_loss: 0.8806 - val_accuracy: 0.5794 - val_recall: 0.3849 - val_true_negatives: 2324.0000 - val_false_positives: 196.0000 - val_precision: 0.7122 - val_auc: 0.7804\n",
      "Epoch 73/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.9146 - accuracy: 0.5650 - recall: 0.3701 - true_negatives: 5299.0000 - false_positives: 581.0000 - precision: 0.6519 - auc: 0.7523 - val_loss: 0.8924 - val_accuracy: 0.5667 - val_recall: 0.3556 - val_true_negatives: 2314.0000 - val_false_positives: 206.0000 - val_precision: 0.6850 - val_auc: 0.7681\n",
      "Epoch 74/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8958 - accuracy: 0.5755 - recall: 0.3690 - true_negatives: 5319.0000 - false_positives: 561.0000 - precision: 0.6592 - auc: 0.7657 - val_loss: 0.8903 - val_accuracy: 0.5714 - val_recall: 0.3619 - val_true_negatives: 2306.0000 - val_false_positives: 214.0000 - val_precision: 0.6806 - val_auc: 0.7700\n",
      "Epoch 75/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.9025 - accuracy: 0.5752 - recall: 0.3588 - true_negatives: 5332.0000 - false_positives: 548.0000 - precision: 0.6581 - auc: 0.7616 - val_loss: 0.8843 - val_accuracy: 0.5825 - val_recall: 0.3698 - val_true_negatives: 2253.0000 - val_false_positives: 267.0000 - val_precision: 0.6357 - val_auc: 0.7730\n",
      "Epoch 76/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.9015 - accuracy: 0.5748 - recall: 0.3776 - true_negatives: 5308.0000 - false_positives: 572.0000 - precision: 0.6599 - auc: 0.7618 - val_loss: 0.8847 - val_accuracy: 0.5897 - val_recall: 0.3746 - val_true_negatives: 2321.0000 - val_false_positives: 199.0000 - val_precision: 0.7034 - val_auc: 0.7759\n",
      "Epoch 77/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.9042 - accuracy: 0.5660 - recall: 0.3844 - true_negatives: 5244.0000 - false_positives: 636.0000 - precision: 0.6399 - auc: 0.7582 - val_loss: 0.9139 - val_accuracy: 0.5492 - val_recall: 0.3778 - val_true_negatives: 2194.0000 - val_false_positives: 326.0000 - val_precision: 0.5935 - val_auc: 0.7491\n",
      "Epoch 78/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.9183 - accuracy: 0.5622 - recall: 0.3837 - true_negatives: 5221.0000 - false_positives: 659.0000 - precision: 0.6312 - auc: 0.7502 - val_loss: 0.8739 - val_accuracy: 0.5905 - val_recall: 0.3659 - val_true_negatives: 2329.0000 - val_false_positives: 191.0000 - val_precision: 0.7071 - val_auc: 0.7836\n",
      "Epoch 79/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.9340 - accuracy: 0.5361 - recall: 0.3524 - true_negatives: 5236.0000 - false_positives: 644.0000 - precision: 0.6167 - auc: 0.7384 - val_loss: 0.9820 - val_accuracy: 0.4992 - val_recall: 0.3786 - val_true_negatives: 2127.0000 - val_false_positives: 393.0000 - val_precision: 0.5483 - val_auc: 0.7065\n",
      "Epoch 80/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.9201 - accuracy: 0.5493 - recall: 0.3840 - true_negatives: 5241.0000 - false_positives: 639.0000 - precision: 0.6386 - auc: 0.7458 - val_loss: 0.8673 - val_accuracy: 0.6151 - val_recall: 0.3603 - val_true_negatives: 2318.0000 - val_false_positives: 202.0000 - val_precision: 0.6921 - val_auc: 0.7921\n",
      "Epoch 81/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8882 - accuracy: 0.5898 - recall: 0.3605 - true_negatives: 5358.0000 - false_positives: 522.0000 - precision: 0.6700 - auc: 0.7728 - val_loss: 0.8671 - val_accuracy: 0.6071 - val_recall: 0.3698 - val_true_negatives: 2312.0000 - val_false_positives: 208.0000 - val_precision: 0.6914 - val_auc: 0.7904\n",
      "Epoch 82/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8868 - accuracy: 0.5844 - recall: 0.3765 - true_negatives: 5346.0000 - false_positives: 534.0000 - precision: 0.6746 - auc: 0.7729 - val_loss: 0.8913 - val_accuracy: 0.5754 - val_recall: 0.3730 - val_true_negatives: 2267.0000 - val_false_positives: 253.0000 - val_precision: 0.6501 - val_auc: 0.7674\n",
      "Epoch 83/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8991 - accuracy: 0.5714 - recall: 0.3830 - true_negatives: 5287.0000 - false_positives: 593.0000 - precision: 0.6550 - auc: 0.7619 - val_loss: 0.9217 - val_accuracy: 0.5349 - val_recall: 0.4286 - val_true_negatives: 2207.0000 - val_false_positives: 313.0000 - val_precision: 0.6331 - val_auc: 0.7454\n",
      "Epoch 84/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.9017 - accuracy: 0.5653 - recall: 0.3854 - true_negatives: 5261.0000 - false_positives: 619.0000 - precision: 0.6467 - auc: 0.7603 - val_loss: 0.8557 - val_accuracy: 0.6167 - val_recall: 0.3754 - val_true_negatives: 2356.0000 - val_false_positives: 164.0000 - val_precision: 0.7425 - val_auc: 0.8006\n",
      "Epoch 85/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8877 - accuracy: 0.5816 - recall: 0.3908 - true_negatives: 5309.0000 - false_positives: 571.0000 - precision: 0.6680 - auc: 0.7697 - val_loss: 0.8613 - val_accuracy: 0.5889 - val_recall: 0.4000 - val_true_negatives: 2327.0000 - val_false_positives: 193.0000 - val_precision: 0.7231 - val_auc: 0.7920\n",
      "Epoch 86/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8870 - accuracy: 0.5765 - recall: 0.3871 - true_negatives: 5302.0000 - false_positives: 578.0000 - precision: 0.6632 - auc: 0.7695 - val_loss: 0.8711 - val_accuracy: 0.5905 - val_recall: 0.4095 - val_true_negatives: 2240.0000 - val_false_positives: 280.0000 - val_precision: 0.6482 - val_auc: 0.7802\n",
      "Epoch 87/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8939 - accuracy: 0.5793 - recall: 0.3884 - true_negatives: 5269.0000 - false_positives: 611.0000 - precision: 0.6515 - auc: 0.7658 - val_loss: 0.8540 - val_accuracy: 0.5992 - val_recall: 0.4008 - val_true_negatives: 2332.0000 - val_false_positives: 188.0000 - val_precision: 0.7287 - val_auc: 0.7980\n",
      "Epoch 88/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.9233 - accuracy: 0.5571 - recall: 0.3942 - true_negatives: 5174.0000 - false_positives: 706.0000 - precision: 0.6214 - auc: 0.7471 - val_loss: 0.8832 - val_accuracy: 0.5913 - val_recall: 0.3857 - val_true_negatives: 2273.0000 - val_false_positives: 247.0000 - val_precision: 0.6630 - val_auc: 0.7737\n",
      "Epoch 89/200\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.8906 - accuracy: 0.5701 - recall: 0.3918 - true_negatives: 5267.0000 - false_positives: 613.0000 - precision: 0.6527 - auc: 0.7664 - val_loss: 0.9719 - val_accuracy: 0.5087 - val_recall: 0.3810 - val_true_negatives: 2126.0000 - val_false_positives: 394.0000 - val_precision: 0.5492 - val_auc: 0.7171\n",
      "Epoch 90/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.9008 - accuracy: 0.5650 - recall: 0.3861 - true_negatives: 5228.0000 - false_positives: 652.0000 - precision: 0.6351 - auc: 0.7593 - val_loss: 1.0312 - val_accuracy: 0.4373 - val_recall: 0.3492 - val_true_negatives: 2082.0000 - val_false_positives: 438.0000 - val_precision: 0.5011 - val_auc: 0.6836\n",
      "Epoch 91/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.9214 - accuracy: 0.5469 - recall: 0.3874 - true_negatives: 5188.0000 - false_positives: 692.0000 - precision: 0.6221 - auc: 0.7450 - val_loss: 0.9244 - val_accuracy: 0.5421 - val_recall: 0.3960 - val_true_negatives: 2177.0000 - val_false_positives: 343.0000 - val_precision: 0.5926 - val_auc: 0.7426\n",
      "Epoch 92/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.9016 - accuracy: 0.5684 - recall: 0.4024 - true_negatives: 5215.0000 - false_positives: 665.0000 - precision: 0.6402 - auc: 0.7610 - val_loss: 0.8939 - val_accuracy: 0.5532 - val_recall: 0.4079 - val_true_negatives: 2200.0000 - val_false_positives: 320.0000 - val_precision: 0.6163 - val_auc: 0.7628\n",
      "Epoch 93/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8880 - accuracy: 0.5707 - recall: 0.4031 - true_negatives: 5277.0000 - false_positives: 603.0000 - precision: 0.6628 - auc: 0.7693 - val_loss: 0.8782 - val_accuracy: 0.5762 - val_recall: 0.3976 - val_true_negatives: 2243.0000 - val_false_positives: 277.0000 - val_precision: 0.6440 - val_auc: 0.7756\n",
      "Epoch 94/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8806 - accuracy: 0.5762 - recall: 0.4156 - true_negatives: 5249.0000 - false_positives: 631.0000 - precision: 0.6595 - auc: 0.7740 - val_loss: 0.8818 - val_accuracy: 0.5690 - val_recall: 0.4246 - val_true_negatives: 2248.0000 - val_false_positives: 272.0000 - val_precision: 0.6629 - val_auc: 0.7719\n",
      "Epoch 95/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.9248 - accuracy: 0.5422 - recall: 0.4078 - true_negatives: 5127.0000 - false_positives: 753.0000 - precision: 0.6142 - auc: 0.7435 - val_loss: 0.8553 - val_accuracy: 0.6246 - val_recall: 0.3897 - val_true_negatives: 2319.0000 - val_false_positives: 201.0000 - val_precision: 0.7095 - val_auc: 0.7956\n",
      "Epoch 96/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8791 - accuracy: 0.5847 - recall: 0.3990 - true_negatives: 5312.0000 - false_positives: 568.0000 - precision: 0.6738 - auc: 0.7757 - val_loss: 0.8406 - val_accuracy: 0.6222 - val_recall: 0.4040 - val_true_negatives: 2325.0000 - val_false_positives: 195.0000 - val_precision: 0.7230 - val_auc: 0.8091\n",
      "Epoch 97/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8738 - accuracy: 0.5898 - recall: 0.4109 - true_negatives: 5302.0000 - false_positives: 578.0000 - precision: 0.6764 - auc: 0.7793 - val_loss: 0.9543 - val_accuracy: 0.5230 - val_recall: 0.4087 - val_true_negatives: 2112.0000 - val_false_positives: 408.0000 - val_precision: 0.5580 - val_auc: 0.7273\n",
      "Epoch 98/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8867 - accuracy: 0.5776 - recall: 0.4139 - true_negatives: 5225.0000 - false_positives: 655.0000 - precision: 0.6501 - auc: 0.7682 - val_loss: 0.9140 - val_accuracy: 0.5429 - val_recall: 0.4167 - val_true_negatives: 2158.0000 - val_false_positives: 362.0000 - val_precision: 0.5919 - val_auc: 0.7499\n",
      "Epoch 99/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.9055 - accuracy: 0.5582 - recall: 0.4048 - true_negatives: 5202.0000 - false_positives: 678.0000 - precision: 0.6370 - auc: 0.7558 - val_loss: 0.8588 - val_accuracy: 0.6008 - val_recall: 0.3968 - val_true_negatives: 2324.0000 - val_false_positives: 196.0000 - val_precision: 0.7184 - val_auc: 0.7908\n",
      "Epoch 100/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.9377 - accuracy: 0.5510 - recall: 0.4003 - true_negatives: 5121.0000 - false_positives: 759.0000 - precision: 0.6080 - auc: 0.7405 - val_loss: 0.9278 - val_accuracy: 0.5365 - val_recall: 0.3921 - val_true_negatives: 2165.0000 - val_false_positives: 355.0000 - val_precision: 0.5819 - val_auc: 0.7398\n",
      "Epoch 101/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.9025 - accuracy: 0.5609 - recall: 0.3990 - true_negatives: 5219.0000 - false_positives: 661.0000 - precision: 0.6396 - auc: 0.7570 - val_loss: 0.8670 - val_accuracy: 0.6032 - val_recall: 0.4032 - val_true_negatives: 2257.0000 - val_false_positives: 263.0000 - val_precision: 0.6589 - val_auc: 0.7837\n",
      "Epoch 102/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8772 - accuracy: 0.5833 - recall: 0.4286 - true_negatives: 5245.0000 - false_positives: 635.0000 - precision: 0.6649 - auc: 0.7753 - val_loss: 0.8382 - val_accuracy: 0.6246 - val_recall: 0.4087 - val_true_negatives: 2334.0000 - val_false_positives: 186.0000 - val_precision: 0.7347 - val_auc: 0.8097\n",
      "Epoch 103/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8712 - accuracy: 0.5959 - recall: 0.4218 - true_negatives: 5268.0000 - false_positives: 612.0000 - precision: 0.6695 - auc: 0.7809 - val_loss: 0.8608 - val_accuracy: 0.6167 - val_recall: 0.4071 - val_true_negatives: 2279.0000 - val_false_positives: 241.0000 - val_precision: 0.6804 - val_auc: 0.7885\n",
      "Epoch 104/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8794 - accuracy: 0.5799 - recall: 0.4031 - true_negatives: 5296.0000 - false_positives: 584.0000 - precision: 0.6699 - auc: 0.7744 - val_loss: 0.8384 - val_accuracy: 0.6151 - val_recall: 0.4143 - val_true_negatives: 2306.0000 - val_false_positives: 214.0000 - val_precision: 0.7092 - val_auc: 0.8070\n",
      "Epoch 105/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8882 - accuracy: 0.5871 - recall: 0.4150 - true_negatives: 5274.0000 - false_positives: 606.0000 - precision: 0.6681 - auc: 0.7695 - val_loss: 1.0409 - val_accuracy: 0.4381 - val_recall: 0.3603 - val_true_negatives: 2061.0000 - val_false_positives: 459.0000 - val_precision: 0.4973 - val_auc: 0.6845\n",
      "Epoch 106/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.9069 - accuracy: 0.5738 - recall: 0.3939 - true_negatives: 5248.0000 - false_positives: 632.0000 - precision: 0.6469 - auc: 0.7589 - val_loss: 0.8515 - val_accuracy: 0.6214 - val_recall: 0.4048 - val_true_negatives: 2287.0000 - val_false_positives: 233.0000 - val_precision: 0.6864 - val_auc: 0.7954\n",
      "Epoch 107/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8618 - accuracy: 0.6034 - recall: 0.4269 - true_negatives: 5309.0000 - false_positives: 571.0000 - precision: 0.6873 - auc: 0.7876 - val_loss: 0.8454 - val_accuracy: 0.6175 - val_recall: 0.4127 - val_true_negatives: 2279.0000 - val_false_positives: 241.0000 - val_precision: 0.6833 - val_auc: 0.7994\n",
      "Epoch 108/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8669 - accuracy: 0.6014 - recall: 0.4306 - true_negatives: 5272.0000 - false_positives: 608.0000 - precision: 0.6756 - auc: 0.7839 - val_loss: 0.8386 - val_accuracy: 0.6270 - val_recall: 0.4246 - val_true_negatives: 2311.0000 - val_false_positives: 209.0000 - val_precision: 0.7191 - val_auc: 0.8056\n",
      "Epoch 109/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8582 - accuracy: 0.5922 - recall: 0.4276 - true_negatives: 5284.0000 - false_positives: 596.0000 - precision: 0.6784 - auc: 0.7879 - val_loss: 0.8392 - val_accuracy: 0.6135 - val_recall: 0.4270 - val_true_negatives: 2306.0000 - val_false_positives: 214.0000 - val_precision: 0.7154 - val_auc: 0.8038\n",
      "Epoch 110/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8725 - accuracy: 0.5867 - recall: 0.4337 - true_negatives: 5207.0000 - false_positives: 673.0000 - precision: 0.6545 - auc: 0.7775 - val_loss: 0.8691 - val_accuracy: 0.5889 - val_recall: 0.4548 - val_true_negatives: 2188.0000 - val_false_positives: 332.0000 - val_precision: 0.6331 - val_auc: 0.7771\n",
      "Epoch 111/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8755 - accuracy: 0.5789 - recall: 0.4371 - true_negatives: 5208.0000 - false_positives: 672.0000 - precision: 0.6566 - auc: 0.7756 - val_loss: 0.8480 - val_accuracy: 0.6048 - val_recall: 0.4159 - val_true_negatives: 2261.0000 - val_false_positives: 259.0000 - val_precision: 0.6692 - val_auc: 0.7960\n",
      "Epoch 112/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8634 - accuracy: 0.5935 - recall: 0.4310 - true_negatives: 5260.0000 - false_positives: 620.0000 - precision: 0.6714 - auc: 0.7844 - val_loss: 0.8720 - val_accuracy: 0.5960 - val_recall: 0.4214 - val_true_negatives: 2247.0000 - val_false_positives: 273.0000 - val_precision: 0.6604 - val_auc: 0.7785\n",
      "Epoch 113/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8706 - accuracy: 0.5769 - recall: 0.4330 - true_negatives: 5223.0000 - false_positives: 657.0000 - precision: 0.6596 - auc: 0.7773 - val_loss: 0.9905 - val_accuracy: 0.4968 - val_recall: 0.4087 - val_true_negatives: 2073.0000 - val_false_positives: 447.0000 - val_precision: 0.5353 - val_auc: 0.7144\n",
      "Epoch 114/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8722 - accuracy: 0.5935 - recall: 0.4408 - true_negatives: 5255.0000 - false_positives: 625.0000 - precision: 0.6746 - auc: 0.7801 - val_loss: 0.8946 - val_accuracy: 0.5762 - val_recall: 0.4437 - val_true_negatives: 2203.0000 - val_false_positives: 317.0000 - val_precision: 0.6381 - val_auc: 0.7634\n",
      "Epoch 115/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8589 - accuracy: 0.5983 - recall: 0.4374 - true_negatives: 5256.0000 - false_positives: 624.0000 - precision: 0.6733 - auc: 0.7867 - val_loss: 0.8579 - val_accuracy: 0.6024 - val_recall: 0.4190 - val_true_negatives: 2270.0000 - val_false_positives: 250.0000 - val_precision: 0.6787 - val_auc: 0.7881\n",
      "Epoch 116/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8748 - accuracy: 0.5793 - recall: 0.4299 - true_negatives: 5194.0000 - false_positives: 686.0000 - precision: 0.6482 - auc: 0.7761 - val_loss: 0.8956 - val_accuracy: 0.5794 - val_recall: 0.4571 - val_true_negatives: 2203.0000 - val_false_positives: 317.0000 - val_precision: 0.6450 - val_auc: 0.7650\n",
      "Epoch 117/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8685 - accuracy: 0.5827 - recall: 0.4296 - true_negatives: 5237.0000 - false_positives: 643.0000 - precision: 0.6626 - auc: 0.7797 - val_loss: 0.8292 - val_accuracy: 0.6262 - val_recall: 0.4190 - val_true_negatives: 2346.0000 - val_false_positives: 174.0000 - val_precision: 0.7521 - val_auc: 0.8140\n",
      "Epoch 118/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8718 - accuracy: 0.5813 - recall: 0.4153 - true_negatives: 5286.0000 - false_positives: 594.0000 - precision: 0.6727 - auc: 0.7782 - val_loss: 0.8581 - val_accuracy: 0.6071 - val_recall: 0.4103 - val_true_negatives: 2290.0000 - val_false_positives: 230.0000 - val_precision: 0.6921 - val_auc: 0.7882\n",
      "Epoch 119/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8618 - accuracy: 0.6000 - recall: 0.4395 - true_negatives: 5269.0000 - false_positives: 611.0000 - precision: 0.6789 - auc: 0.7858 - val_loss: 0.8260 - val_accuracy: 0.6286 - val_recall: 0.4389 - val_true_negatives: 2312.0000 - val_false_positives: 208.0000 - val_precision: 0.7267 - val_auc: 0.8123\n",
      "Epoch 120/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8670 - accuracy: 0.5888 - recall: 0.4429 - true_negatives: 5251.0000 - false_positives: 629.0000 - precision: 0.6743 - auc: 0.7820 - val_loss: 0.8282 - val_accuracy: 0.6206 - val_recall: 0.4540 - val_true_negatives: 2246.0000 - val_false_positives: 274.0000 - val_precision: 0.6761 - val_auc: 0.8080\n",
      "Epoch 121/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8855 - accuracy: 0.5799 - recall: 0.4425 - true_negatives: 5160.0000 - false_positives: 720.0000 - precision: 0.6437 - auc: 0.7699 - val_loss: 0.9361 - val_accuracy: 0.5302 - val_recall: 0.4206 - val_true_negatives: 2144.0000 - val_false_positives: 376.0000 - val_precision: 0.5850 - val_auc: 0.7433\n",
      "Epoch 122/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8817 - accuracy: 0.5782 - recall: 0.4282 - true_negatives: 5181.0000 - false_positives: 699.0000 - precision: 0.6430 - auc: 0.7728 - val_loss: 0.9158 - val_accuracy: 0.5302 - val_recall: 0.4063 - val_true_negatives: 2198.0000 - val_false_positives: 322.0000 - val_precision: 0.6139 - val_auc: 0.7468\n",
      "Epoch 123/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8755 - accuracy: 0.5847 - recall: 0.4327 - true_negatives: 5214.0000 - false_positives: 666.0000 - precision: 0.6563 - auc: 0.7770 - val_loss: 0.8184 - val_accuracy: 0.6341 - val_recall: 0.4476 - val_true_negatives: 2311.0000 - val_false_positives: 209.0000 - val_precision: 0.7296 - val_auc: 0.8185\n",
      "Epoch 124/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8549 - accuracy: 0.5956 - recall: 0.4367 - true_negatives: 5247.0000 - false_positives: 633.0000 - precision: 0.6698 - auc: 0.7881 - val_loss: 0.8399 - val_accuracy: 0.5905 - val_recall: 0.4262 - val_true_negatives: 2293.0000 - val_false_positives: 227.0000 - val_precision: 0.7029 - val_auc: 0.7986\n",
      "Epoch 125/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.9554 - accuracy: 0.5415 - recall: 0.4187 - true_negatives: 5015.0000 - false_positives: 865.0000 - precision: 0.5873 - auc: 0.7307 - val_loss: 0.8772 - val_accuracy: 0.5810 - val_recall: 0.4230 - val_true_negatives: 2218.0000 - val_false_positives: 302.0000 - val_precision: 0.6383 - val_auc: 0.7736\n",
      "Epoch 126/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8534 - accuracy: 0.5912 - recall: 0.4303 - true_negatives: 5281.0000 - false_positives: 599.0000 - precision: 0.6786 - auc: 0.7903 - val_loss: 0.8221 - val_accuracy: 0.6230 - val_recall: 0.4389 - val_true_negatives: 2317.0000 - val_false_positives: 203.0000 - val_precision: 0.7315 - val_auc: 0.8150\n",
      "Epoch 127/200\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.8617 - accuracy: 0.5915 - recall: 0.4432 - true_negatives: 5244.0000 - false_positives: 636.0000 - precision: 0.6720 - auc: 0.7848 - val_loss: 0.8518 - val_accuracy: 0.5849 - val_recall: 0.4667 - val_true_negatives: 2183.0000 - val_false_positives: 337.0000 - val_precision: 0.6357 - val_auc: 0.7865\n",
      "Epoch 128/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8707 - accuracy: 0.5844 - recall: 0.4391 - true_negatives: 5205.0000 - false_positives: 675.0000 - precision: 0.6567 - auc: 0.7794 - val_loss: 0.9255 - val_accuracy: 0.5183 - val_recall: 0.3921 - val_true_negatives: 2175.0000 - val_false_positives: 345.0000 - val_precision: 0.5888 - val_auc: 0.7400\n",
      "Epoch 129/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8672 - accuracy: 0.5898 - recall: 0.4330 - true_negatives: 5229.0000 - false_positives: 651.0000 - precision: 0.6616 - auc: 0.7800 - val_loss: 0.8195 - val_accuracy: 0.6294 - val_recall: 0.4460 - val_true_negatives: 2314.0000 - val_false_positives: 206.0000 - val_precision: 0.7318 - val_auc: 0.8161\n",
      "Epoch 130/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8704 - accuracy: 0.5901 - recall: 0.4286 - true_negatives: 5230.0000 - false_positives: 650.0000 - precision: 0.6597 - auc: 0.7796 - val_loss: 0.8532 - val_accuracy: 0.5778 - val_recall: 0.4603 - val_true_negatives: 2180.0000 - val_false_positives: 340.0000 - val_precision: 0.6304 - val_auc: 0.7844\n",
      "Epoch 131/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8530 - accuracy: 0.6061 - recall: 0.4639 - true_negatives: 5219.0000 - false_positives: 661.0000 - precision: 0.6736 - auc: 0.7899 - val_loss: 0.9811 - val_accuracy: 0.4810 - val_recall: 0.3833 - val_true_negatives: 2120.0000 - val_false_positives: 400.0000 - val_precision: 0.5470 - val_auc: 0.7126\n",
      "Epoch 132/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8550 - accuracy: 0.5966 - recall: 0.4429 - true_negatives: 5247.0000 - false_positives: 633.0000 - precision: 0.6729 - auc: 0.7882 - val_loss: 0.8350 - val_accuracy: 0.6317 - val_recall: 0.4429 - val_true_negatives: 2279.0000 - val_false_positives: 241.0000 - val_precision: 0.6984 - val_auc: 0.8034\n",
      "Epoch 133/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8521 - accuracy: 0.5956 - recall: 0.4548 - true_negatives: 5265.0000 - false_positives: 615.0000 - precision: 0.6849 - auc: 0.7904 - val_loss: 0.8138 - val_accuracy: 0.6246 - val_recall: 0.4619 - val_true_negatives: 2295.0000 - val_false_positives: 225.0000 - val_precision: 0.7212 - val_auc: 0.8195\n",
      "Epoch 134/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8509 - accuracy: 0.6031 - recall: 0.4469 - true_negatives: 5253.0000 - false_positives: 627.0000 - precision: 0.6770 - auc: 0.7915 - val_loss: 0.8179 - val_accuracy: 0.6349 - val_recall: 0.4452 - val_true_negatives: 2312.0000 - val_false_positives: 208.0000 - val_precision: 0.7295 - val_auc: 0.8160\n",
      "Epoch 135/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8769 - accuracy: 0.5857 - recall: 0.4337 - true_negatives: 5197.0000 - false_positives: 683.0000 - precision: 0.6512 - auc: 0.7738 - val_loss: 0.8147 - val_accuracy: 0.6381 - val_recall: 0.4437 - val_true_negatives: 2313.0000 - val_false_positives: 207.0000 - val_precision: 0.7298 - val_auc: 0.8206\n",
      "Epoch 136/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8543 - accuracy: 0.5956 - recall: 0.4265 - true_negatives: 5294.0000 - false_positives: 586.0000 - precision: 0.6815 - auc: 0.7893 - val_loss: 0.8137 - val_accuracy: 0.6302 - val_recall: 0.4484 - val_true_negatives: 2314.0000 - val_false_positives: 206.0000 - val_precision: 0.7328 - val_auc: 0.8208\n",
      "Epoch 137/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8503 - accuracy: 0.6010 - recall: 0.4565 - true_negatives: 5245.0000 - false_positives: 635.0000 - precision: 0.6788 - auc: 0.7913 - val_loss: 0.8383 - val_accuracy: 0.6238 - val_recall: 0.4492 - val_true_negatives: 2267.0000 - val_false_positives: 253.0000 - val_precision: 0.6911 - val_auc: 0.8003\n",
      "Epoch 138/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8541 - accuracy: 0.5963 - recall: 0.4622 - true_negatives: 5211.0000 - false_positives: 669.0000 - precision: 0.6701 - auc: 0.7882 - val_loss: 0.8106 - val_accuracy: 0.6437 - val_recall: 0.4595 - val_true_negatives: 2305.0000 - val_false_positives: 215.0000 - val_precision: 0.7292 - val_auc: 0.8212\n",
      "Epoch 139/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8584 - accuracy: 0.5952 - recall: 0.4497 - true_negatives: 5211.0000 - false_positives: 669.0000 - precision: 0.6640 - auc: 0.7861 - val_loss: 0.9640 - val_accuracy: 0.5286 - val_recall: 0.4452 - val_true_negatives: 2091.0000 - val_false_positives: 429.0000 - val_precision: 0.5667 - val_auc: 0.7307\n",
      "Epoch 140/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8910 - accuracy: 0.5772 - recall: 0.4459 - true_negatives: 5124.0000 - false_positives: 756.0000 - precision: 0.6343 - auc: 0.7674 - val_loss: 0.8162 - val_accuracy: 0.6468 - val_recall: 0.4524 - val_true_negatives: 2299.0000 - val_false_positives: 221.0000 - val_precision: 0.7206 - val_auc: 0.8167\n",
      "Epoch 141/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8573 - accuracy: 0.5891 - recall: 0.4667 - true_negatives: 5170.0000 - false_positives: 710.0000 - precision: 0.6590 - auc: 0.7858 - val_loss: 0.8849 - val_accuracy: 0.5905 - val_recall: 0.4825 - val_true_negatives: 2165.0000 - val_false_positives: 355.0000 - val_precision: 0.6314 - val_auc: 0.7691\n",
      "Epoch 142/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8609 - accuracy: 0.6010 - recall: 0.4449 - true_negatives: 5233.0000 - false_positives: 647.0000 - precision: 0.6691 - auc: 0.7857 - val_loss: 0.8087 - val_accuracy: 0.6381 - val_recall: 0.4563 - val_true_negatives: 2304.0000 - val_false_positives: 216.0000 - val_precision: 0.7269 - val_auc: 0.8222\n",
      "Epoch 143/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8500 - accuracy: 0.5983 - recall: 0.4650 - true_negatives: 5237.0000 - false_positives: 643.0000 - precision: 0.6801 - auc: 0.7919 - val_loss: 0.8165 - val_accuracy: 0.6167 - val_recall: 0.4476 - val_true_negatives: 2298.0000 - val_false_positives: 222.0000 - val_precision: 0.7176 - val_auc: 0.8148\n",
      "Epoch 144/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8771 - accuracy: 0.5755 - recall: 0.4418 - true_negatives: 5216.0000 - false_positives: 664.0000 - precision: 0.6617 - auc: 0.7758 - val_loss: 0.8300 - val_accuracy: 0.6222 - val_recall: 0.4508 - val_true_negatives: 2243.0000 - val_false_positives: 277.0000 - val_precision: 0.6722 - val_auc: 0.8047\n",
      "Epoch 145/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8538 - accuracy: 0.5983 - recall: 0.4537 - true_negatives: 5203.0000 - false_positives: 677.0000 - precision: 0.6634 - auc: 0.7895 - val_loss: 0.9522 - val_accuracy: 0.5000 - val_recall: 0.3921 - val_true_negatives: 2138.0000 - val_false_positives: 382.0000 - val_precision: 0.5639 - val_auc: 0.7279\n",
      "Epoch 146/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8752 - accuracy: 0.5861 - recall: 0.4466 - true_negatives: 5183.0000 - false_positives: 697.0000 - precision: 0.6532 - auc: 0.7764 - val_loss: 0.8158 - val_accuracy: 0.6151 - val_recall: 0.4452 - val_true_negatives: 2302.0000 - val_false_positives: 218.0000 - val_precision: 0.7202 - val_auc: 0.8151\n",
      "Epoch 147/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8690 - accuracy: 0.5878 - recall: 0.4449 - true_negatives: 5177.0000 - false_positives: 703.0000 - precision: 0.6504 - auc: 0.7788 - val_loss: 1.0169 - val_accuracy: 0.4587 - val_recall: 0.3817 - val_true_negatives: 2065.0000 - val_false_positives: 455.0000 - val_precision: 0.5139 - val_auc: 0.7002\n",
      "Epoch 148/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8691 - accuracy: 0.5952 - recall: 0.4378 - true_negatives: 5201.0000 - false_positives: 679.0000 - precision: 0.6546 - auc: 0.7795 - val_loss: 0.8203 - val_accuracy: 0.6397 - val_recall: 0.4611 - val_true_negatives: 2293.0000 - val_false_positives: 227.0000 - val_precision: 0.7191 - val_auc: 0.8121\n",
      "Epoch 149/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8441 - accuracy: 0.5966 - recall: 0.4500 - true_negatives: 5242.0000 - false_positives: 638.0000 - precision: 0.6747 - auc: 0.7935 - val_loss: 0.8818 - val_accuracy: 0.5381 - val_recall: 0.4302 - val_true_negatives: 2203.0000 - val_false_positives: 317.0000 - val_precision: 0.6310 - val_auc: 0.7696\n",
      "Epoch 150/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8499 - accuracy: 0.5942 - recall: 0.4548 - true_negatives: 5251.0000 - false_positives: 629.0000 - precision: 0.6801 - auc: 0.7920 - val_loss: 0.8307 - val_accuracy: 0.6278 - val_recall: 0.4500 - val_true_negatives: 2235.0000 - val_false_positives: 285.0000 - val_precision: 0.6655 - val_auc: 0.8039\n",
      "Epoch 151/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8478 - accuracy: 0.5980 - recall: 0.4534 - true_negatives: 5198.0000 - false_positives: 682.0000 - precision: 0.6615 - auc: 0.7908 - val_loss: 0.8100 - val_accuracy: 0.6484 - val_recall: 0.4571 - val_true_negatives: 2300.0000 - val_false_positives: 220.0000 - val_precision: 0.7236 - val_auc: 0.8200\n",
      "Epoch 152/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8489 - accuracy: 0.5973 - recall: 0.4541 - true_negatives: 5251.0000 - false_positives: 629.0000 - precision: 0.6797 - auc: 0.7923 - val_loss: 0.8082 - val_accuracy: 0.6381 - val_recall: 0.4675 - val_true_negatives: 2296.0000 - val_false_positives: 224.0000 - val_precision: 0.7245 - val_auc: 0.8203\n",
      "Epoch 153/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8582 - accuracy: 0.6027 - recall: 0.4578 - true_negatives: 5237.0000 - false_positives: 643.0000 - precision: 0.6767 - auc: 0.7875 - val_loss: 0.8450 - val_accuracy: 0.6087 - val_recall: 0.4619 - val_true_negatives: 2231.0000 - val_false_positives: 289.0000 - val_precision: 0.6682 - val_auc: 0.7940\n",
      "Epoch 154/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8367 - accuracy: 0.6048 - recall: 0.4622 - true_negatives: 5208.0000 - false_positives: 672.0000 - precision: 0.6691 - auc: 0.7974 - val_loss: 0.8077 - val_accuracy: 0.6325 - val_recall: 0.4706 - val_true_negatives: 2278.0000 - val_false_positives: 242.0000 - val_precision: 0.7102 - val_auc: 0.8201\n",
      "Epoch 155/200\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.8461 - accuracy: 0.6041 - recall: 0.4609 - true_negatives: 5222.0000 - false_positives: 658.0000 - precision: 0.6731 - auc: 0.7933 - val_loss: 0.8372 - val_accuracy: 0.6294 - val_recall: 0.4611 - val_true_negatives: 2246.0000 - val_false_positives: 274.0000 - val_precision: 0.6795 - val_auc: 0.7992\n",
      "Epoch 156/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8421 - accuracy: 0.6129 - recall: 0.4660 - true_negatives: 5223.0000 - false_positives: 657.0000 - precision: 0.6759 - auc: 0.7956 - val_loss: 0.8708 - val_accuracy: 0.5579 - val_recall: 0.4405 - val_true_negatives: 2217.0000 - val_false_positives: 303.0000 - val_precision: 0.6469 - val_auc: 0.7769\n",
      "Epoch 157/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8605 - accuracy: 0.5966 - recall: 0.4588 - true_negatives: 5180.0000 - false_positives: 700.0000 - precision: 0.6584 - auc: 0.7857 - val_loss: 0.8165 - val_accuracy: 0.6230 - val_recall: 0.4810 - val_true_negatives: 2240.0000 - val_false_positives: 280.0000 - val_precision: 0.6840 - val_auc: 0.8116\n",
      "Epoch 158/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8440 - accuracy: 0.6044 - recall: 0.4701 - true_negatives: 5189.0000 - false_positives: 691.0000 - precision: 0.6667 - auc: 0.7946 - val_loss: 0.9534 - val_accuracy: 0.5040 - val_recall: 0.4016 - val_true_negatives: 2122.0000 - val_false_positives: 398.0000 - val_precision: 0.5597 - val_auc: 0.7307\n",
      "Epoch 159/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8864 - accuracy: 0.5810 - recall: 0.4537 - true_negatives: 5129.0000 - false_positives: 751.0000 - precision: 0.6398 - auc: 0.7709 - val_loss: 0.8001 - val_accuracy: 0.6516 - val_recall: 0.4651 - val_true_negatives: 2293.0000 - val_false_positives: 227.0000 - val_precision: 0.7208 - val_auc: 0.8264\n",
      "Epoch 160/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8492 - accuracy: 0.6095 - recall: 0.4684 - true_negatives: 5196.0000 - false_positives: 684.0000 - precision: 0.6681 - auc: 0.7924 - val_loss: 0.7978 - val_accuracy: 0.6397 - val_recall: 0.4810 - val_true_negatives: 2307.0000 - val_false_positives: 213.0000 - val_precision: 0.7399 - val_auc: 0.8281\n",
      "Epoch 161/200\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.8910 - accuracy: 0.5786 - recall: 0.4510 - true_negatives: 5132.0000 - false_positives: 748.0000 - precision: 0.6393 - auc: 0.7689 - val_loss: 0.7982 - val_accuracy: 0.6325 - val_recall: 0.4714 - val_true_negatives: 2322.0000 - val_false_positives: 198.0000 - val_precision: 0.7500 - val_auc: 0.8283\n",
      "Epoch 162/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8362 - accuracy: 0.6105 - recall: 0.4595 - true_negatives: 5251.0000 - false_positives: 629.0000 - precision: 0.6823 - auc: 0.8007 - val_loss: 0.8120 - val_accuracy: 0.6270 - val_recall: 0.4460 - val_true_negatives: 2307.0000 - val_false_positives: 213.0000 - val_precision: 0.7252 - val_auc: 0.8166\n",
      "Epoch 163/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8542 - accuracy: 0.6000 - recall: 0.4510 - true_negatives: 5201.0000 - false_positives: 679.0000 - precision: 0.6613 - auc: 0.7879 - val_loss: 0.8713 - val_accuracy: 0.5556 - val_recall: 0.4706 - val_true_negatives: 2134.0000 - val_false_positives: 386.0000 - val_precision: 0.6057 - val_auc: 0.7732\n",
      "Epoch 164/200\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.9072 - accuracy: 0.5629 - recall: 0.4391 - true_negatives: 5118.0000 - false_positives: 762.0000 - precision: 0.6288 - auc: 0.7589 - val_loss: 0.8142 - val_accuracy: 0.6032 - val_recall: 0.4341 - val_true_negatives: 2312.0000 - val_false_positives: 208.0000 - val_precision: 0.7245 - val_auc: 0.8161\n",
      "Epoch 165/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8584 - accuracy: 0.5997 - recall: 0.4548 - true_negatives: 5222.0000 - false_positives: 658.0000 - precision: 0.6702 - auc: 0.7877 - val_loss: 0.8097 - val_accuracy: 0.6333 - val_recall: 0.4722 - val_true_negatives: 2251.0000 - val_false_positives: 269.0000 - val_precision: 0.6887 - val_auc: 0.8176\n",
      "Epoch 166/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8306 - accuracy: 0.6109 - recall: 0.4636 - true_negatives: 5252.0000 - false_positives: 628.0000 - precision: 0.6846 - auc: 0.8028 - val_loss: 0.8097 - val_accuracy: 0.6190 - val_recall: 0.4778 - val_true_negatives: 2248.0000 - val_false_positives: 272.0000 - val_precision: 0.6888 - val_auc: 0.8165\n",
      "Epoch 167/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8399 - accuracy: 0.6071 - recall: 0.4639 - true_negatives: 5226.0000 - false_positives: 654.0000 - precision: 0.6759 - auc: 0.7971 - val_loss: 0.8155 - val_accuracy: 0.6183 - val_recall: 0.4595 - val_true_negatives: 2267.0000 - val_false_positives: 253.0000 - val_precision: 0.6959 - val_auc: 0.8128\n",
      "Epoch 168/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8250 - accuracy: 0.6153 - recall: 0.4599 - true_negatives: 5272.0000 - false_positives: 608.0000 - precision: 0.6898 - auc: 0.8061 - val_loss: 0.8069 - val_accuracy: 0.6397 - val_recall: 0.4627 - val_true_negatives: 2291.0000 - val_false_positives: 229.0000 - val_precision: 0.7180 - val_auc: 0.8196\n",
      "Epoch 169/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8327 - accuracy: 0.6075 - recall: 0.4694 - true_negatives: 5241.0000 - false_positives: 639.0000 - precision: 0.6835 - auc: 0.8009 - val_loss: 0.7985 - val_accuracy: 0.6452 - val_recall: 0.4929 - val_true_negatives: 2260.0000 - val_false_positives: 260.0000 - val_precision: 0.7049 - val_auc: 0.8245\n",
      "Epoch 170/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8757 - accuracy: 0.5782 - recall: 0.4554 - true_negatives: 5133.0000 - false_positives: 747.0000 - precision: 0.6419 - auc: 0.7756 - val_loss: 0.9144 - val_accuracy: 0.5595 - val_recall: 0.4397 - val_true_negatives: 2170.0000 - val_false_positives: 350.0000 - val_precision: 0.6128 - val_auc: 0.7572\n",
      "Epoch 171/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8652 - accuracy: 0.5878 - recall: 0.4422 - true_negatives: 5193.0000 - false_positives: 687.0000 - precision: 0.6543 - auc: 0.7795 - val_loss: 0.7915 - val_accuracy: 0.6452 - val_recall: 0.4714 - val_true_negatives: 2312.0000 - val_false_positives: 208.0000 - val_precision: 0.7406 - val_auc: 0.8315\n",
      "Epoch 172/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8471 - accuracy: 0.6065 - recall: 0.4704 - true_negatives: 5193.0000 - false_positives: 687.0000 - precision: 0.6681 - auc: 0.7930 - val_loss: 0.8197 - val_accuracy: 0.6262 - val_recall: 0.4484 - val_true_negatives: 2286.0000 - val_false_positives: 234.0000 - val_precision: 0.7071 - val_auc: 0.8098\n",
      "Epoch 173/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8372 - accuracy: 0.6116 - recall: 0.4639 - true_negatives: 5244.0000 - false_positives: 636.0000 - precision: 0.6820 - auc: 0.7990 - val_loss: 0.8302 - val_accuracy: 0.6159 - val_recall: 0.4897 - val_true_negatives: 2210.0000 - val_false_positives: 310.0000 - val_precision: 0.6656 - val_auc: 0.8006\n",
      "Epoch 174/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8767 - accuracy: 0.5779 - recall: 0.4537 - true_negatives: 5113.0000 - false_positives: 767.0000 - precision: 0.6349 - auc: 0.7739 - val_loss: 0.8066 - val_accuracy: 0.6270 - val_recall: 0.4635 - val_true_negatives: 2278.0000 - val_false_positives: 242.0000 - val_precision: 0.7070 - val_auc: 0.8185\n",
      "Epoch 175/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8144 - accuracy: 0.6276 - recall: 0.4776 - true_negatives: 5266.0000 - false_positives: 614.0000 - precision: 0.6957 - auc: 0.8126 - val_loss: 0.7960 - val_accuracy: 0.6603 - val_recall: 0.4683 - val_true_negatives: 2280.0000 - val_false_positives: 240.0000 - val_precision: 0.7108 - val_auc: 0.8273\n",
      "Epoch 176/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8123 - accuracy: 0.6313 - recall: 0.4769 - true_negatives: 5294.0000 - false_positives: 586.0000 - precision: 0.7052 - auc: 0.8140 - val_loss: 0.7890 - val_accuracy: 0.6421 - val_recall: 0.4889 - val_true_negatives: 2307.0000 - val_false_positives: 213.0000 - val_precision: 0.7431 - val_auc: 0.8321\n",
      "Epoch 177/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8156 - accuracy: 0.6262 - recall: 0.4827 - true_negatives: 5240.0000 - false_positives: 640.0000 - precision: 0.6892 - auc: 0.8109 - val_loss: 0.8047 - val_accuracy: 0.6254 - val_recall: 0.4714 - val_true_negatives: 2289.0000 - val_false_positives: 231.0000 - val_precision: 0.7200 - val_auc: 0.8189\n",
      "Epoch 178/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8575 - accuracy: 0.5976 - recall: 0.4731 - true_negatives: 5170.0000 - false_positives: 710.0000 - precision: 0.6621 - auc: 0.7878 - val_loss: 0.8040 - val_accuracy: 0.6302 - val_recall: 0.4905 - val_true_negatives: 2257.0000 - val_false_positives: 263.0000 - val_precision: 0.7015 - val_auc: 0.8194\n",
      "Epoch 179/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8341 - accuracy: 0.6139 - recall: 0.4786 - true_negatives: 5202.0000 - false_positives: 678.0000 - precision: 0.6748 - auc: 0.7990 - val_loss: 0.7862 - val_accuracy: 0.6405 - val_recall: 0.4889 - val_true_negatives: 2306.0000 - val_false_positives: 214.0000 - val_precision: 0.7422 - val_auc: 0.8334\n",
      "Epoch 180/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8329 - accuracy: 0.6065 - recall: 0.4816 - true_negatives: 5209.0000 - false_positives: 671.0000 - precision: 0.6785 - auc: 0.7993 - val_loss: 0.7869 - val_accuracy: 0.6563 - val_recall: 0.4738 - val_true_negatives: 2292.0000 - val_false_positives: 228.0000 - val_precision: 0.7236 - val_auc: 0.8325\n",
      "Epoch 181/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8284 - accuracy: 0.6102 - recall: 0.4827 - true_negatives: 5223.0000 - false_positives: 657.0000 - precision: 0.6835 - auc: 0.8027 - val_loss: 0.8420 - val_accuracy: 0.6143 - val_recall: 0.4794 - val_true_negatives: 2213.0000 - val_false_positives: 307.0000 - val_precision: 0.6630 - val_auc: 0.7940\n",
      "Epoch 182/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8537 - accuracy: 0.6017 - recall: 0.4670 - true_negatives: 5207.0000 - false_positives: 673.0000 - precision: 0.6711 - auc: 0.7889 - val_loss: 0.8389 - val_accuracy: 0.6135 - val_recall: 0.4730 - val_true_negatives: 2222.0000 - val_false_positives: 298.0000 - val_precision: 0.6667 - val_auc: 0.7964\n",
      "Epoch 183/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8465 - accuracy: 0.6017 - recall: 0.4656 - true_negatives: 5194.0000 - false_positives: 686.0000 - precision: 0.6662 - auc: 0.7936 - val_loss: 0.7883 - val_accuracy: 0.6595 - val_recall: 0.4810 - val_true_negatives: 2286.0000 - val_false_positives: 234.0000 - val_precision: 0.7214 - val_auc: 0.8314\n",
      "Epoch 184/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8234 - accuracy: 0.6204 - recall: 0.4871 - true_negatives: 5245.0000 - false_positives: 635.0000 - precision: 0.6928 - auc: 0.8066 - val_loss: 0.7858 - val_accuracy: 0.6341 - val_recall: 0.4849 - val_true_negatives: 2304.0000 - val_false_positives: 216.0000 - val_precision: 0.7388 - val_auc: 0.8325\n",
      "Epoch 185/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8368 - accuracy: 0.6092 - recall: 0.4850 - true_negatives: 5188.0000 - false_positives: 692.0000 - precision: 0.6733 - auc: 0.7982 - val_loss: 0.7855 - val_accuracy: 0.6413 - val_recall: 0.5032 - val_true_negatives: 2283.0000 - val_false_positives: 237.0000 - val_precision: 0.7279 - val_auc: 0.8323\n",
      "Epoch 186/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8281 - accuracy: 0.6122 - recall: 0.4711 - true_negatives: 5225.0000 - false_positives: 655.0000 - precision: 0.6789 - auc: 0.8031 - val_loss: 0.7887 - val_accuracy: 0.6317 - val_recall: 0.4817 - val_true_negatives: 2303.0000 - val_false_positives: 217.0000 - val_precision: 0.7367 - val_auc: 0.8300\n",
      "Epoch 187/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8327 - accuracy: 0.6041 - recall: 0.4745 - true_negatives: 5193.0000 - false_positives: 687.0000 - precision: 0.6700 - auc: 0.7993 - val_loss: 0.9294 - val_accuracy: 0.5190 - val_recall: 0.4254 - val_true_negatives: 2130.0000 - val_false_positives: 390.0000 - val_precision: 0.5788 - val_auc: 0.7440\n",
      "Epoch 188/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8367 - accuracy: 0.6054 - recall: 0.4833 - true_negatives: 5199.0000 - false_positives: 681.0000 - precision: 0.6760 - auc: 0.7986 - val_loss: 0.8570 - val_accuracy: 0.5611 - val_recall: 0.4365 - val_true_negatives: 2221.0000 - val_false_positives: 299.0000 - val_precision: 0.6478 - val_auc: 0.7822\n",
      "Epoch 189/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8563 - accuracy: 0.5990 - recall: 0.4677 - true_negatives: 5187.0000 - false_positives: 693.0000 - precision: 0.6649 - auc: 0.7877 - val_loss: 0.8262 - val_accuracy: 0.6341 - val_recall: 0.4667 - val_true_negatives: 2251.0000 - val_false_positives: 269.0000 - val_precision: 0.6861 - val_auc: 0.8050\n",
      "Epoch 190/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8419 - accuracy: 0.6088 - recall: 0.4650 - true_negatives: 5207.0000 - false_positives: 673.0000 - precision: 0.6701 - auc: 0.7963 - val_loss: 0.7920 - val_accuracy: 0.6349 - val_recall: 0.4937 - val_true_negatives: 2268.0000 - val_false_positives: 252.0000 - val_precision: 0.7117 - val_auc: 0.8279\n",
      "Epoch 191/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8076 - accuracy: 0.6286 - recall: 0.4874 - true_negatives: 5281.0000 - false_positives: 599.0000 - precision: 0.7052 - auc: 0.8162 - val_loss: 0.7911 - val_accuracy: 0.6317 - val_recall: 0.4968 - val_true_negatives: 2260.0000 - val_false_positives: 260.0000 - val_precision: 0.7065 - val_auc: 0.8282\n",
      "Epoch 192/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8228 - accuracy: 0.6173 - recall: 0.4769 - true_negatives: 5264.0000 - false_positives: 616.0000 - precision: 0.6947 - auc: 0.8069 - val_loss: 0.8008 - val_accuracy: 0.6095 - val_recall: 0.4659 - val_true_negatives: 2304.0000 - val_false_positives: 216.0000 - val_precision: 0.7310 - val_auc: 0.8209\n",
      "Epoch 193/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8259 - accuracy: 0.6167 - recall: 0.4690 - true_negatives: 5205.0000 - false_positives: 675.0000 - precision: 0.6714 - auc: 0.8043 - val_loss: 0.8517 - val_accuracy: 0.5643 - val_recall: 0.4484 - val_true_negatives: 2220.0000 - val_false_positives: 300.0000 - val_precision: 0.6532 - val_auc: 0.7873\n",
      "Epoch 194/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8148 - accuracy: 0.6350 - recall: 0.4837 - true_negatives: 5276.0000 - false_positives: 604.0000 - precision: 0.7019 - auc: 0.8126 - val_loss: 0.7829 - val_accuracy: 0.6389 - val_recall: 0.5040 - val_true_negatives: 2292.0000 - val_false_positives: 228.0000 - val_precision: 0.7358 - val_auc: 0.8344\n",
      "Epoch 195/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8193 - accuracy: 0.6228 - recall: 0.4854 - true_negatives: 5238.0000 - false_positives: 642.0000 - precision: 0.6897 - auc: 0.8081 - val_loss: 0.8478 - val_accuracy: 0.5841 - val_recall: 0.5119 - val_true_negatives: 2131.0000 - val_false_positives: 389.0000 - val_precision: 0.6238 - val_auc: 0.7861\n",
      "Epoch 196/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8353 - accuracy: 0.6170 - recall: 0.4881 - true_negatives: 5176.0000 - false_positives: 704.0000 - precision: 0.6709 - auc: 0.7992 - val_loss: 0.7987 - val_accuracy: 0.6381 - val_recall: 0.4706 - val_true_negatives: 2296.0000 - val_false_positives: 224.0000 - val_precision: 0.7258 - val_auc: 0.8237\n",
      "Epoch 197/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8294 - accuracy: 0.6173 - recall: 0.4840 - true_negatives: 5231.0000 - false_positives: 649.0000 - precision: 0.6868 - auc: 0.8040 - val_loss: 0.7792 - val_accuracy: 0.6508 - val_recall: 0.4944 - val_true_negatives: 2309.0000 - val_false_positives: 211.0000 - val_precision: 0.7470 - val_auc: 0.8369\n",
      "Epoch 198/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8138 - accuracy: 0.6248 - recall: 0.4820 - true_negatives: 5247.0000 - false_positives: 633.0000 - precision: 0.6912 - auc: 0.8109 - val_loss: 0.8098 - val_accuracy: 0.6127 - val_recall: 0.4571 - val_true_negatives: 2287.0000 - val_false_positives: 233.0000 - val_precision: 0.7120 - val_auc: 0.8134\n",
      "Epoch 199/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8260 - accuracy: 0.6218 - recall: 0.4833 - true_negatives: 5233.0000 - false_positives: 647.0000 - precision: 0.6871 - auc: 0.8050 - val_loss: 0.7831 - val_accuracy: 0.6413 - val_recall: 0.4738 - val_true_negatives: 2308.0000 - val_false_positives: 212.0000 - val_precision: 0.7379 - val_auc: 0.8331\n",
      "Epoch 200/200\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8332 - accuracy: 0.6071 - recall: 0.4789 - true_negatives: 5214.0000 - false_positives: 666.0000 - precision: 0.6789 - auc: 0.8004 - val_loss: 0.7908 - val_accuracy: 0.6405 - val_recall: 0.5095 - val_true_negatives: 2274.0000 - val_false_positives: 246.0000 - val_precision: 0.7230 - val_auc: 0.8274\n",
      "                    base model  out layers  extra params  epochs  batch size  \\\n",
      "26/03/2022 16:58:33   resnet50           3        131331     200          60   \n",
      "\n",
      "                     accuracy  recall  specificity  precision  f1_score   auc  \\\n",
      "26/03/2022 16:58:33      0.63    0.52         0.89       0.71       0.6  0.82   \n",
      "\n",
      "                     train time  eval time  \n",
      "26/03/2022 16:58:33       44.49       3.78  \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train model using features generated from VGG16 model\n",
    "epochs = 200\n",
    "batch_size = 60\n",
    "specificity = []\n",
    "train_time = []\n",
    "eval_time = []\n",
    "precision = []\n",
    "accuracy = []\n",
    "f1_score = []\n",
    "au_curve = []\n",
    "_layers = []\n",
    "params = []\n",
    "recall = []\n",
    "model = []\n",
    "batch = []\n",
    "epoch = []\n",
    "time_ = []\n",
    "\n",
    "#Se entrena el modelo\n",
    "tic = time.perf_counter()\n",
    "features_train = pretrained_model.predict(X_train.reshape(len(X_train),IMG_SIZE,IMG_SIZE,3))\n",
    "features_val = pretrained_model.predict(X_val.reshape(len(X_val),IMG_SIZE,IMG_SIZE,3))\n",
    "history = (modelCNN.fit(features_train, train_target, epochs=epochs, batch_size=batch_size, validation_data=(features_val, val_target)))\n",
    "toc = time.perf_counter()\n",
    "train_time.append(round((toc-tic), 2))\n",
    "\n",
    "# Se evalua el modelo segun algunas metricas de error\n",
    "tic = time.perf_counter()\n",
    "features_test = pretrained_model.predict(X_test.reshape(len(X_test),IMG_SIZE,IMG_SIZE,3))\n",
    "test_loss, test_acc, test_recall, true_neg, false_pos, test_prec, test_auc = modelCNN.evaluate(features_test,  test_target, verbose=0)\n",
    "toc = time.perf_counter()\n",
    "eval_time.append(round((toc-tic), 2))\n",
    "specificity.append(round(true_neg/(true_neg + false_pos),2))\n",
    "f1_score.append(round(2 * test_recall * test_prec / (test_recall + test_prec),2)\n",
    "                if (test_recall + test_prec) > 0 else 0)\n",
    "model.append(pretrained_model.name)\n",
    "epoch.append(epochs)\n",
    "batch.append(batch_size)\n",
    "accuracy.append(round(test_acc,2))\n",
    "recall.append(round(test_recall,2))\n",
    "precision.append(round(test_prec,2))\n",
    "au_curve.append(round(test_auc,2))\n",
    "_layers.append(len(modelCNN.layers))\n",
    "params.append(modelCNN.count_params()) \n",
    "\n",
    "test_data = {'base model':model,\n",
    "        'out layers': _layers,\n",
    "        'extra params': params,\n",
    "        'epochs': epoch,\n",
    "        'batch size': batch,\n",
    "        'accuracy': accuracy,\n",
    "        'recall': recall,\n",
    "        'specificity': specificity,\n",
    "        'precision': precision,\n",
    "        'f1_score': f1_score,\n",
    "        'auc': au_curve,\n",
    "        'train time': train_time,\n",
    "        'eval time': eval_time\n",
    "        }\n",
    "\n",
    "now = datetime.now() # current date and time\n",
    "time_.append(now.strftime(\"%d/%m/%Y %H:%M:%S\"))\n",
    "df = pd.DataFrame(test_data, index = time_)\n",
    "excel_name = \"./informe/tables/DCNN.xlsx\"\n",
    "append_data_to_excel(excel_name, df)\n",
    "print(df)\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Se puede calcular la matriz de confusión de la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
       "array([[341, 192,  59],\n",
       "       [ 75, 404, 117],\n",
       "       [ 48, 167, 397]])>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_test = pretrained_model.predict(X_test.reshape(len(X_test),IMG_SIZE,IMG_SIZE,3))\n",
    "t_pred = []\n",
    "for i in range(0,len(features_test)):\n",
    "    t_pred.append(np.argmax(modelCNN.predict(features_test[i:i+1])))\n",
    "tf.math.confusion_matrix(t_test, t_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'stored_accuracy' (list)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "stored_accuracy = history.history['accuracy'][-5:]\n",
    "\n",
    "%store stored_accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
